{"version":3,"file":"comunica-browser.js","sources":["webpack://Comunica/webpack/bootstrap","webpack://Comunica//home/travis/build/comunica/comunica/node_modules/buffer/index.js","webpack://Comunica/../actor-rdf-serialize-jsonld/node_modules/jsonld/lib/context.js","webpack://Comunica//home/travis/build/comunica/comunica/node_modules/tslib/tslib.es6.js","webpack://Comunica//home/travis/build/comunica/comunica/node_modules/es6-promise/dist/es6-promise.js","webpack://Comunica/../actor-http-native/lib/Requester-browser.js","webpack://Comunica//home/travis/build/comunica/comunica/node_modules/punycode/punycode.js","webpack://Comunica//home/travis/build/comunica/comunica/node_modules/jsonld/js/jsonld.js","webpack://Comunica/../actor-rdf-serialize-jsonld/node_modules/jsonld/lib/jsonld.js","webpack://Comunica/../actor-rdf-serialize-jsonld/node_modules/jsonld/lib/compact.js"],"sourcesContent":[" \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 288);\n","/*!\n * The buffer module from node.js, for the browser.\n *\n * @author   Feross Aboukhadijeh <feross@feross.org> <http://feross.org>\n * @license  MIT\n */\n/* eslint-disable no-proto */\n\n'use strict'\n\nvar base64 = require('base64-js')\nvar ieee754 = require('ieee754')\nvar isArray = require('isarray')\n\nexports.Buffer = Buffer\nexports.SlowBuffer = SlowBuffer\nexports.INSPECT_MAX_BYTES = 50\n\n/**\n * If `Buffer.TYPED_ARRAY_SUPPORT`:\n *   === true    Use Uint8Array implementation (fastest)\n *   === false   Use Object implementation (most compatible, even IE6)\n *\n * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,\n * Opera 11.6+, iOS 4.2+.\n *\n * Due to various browser bugs, sometimes the Object implementation will be used even\n * when the browser supports typed arrays.\n *\n * Note:\n *\n *   - Firefox 4-29 lacks support for adding new properties to `Uint8Array` instances,\n *     See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438.\n *\n *   - Chrome 9-10 is missing the `TypedArray.prototype.subarray` function.\n *\n *   - IE10 has a broken `TypedArray.prototype.subarray` function which returns arrays of\n *     incorrect length in some situations.\n\n * We detect these buggy browsers and set `Buffer.TYPED_ARRAY_SUPPORT` to `false` so they\n * get the Object implementation, which is slower but behaves correctly.\n */\nBuffer.TYPED_ARRAY_SUPPORT = global.TYPED_ARRAY_SUPPORT !== undefined\n  ? global.TYPED_ARRAY_SUPPORT\n  : typedArraySupport()\n\n/*\n * Export kMaxLength after typed array support is determined.\n */\nexports.kMaxLength = kMaxLength()\n\nfunction typedArraySupport () {\n  try {\n    var arr = new Uint8Array(1)\n    arr.__proto__ = {__proto__: Uint8Array.prototype, foo: function () { return 42 }}\n    return arr.foo() === 42 && // typed array instances can be augmented\n        typeof arr.subarray === 'function' && // chrome 9-10 lack `subarray`\n        arr.subarray(1, 1).byteLength === 0 // ie10 has broken `subarray`\n  } catch (e) {\n    return false\n  }\n}\n\nfunction kMaxLength () {\n  return Buffer.TYPED_ARRAY_SUPPORT\n    ? 0x7fffffff\n    : 0x3fffffff\n}\n\nfunction createBuffer (that, length) {\n  if (kMaxLength() < length) {\n    throw new RangeError('Invalid typed array length')\n  }\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = new Uint8Array(length)\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    if (that === null) {\n      that = new Buffer(length)\n    }\n    that.length = length\n  }\n\n  return that\n}\n\n/**\n * The Buffer constructor returns instances of `Uint8Array` that have their\n * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of\n * `Uint8Array`, so the returned instances will have all the node `Buffer` methods\n * and the `Uint8Array` methods. Square bracket notation works as expected -- it\n * returns a single octet.\n *\n * The `Uint8Array` prototype remains unmodified.\n */\n\nfunction Buffer (arg, encodingOrOffset, length) {\n  if (!Buffer.TYPED_ARRAY_SUPPORT && !(this instanceof Buffer)) {\n    return new Buffer(arg, encodingOrOffset, length)\n  }\n\n  // Common case.\n  if (typeof arg === 'number') {\n    if (typeof encodingOrOffset === 'string') {\n      throw new Error(\n        'If encoding is specified then the first argument must be a string'\n      )\n    }\n    return allocUnsafe(this, arg)\n  }\n  return from(this, arg, encodingOrOffset, length)\n}\n\nBuffer.poolSize = 8192 // not used by this implementation\n\n// TODO: Legacy, not needed anymore. Remove in next major version.\nBuffer._augment = function (arr) {\n  arr.__proto__ = Buffer.prototype\n  return arr\n}\n\nfunction from (that, value, encodingOrOffset, length) {\n  if (typeof value === 'number') {\n    throw new TypeError('\"value\" argument must not be a number')\n  }\n\n  if (typeof ArrayBuffer !== 'undefined' && value instanceof ArrayBuffer) {\n    return fromArrayBuffer(that, value, encodingOrOffset, length)\n  }\n\n  if (typeof value === 'string') {\n    return fromString(that, value, encodingOrOffset)\n  }\n\n  return fromObject(that, value)\n}\n\n/**\n * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError\n * if value is a number.\n * Buffer.from(str[, encoding])\n * Buffer.from(array)\n * Buffer.from(buffer)\n * Buffer.from(arrayBuffer[, byteOffset[, length]])\n **/\nBuffer.from = function (value, encodingOrOffset, length) {\n  return from(null, value, encodingOrOffset, length)\n}\n\nif (Buffer.TYPED_ARRAY_SUPPORT) {\n  Buffer.prototype.__proto__ = Uint8Array.prototype\n  Buffer.__proto__ = Uint8Array\n  if (typeof Symbol !== 'undefined' && Symbol.species &&\n      Buffer[Symbol.species] === Buffer) {\n    // Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97\n    Object.defineProperty(Buffer, Symbol.species, {\n      value: null,\n      configurable: true\n    })\n  }\n}\n\nfunction assertSize (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('\"size\" argument must be a number')\n  } else if (size < 0) {\n    throw new RangeError('\"size\" argument must not be negative')\n  }\n}\n\nfunction alloc (that, size, fill, encoding) {\n  assertSize(size)\n  if (size <= 0) {\n    return createBuffer(that, size)\n  }\n  if (fill !== undefined) {\n    // Only pay attention to encoding if it's a string. This\n    // prevents accidentally sending in a number that would\n    // be interpretted as a start offset.\n    return typeof encoding === 'string'\n      ? createBuffer(that, size).fill(fill, encoding)\n      : createBuffer(that, size).fill(fill)\n  }\n  return createBuffer(that, size)\n}\n\n/**\n * Creates a new filled Buffer instance.\n * alloc(size[, fill[, encoding]])\n **/\nBuffer.alloc = function (size, fill, encoding) {\n  return alloc(null, size, fill, encoding)\n}\n\nfunction allocUnsafe (that, size) {\n  assertSize(size)\n  that = createBuffer(that, size < 0 ? 0 : checked(size) | 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) {\n    for (var i = 0; i < size; ++i) {\n      that[i] = 0\n    }\n  }\n  return that\n}\n\n/**\n * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.\n * */\nBuffer.allocUnsafe = function (size) {\n  return allocUnsafe(null, size)\n}\n/**\n * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.\n */\nBuffer.allocUnsafeSlow = function (size) {\n  return allocUnsafe(null, size)\n}\n\nfunction fromString (that, string, encoding) {\n  if (typeof encoding !== 'string' || encoding === '') {\n    encoding = 'utf8'\n  }\n\n  if (!Buffer.isEncoding(encoding)) {\n    throw new TypeError('\"encoding\" must be a valid string encoding')\n  }\n\n  var length = byteLength(string, encoding) | 0\n  that = createBuffer(that, length)\n\n  var actual = that.write(string, encoding)\n\n  if (actual !== length) {\n    // Writing a hex string, for example, that contains invalid characters will\n    // cause everything after the first invalid character to be ignored. (e.g.\n    // 'abxxcd' will be treated as 'ab')\n    that = that.slice(0, actual)\n  }\n\n  return that\n}\n\nfunction fromArrayLike (that, array) {\n  var length = array.length < 0 ? 0 : checked(array.length) | 0\n  that = createBuffer(that, length)\n  for (var i = 0; i < length; i += 1) {\n    that[i] = array[i] & 255\n  }\n  return that\n}\n\nfunction fromArrayBuffer (that, array, byteOffset, length) {\n  array.byteLength // this throws if `array` is not a valid ArrayBuffer\n\n  if (byteOffset < 0 || array.byteLength < byteOffset) {\n    throw new RangeError('\\'offset\\' is out of bounds')\n  }\n\n  if (array.byteLength < byteOffset + (length || 0)) {\n    throw new RangeError('\\'length\\' is out of bounds')\n  }\n\n  if (byteOffset === undefined && length === undefined) {\n    array = new Uint8Array(array)\n  } else if (length === undefined) {\n    array = new Uint8Array(array, byteOffset)\n  } else {\n    array = new Uint8Array(array, byteOffset, length)\n  }\n\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    // Return an augmented `Uint8Array` instance, for best performance\n    that = array\n    that.__proto__ = Buffer.prototype\n  } else {\n    // Fallback: Return an object instance of the Buffer class\n    that = fromArrayLike(that, array)\n  }\n  return that\n}\n\nfunction fromObject (that, obj) {\n  if (Buffer.isBuffer(obj)) {\n    var len = checked(obj.length) | 0\n    that = createBuffer(that, len)\n\n    if (that.length === 0) {\n      return that\n    }\n\n    obj.copy(that, 0, 0, len)\n    return that\n  }\n\n  if (obj) {\n    if ((typeof ArrayBuffer !== 'undefined' &&\n        obj.buffer instanceof ArrayBuffer) || 'length' in obj) {\n      if (typeof obj.length !== 'number' || isnan(obj.length)) {\n        return createBuffer(that, 0)\n      }\n      return fromArrayLike(that, obj)\n    }\n\n    if (obj.type === 'Buffer' && isArray(obj.data)) {\n      return fromArrayLike(that, obj.data)\n    }\n  }\n\n  throw new TypeError('First argument must be a string, Buffer, ArrayBuffer, Array, or array-like object.')\n}\n\nfunction checked (length) {\n  // Note: cannot use `length < kMaxLength()` here because that fails when\n  // length is NaN (which is otherwise coerced to zero.)\n  if (length >= kMaxLength()) {\n    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +\n                         'size: 0x' + kMaxLength().toString(16) + ' bytes')\n  }\n  return length | 0\n}\n\nfunction SlowBuffer (length) {\n  if (+length != length) { // eslint-disable-line eqeqeq\n    length = 0\n  }\n  return Buffer.alloc(+length)\n}\n\nBuffer.isBuffer = function isBuffer (b) {\n  return !!(b != null && b._isBuffer)\n}\n\nBuffer.compare = function compare (a, b) {\n  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {\n    throw new TypeError('Arguments must be Buffers')\n  }\n\n  if (a === b) return 0\n\n  var x = a.length\n  var y = b.length\n\n  for (var i = 0, len = Math.min(x, y); i < len; ++i) {\n    if (a[i] !== b[i]) {\n      x = a[i]\n      y = b[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\nBuffer.isEncoding = function isEncoding (encoding) {\n  switch (String(encoding).toLowerCase()) {\n    case 'hex':\n    case 'utf8':\n    case 'utf-8':\n    case 'ascii':\n    case 'latin1':\n    case 'binary':\n    case 'base64':\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return true\n    default:\n      return false\n  }\n}\n\nBuffer.concat = function concat (list, length) {\n  if (!isArray(list)) {\n    throw new TypeError('\"list\" argument must be an Array of Buffers')\n  }\n\n  if (list.length === 0) {\n    return Buffer.alloc(0)\n  }\n\n  var i\n  if (length === undefined) {\n    length = 0\n    for (i = 0; i < list.length; ++i) {\n      length += list[i].length\n    }\n  }\n\n  var buffer = Buffer.allocUnsafe(length)\n  var pos = 0\n  for (i = 0; i < list.length; ++i) {\n    var buf = list[i]\n    if (!Buffer.isBuffer(buf)) {\n      throw new TypeError('\"list\" argument must be an Array of Buffers')\n    }\n    buf.copy(buffer, pos)\n    pos += buf.length\n  }\n  return buffer\n}\n\nfunction byteLength (string, encoding) {\n  if (Buffer.isBuffer(string)) {\n    return string.length\n  }\n  if (typeof ArrayBuffer !== 'undefined' && typeof ArrayBuffer.isView === 'function' &&\n      (ArrayBuffer.isView(string) || string instanceof ArrayBuffer)) {\n    return string.byteLength\n  }\n  if (typeof string !== 'string') {\n    string = '' + string\n  }\n\n  var len = string.length\n  if (len === 0) return 0\n\n  // Use a for loop to avoid recursion\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'ascii':\n      case 'latin1':\n      case 'binary':\n        return len\n      case 'utf8':\n      case 'utf-8':\n      case undefined:\n        return utf8ToBytes(string).length\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return len * 2\n      case 'hex':\n        return len >>> 1\n      case 'base64':\n        return base64ToBytes(string).length\n      default:\n        if (loweredCase) return utf8ToBytes(string).length // assume utf8\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\nBuffer.byteLength = byteLength\n\nfunction slowToString (encoding, start, end) {\n  var loweredCase = false\n\n  // No need to verify that \"this.length <= MAX_UINT32\" since it's a read-only\n  // property of a typed array.\n\n  // This behaves neither like String nor Uint8Array in that we set start/end\n  // to their upper/lower bounds if the value passed is out of range.\n  // undefined is handled specially as per ECMA-262 6th Edition,\n  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.\n  if (start === undefined || start < 0) {\n    start = 0\n  }\n  // Return early if start > this.length. Done here to prevent potential uint32\n  // coercion fail below.\n  if (start > this.length) {\n    return ''\n  }\n\n  if (end === undefined || end > this.length) {\n    end = this.length\n  }\n\n  if (end <= 0) {\n    return ''\n  }\n\n  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.\n  end >>>= 0\n  start >>>= 0\n\n  if (end <= start) {\n    return ''\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  while (true) {\n    switch (encoding) {\n      case 'hex':\n        return hexSlice(this, start, end)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Slice(this, start, end)\n\n      case 'ascii':\n        return asciiSlice(this, start, end)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Slice(this, start, end)\n\n      case 'base64':\n        return base64Slice(this, start, end)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return utf16leSlice(this, start, end)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = (encoding + '').toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\n// The property is used by `Buffer.isBuffer` and `is-buffer` (in Safari 5-7) to detect\n// Buffer instances.\nBuffer.prototype._isBuffer = true\n\nfunction swap (b, n, m) {\n  var i = b[n]\n  b[n] = b[m]\n  b[m] = i\n}\n\nBuffer.prototype.swap16 = function swap16 () {\n  var len = this.length\n  if (len % 2 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 16-bits')\n  }\n  for (var i = 0; i < len; i += 2) {\n    swap(this, i, i + 1)\n  }\n  return this\n}\n\nBuffer.prototype.swap32 = function swap32 () {\n  var len = this.length\n  if (len % 4 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 32-bits')\n  }\n  for (var i = 0; i < len; i += 4) {\n    swap(this, i, i + 3)\n    swap(this, i + 1, i + 2)\n  }\n  return this\n}\n\nBuffer.prototype.swap64 = function swap64 () {\n  var len = this.length\n  if (len % 8 !== 0) {\n    throw new RangeError('Buffer size must be a multiple of 64-bits')\n  }\n  for (var i = 0; i < len; i += 8) {\n    swap(this, i, i + 7)\n    swap(this, i + 1, i + 6)\n    swap(this, i + 2, i + 5)\n    swap(this, i + 3, i + 4)\n  }\n  return this\n}\n\nBuffer.prototype.toString = function toString () {\n  var length = this.length | 0\n  if (length === 0) return ''\n  if (arguments.length === 0) return utf8Slice(this, 0, length)\n  return slowToString.apply(this, arguments)\n}\n\nBuffer.prototype.equals = function equals (b) {\n  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')\n  if (this === b) return true\n  return Buffer.compare(this, b) === 0\n}\n\nBuffer.prototype.inspect = function inspect () {\n  var str = ''\n  var max = exports.INSPECT_MAX_BYTES\n  if (this.length > 0) {\n    str = this.toString('hex', 0, max).match(/.{2}/g).join(' ')\n    if (this.length > max) str += ' ... '\n  }\n  return '<Buffer ' + str + '>'\n}\n\nBuffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {\n  if (!Buffer.isBuffer(target)) {\n    throw new TypeError('Argument must be a Buffer')\n  }\n\n  if (start === undefined) {\n    start = 0\n  }\n  if (end === undefined) {\n    end = target ? target.length : 0\n  }\n  if (thisStart === undefined) {\n    thisStart = 0\n  }\n  if (thisEnd === undefined) {\n    thisEnd = this.length\n  }\n\n  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {\n    throw new RangeError('out of range index')\n  }\n\n  if (thisStart >= thisEnd && start >= end) {\n    return 0\n  }\n  if (thisStart >= thisEnd) {\n    return -1\n  }\n  if (start >= end) {\n    return 1\n  }\n\n  start >>>= 0\n  end >>>= 0\n  thisStart >>>= 0\n  thisEnd >>>= 0\n\n  if (this === target) return 0\n\n  var x = thisEnd - thisStart\n  var y = end - start\n  var len = Math.min(x, y)\n\n  var thisCopy = this.slice(thisStart, thisEnd)\n  var targetCopy = target.slice(start, end)\n\n  for (var i = 0; i < len; ++i) {\n    if (thisCopy[i] !== targetCopy[i]) {\n      x = thisCopy[i]\n      y = targetCopy[i]\n      break\n    }\n  }\n\n  if (x < y) return -1\n  if (y < x) return 1\n  return 0\n}\n\n// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,\n// OR the last index of `val` in `buffer` at offset <= `byteOffset`.\n//\n// Arguments:\n// - buffer - a Buffer to search\n// - val - a string, Buffer, or number\n// - byteOffset - an index into `buffer`; will be clamped to an int32\n// - encoding - an optional encoding, relevant is val is a string\n// - dir - true for indexOf, false for lastIndexOf\nfunction bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {\n  // Empty buffer means no match\n  if (buffer.length === 0) return -1\n\n  // Normalize byteOffset\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset > 0x7fffffff) {\n    byteOffset = 0x7fffffff\n  } else if (byteOffset < -0x80000000) {\n    byteOffset = -0x80000000\n  }\n  byteOffset = +byteOffset  // Coerce to Number.\n  if (isNaN(byteOffset)) {\n    // byteOffset: it it's undefined, null, NaN, \"foo\", etc, search whole buffer\n    byteOffset = dir ? 0 : (buffer.length - 1)\n  }\n\n  // Normalize byteOffset: negative offsets start from the end of the buffer\n  if (byteOffset < 0) byteOffset = buffer.length + byteOffset\n  if (byteOffset >= buffer.length) {\n    if (dir) return -1\n    else byteOffset = buffer.length - 1\n  } else if (byteOffset < 0) {\n    if (dir) byteOffset = 0\n    else return -1\n  }\n\n  // Normalize val\n  if (typeof val === 'string') {\n    val = Buffer.from(val, encoding)\n  }\n\n  // Finally, search either indexOf (if dir is true) or lastIndexOf\n  if (Buffer.isBuffer(val)) {\n    // Special case: looking for empty string/buffer always fails\n    if (val.length === 0) {\n      return -1\n    }\n    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)\n  } else if (typeof val === 'number') {\n    val = val & 0xFF // Search for a byte value [0-255]\n    if (Buffer.TYPED_ARRAY_SUPPORT &&\n        typeof Uint8Array.prototype.indexOf === 'function') {\n      if (dir) {\n        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)\n      } else {\n        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)\n      }\n    }\n    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)\n  }\n\n  throw new TypeError('val must be string, number or Buffer')\n}\n\nfunction arrayIndexOf (arr, val, byteOffset, encoding, dir) {\n  var indexSize = 1\n  var arrLength = arr.length\n  var valLength = val.length\n\n  if (encoding !== undefined) {\n    encoding = String(encoding).toLowerCase()\n    if (encoding === 'ucs2' || encoding === 'ucs-2' ||\n        encoding === 'utf16le' || encoding === 'utf-16le') {\n      if (arr.length < 2 || val.length < 2) {\n        return -1\n      }\n      indexSize = 2\n      arrLength /= 2\n      valLength /= 2\n      byteOffset /= 2\n    }\n  }\n\n  function read (buf, i) {\n    if (indexSize === 1) {\n      return buf[i]\n    } else {\n      return buf.readUInt16BE(i * indexSize)\n    }\n  }\n\n  var i\n  if (dir) {\n    var foundIndex = -1\n    for (i = byteOffset; i < arrLength; i++) {\n      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength\n    for (i = byteOffset; i >= 0; i--) {\n      var found = true\n      for (var j = 0; j < valLength; j++) {\n        if (read(arr, i + j) !== read(val, j)) {\n          found = false\n          break\n        }\n      }\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nBuffer.prototype.includes = function includes (val, byteOffset, encoding) {\n  return this.indexOf(val, byteOffset, encoding) !== -1\n}\n\nBuffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)\n}\n\nBuffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {\n  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)\n}\n\nfunction hexWrite (buf, string, offset, length) {\n  offset = Number(offset) || 0\n  var remaining = buf.length - offset\n  if (!length) {\n    length = remaining\n  } else {\n    length = Number(length)\n    if (length > remaining) {\n      length = remaining\n    }\n  }\n\n  // must be an even number of digits\n  var strLen = string.length\n  if (strLen % 2 !== 0) throw new TypeError('Invalid hex string')\n\n  if (length > strLen / 2) {\n    length = strLen / 2\n  }\n  for (var i = 0; i < length; ++i) {\n    var parsed = parseInt(string.substr(i * 2, 2), 16)\n    if (isNaN(parsed)) return i\n    buf[offset + i] = parsed\n  }\n  return i\n}\n\nfunction utf8Write (buf, string, offset, length) {\n  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nfunction asciiWrite (buf, string, offset, length) {\n  return blitBuffer(asciiToBytes(string), buf, offset, length)\n}\n\nfunction latin1Write (buf, string, offset, length) {\n  return asciiWrite(buf, string, offset, length)\n}\n\nfunction base64Write (buf, string, offset, length) {\n  return blitBuffer(base64ToBytes(string), buf, offset, length)\n}\n\nfunction ucs2Write (buf, string, offset, length) {\n  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)\n}\n\nBuffer.prototype.write = function write (string, offset, length, encoding) {\n  // Buffer#write(string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n    length = this.length\n    offset = 0\n  // Buffer#write(string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    length = this.length\n    offset = 0\n  // Buffer#write(string, offset[, length][, encoding])\n  } else if (isFinite(offset)) {\n    offset = offset | 0\n    if (isFinite(length)) {\n      length = length | 0\n      if (encoding === undefined) encoding = 'utf8'\n    } else {\n      encoding = length\n      length = undefined\n    }\n  // legacy write(string, encoding, offset, length) - remove in v0.13\n  } else {\n    throw new Error(\n      'Buffer.write(string, encoding, offset[, length]) is no longer supported'\n    )\n  }\n\n  var remaining = this.length - offset\n  if (length === undefined || length > remaining) length = remaining\n\n  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {\n    throw new RangeError('Attempt to write outside buffer bounds')\n  }\n\n  if (!encoding) encoding = 'utf8'\n\n  var loweredCase = false\n  for (;;) {\n    switch (encoding) {\n      case 'hex':\n        return hexWrite(this, string, offset, length)\n\n      case 'utf8':\n      case 'utf-8':\n        return utf8Write(this, string, offset, length)\n\n      case 'ascii':\n        return asciiWrite(this, string, offset, length)\n\n      case 'latin1':\n      case 'binary':\n        return latin1Write(this, string, offset, length)\n\n      case 'base64':\n        // Warning: maxLength not taken into account in base64Write\n        return base64Write(this, string, offset, length)\n\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return ucs2Write(this, string, offset, length)\n\n      default:\n        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)\n        encoding = ('' + encoding).toLowerCase()\n        loweredCase = true\n    }\n  }\n}\n\nBuffer.prototype.toJSON = function toJSON () {\n  return {\n    type: 'Buffer',\n    data: Array.prototype.slice.call(this._arr || this, 0)\n  }\n}\n\nfunction base64Slice (buf, start, end) {\n  if (start === 0 && end === buf.length) {\n    return base64.fromByteArray(buf)\n  } else {\n    return base64.fromByteArray(buf.slice(start, end))\n  }\n}\n\nfunction utf8Slice (buf, start, end) {\n  end = Math.min(buf.length, end)\n  var res = []\n\n  var i = start\n  while (i < end) {\n    var firstByte = buf[i]\n    var codePoint = null\n    var bytesPerSequence = (firstByte > 0xEF) ? 4\n      : (firstByte > 0xDF) ? 3\n      : (firstByte > 0xBF) ? 2\n      : 1\n\n    if (i + bytesPerSequence <= end) {\n      var secondByte, thirdByte, fourthByte, tempCodePoint\n\n      switch (bytesPerSequence) {\n        case 1:\n          if (firstByte < 0x80) {\n            codePoint = firstByte\n          }\n          break\n        case 2:\n          secondByte = buf[i + 1]\n          if ((secondByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)\n            if (tempCodePoint > 0x7F) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 3:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)\n            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {\n              codePoint = tempCodePoint\n            }\n          }\n          break\n        case 4:\n          secondByte = buf[i + 1]\n          thirdByte = buf[i + 2]\n          fourthByte = buf[i + 3]\n          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {\n            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)\n            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {\n              codePoint = tempCodePoint\n            }\n          }\n      }\n    }\n\n    if (codePoint === null) {\n      // we did not generate a valid codePoint so insert a\n      // replacement char (U+FFFD) and advance only 1 byte\n      codePoint = 0xFFFD\n      bytesPerSequence = 1\n    } else if (codePoint > 0xFFFF) {\n      // encode to utf16 (surrogate pair dance)\n      codePoint -= 0x10000\n      res.push(codePoint >>> 10 & 0x3FF | 0xD800)\n      codePoint = 0xDC00 | codePoint & 0x3FF\n    }\n\n    res.push(codePoint)\n    i += bytesPerSequence\n  }\n\n  return decodeCodePointsArray(res)\n}\n\n// Based on http://stackoverflow.com/a/22747272/680742, the browser with\n// the lowest limit is Chrome, with 0x10000 args.\n// We go 1 magnitude less, for safety\nvar MAX_ARGUMENTS_LENGTH = 0x1000\n\nfunction decodeCodePointsArray (codePoints) {\n  var len = codePoints.length\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()\n  }\n\n  // Decode in chunks to avoid \"call stack size exceeded\".\n  var res = ''\n  var i = 0\n  while (i < len) {\n    res += String.fromCharCode.apply(\n      String,\n      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)\n    )\n  }\n  return res\n}\n\nfunction asciiSlice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i] & 0x7F)\n  }\n  return ret\n}\n\nfunction latin1Slice (buf, start, end) {\n  var ret = ''\n  end = Math.min(buf.length, end)\n\n  for (var i = start; i < end; ++i) {\n    ret += String.fromCharCode(buf[i])\n  }\n  return ret\n}\n\nfunction hexSlice (buf, start, end) {\n  var len = buf.length\n\n  if (!start || start < 0) start = 0\n  if (!end || end < 0 || end > len) end = len\n\n  var out = ''\n  for (var i = start; i < end; ++i) {\n    out += toHex(buf[i])\n  }\n  return out\n}\n\nfunction utf16leSlice (buf, start, end) {\n  var bytes = buf.slice(start, end)\n  var res = ''\n  for (var i = 0; i < bytes.length; i += 2) {\n    res += String.fromCharCode(bytes[i] + bytes[i + 1] * 256)\n  }\n  return res\n}\n\nBuffer.prototype.slice = function slice (start, end) {\n  var len = this.length\n  start = ~~start\n  end = end === undefined ? len : ~~end\n\n  if (start < 0) {\n    start += len\n    if (start < 0) start = 0\n  } else if (start > len) {\n    start = len\n  }\n\n  if (end < 0) {\n    end += len\n    if (end < 0) end = 0\n  } else if (end > len) {\n    end = len\n  }\n\n  if (end < start) end = start\n\n  var newBuf\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    newBuf = this.subarray(start, end)\n    newBuf.__proto__ = Buffer.prototype\n  } else {\n    var sliceLen = end - start\n    newBuf = new Buffer(sliceLen, undefined)\n    for (var i = 0; i < sliceLen; ++i) {\n      newBuf[i] = this[i + start]\n    }\n  }\n\n  return newBuf\n}\n\n/*\n * Need to make sure that buffer isn't trying to write out of bounds.\n */\nfunction checkOffset (offset, ext, length) {\n  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')\n  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')\n}\n\nBuffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    checkOffset(offset, byteLength, this.length)\n  }\n\n  var val = this[offset + --byteLength]\n  var mul = 1\n  while (byteLength > 0 && (mul *= 0x100)) {\n    val += this[offset + --byteLength] * mul\n  }\n\n  return val\n}\n\nBuffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  return this[offset]\n}\n\nBuffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return this[offset] | (this[offset + 1] << 8)\n}\n\nBuffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  return (this[offset] << 8) | this[offset + 1]\n}\n\nBuffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return ((this[offset]) |\n      (this[offset + 1] << 8) |\n      (this[offset + 2] << 16)) +\n      (this[offset + 3] * 0x1000000)\n}\n\nBuffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] * 0x1000000) +\n    ((this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    this[offset + 3])\n}\n\nBuffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var val = this[offset]\n  var mul = 1\n  var i = 0\n  while (++i < byteLength && (mul *= 0x100)) {\n    val += this[offset + i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) checkOffset(offset, byteLength, this.length)\n\n  var i = byteLength\n  var mul = 1\n  var val = this[offset + --i]\n  while (i > 0 && (mul *= 0x100)) {\n    val += this[offset + --i] * mul\n  }\n  mul *= 0x80\n\n  if (val >= mul) val -= Math.pow(2, 8 * byteLength)\n\n  return val\n}\n\nBuffer.prototype.readInt8 = function readInt8 (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 1, this.length)\n  if (!(this[offset] & 0x80)) return (this[offset])\n  return ((0xff - this[offset] + 1) * -1)\n}\n\nBuffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset] | (this[offset + 1] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 2, this.length)\n  var val = this[offset + 1] | (this[offset] << 8)\n  return (val & 0x8000) ? val | 0xFFFF0000 : val\n}\n\nBuffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset]) |\n    (this[offset + 1] << 8) |\n    (this[offset + 2] << 16) |\n    (this[offset + 3] << 24)\n}\n\nBuffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n\n  return (this[offset] << 24) |\n    (this[offset + 1] << 16) |\n    (this[offset + 2] << 8) |\n    (this[offset + 3])\n}\n\nBuffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, true, 23, 4)\n}\n\nBuffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 4, this.length)\n  return ieee754.read(this, offset, false, 23, 4)\n}\n\nBuffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, true, 52, 8)\n}\n\nBuffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {\n  if (!noAssert) checkOffset(offset, 8, this.length)\n  return ieee754.read(this, offset, false, 52, 8)\n}\n\nfunction checkInt (buf, value, offset, ext, max, min) {\n  if (!Buffer.isBuffer(buf)) throw new TypeError('\"buffer\" argument must be a Buffer instance')\n  if (value > max || value < min) throw new RangeError('\"value\" argument is out of bounds')\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n}\n\nBuffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var mul = 1\n  var i = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  byteLength = byteLength | 0\n  if (!noAssert) {\n    var maxBytes = Math.pow(2, 8 * byteLength) - 1\n    checkInt(this, value, offset, byteLength, maxBytes, 0)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    this[offset + i] = (value / mul) & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nfunction objectWriteUInt16 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 2); i < j; ++i) {\n    buf[offset + i] = (value & (0xff << (8 * (littleEndian ? i : 1 - i)))) >>>\n      (littleEndian ? i : 1 - i) * 8\n  }\n}\n\nBuffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nfunction objectWriteUInt32 (buf, value, offset, littleEndian) {\n  if (value < 0) value = 0xffffffff + value + 1\n  for (var i = 0, j = Math.min(buf.length - offset, 4); i < j; ++i) {\n    buf[offset + i] = (value >>> (littleEndian ? i : 3 - i) * 8) & 0xff\n  }\n}\n\nBuffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset + 3] = (value >>> 24)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 1] = (value >>> 8)\n    this[offset] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = 0\n  var mul = 1\n  var sub = 0\n  this[offset] = value & 0xFF\n  while (++i < byteLength && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) {\n    var limit = Math.pow(2, 8 * byteLength - 1)\n\n    checkInt(this, value, offset, byteLength, limit - 1, -limit)\n  }\n\n  var i = byteLength - 1\n  var mul = 1\n  var sub = 0\n  this[offset + i] = value & 0xFF\n  while (--i >= 0 && (mul *= 0x100)) {\n    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {\n      sub = 1\n    }\n    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF\n  }\n\n  return offset + byteLength\n}\n\nBuffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)\n  if (!Buffer.TYPED_ARRAY_SUPPORT) value = Math.floor(value)\n  if (value < 0) value = 0xff + value + 1\n  this[offset] = (value & 0xff)\n  return offset + 1\n}\n\nBuffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n  } else {\n    objectWriteUInt16(this, value, offset, true)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 8)\n    this[offset + 1] = (value & 0xff)\n  } else {\n    objectWriteUInt16(this, value, offset, false)\n  }\n  return offset + 2\n}\n\nBuffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value & 0xff)\n    this[offset + 1] = (value >>> 8)\n    this[offset + 2] = (value >>> 16)\n    this[offset + 3] = (value >>> 24)\n  } else {\n    objectWriteUInt32(this, value, offset, true)\n  }\n  return offset + 4\n}\n\nBuffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {\n  value = +value\n  offset = offset | 0\n  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)\n  if (value < 0) value = 0xffffffff + value + 1\n  if (Buffer.TYPED_ARRAY_SUPPORT) {\n    this[offset] = (value >>> 24)\n    this[offset + 1] = (value >>> 16)\n    this[offset + 2] = (value >>> 8)\n    this[offset + 3] = (value & 0xff)\n  } else {\n    objectWriteUInt32(this, value, offset, false)\n  }\n  return offset + 4\n}\n\nfunction checkIEEE754 (buf, value, offset, ext, max, min) {\n  if (offset + ext > buf.length) throw new RangeError('Index out of range')\n  if (offset < 0) throw new RangeError('Index out of range')\n}\n\nfunction writeFloat (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 23, 4)\n  return offset + 4\n}\n\nBuffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {\n  return writeFloat(this, value, offset, false, noAssert)\n}\n\nfunction writeDouble (buf, value, offset, littleEndian, noAssert) {\n  if (!noAssert) {\n    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)\n  }\n  ieee754.write(buf, value, offset, littleEndian, 52, 8)\n  return offset + 8\n}\n\nBuffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, true, noAssert)\n}\n\nBuffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {\n  return writeDouble(this, value, offset, false, noAssert)\n}\n\n// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)\nBuffer.prototype.copy = function copy (target, targetStart, start, end) {\n  if (!start) start = 0\n  if (!end && end !== 0) end = this.length\n  if (targetStart >= target.length) targetStart = target.length\n  if (!targetStart) targetStart = 0\n  if (end > 0 && end < start) end = start\n\n  // Copy 0 bytes; we're done\n  if (end === start) return 0\n  if (target.length === 0 || this.length === 0) return 0\n\n  // Fatal error conditions\n  if (targetStart < 0) {\n    throw new RangeError('targetStart out of bounds')\n  }\n  if (start < 0 || start >= this.length) throw new RangeError('sourceStart out of bounds')\n  if (end < 0) throw new RangeError('sourceEnd out of bounds')\n\n  // Are we oob?\n  if (end > this.length) end = this.length\n  if (target.length - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  var len = end - start\n  var i\n\n  if (this === target && start < targetStart && targetStart < end) {\n    // descending copy from end\n    for (i = len - 1; i >= 0; --i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else if (len < 1000 || !Buffer.TYPED_ARRAY_SUPPORT) {\n    // ascending copy from start\n    for (i = 0; i < len; ++i) {\n      target[i + targetStart] = this[i + start]\n    }\n  } else {\n    Uint8Array.prototype.set.call(\n      target,\n      this.subarray(start, start + len),\n      targetStart\n    )\n  }\n\n  return len\n}\n\n// Usage:\n//    buffer.fill(number[, offset[, end]])\n//    buffer.fill(buffer[, offset[, end]])\n//    buffer.fill(string[, offset[, end]][, encoding])\nBuffer.prototype.fill = function fill (val, start, end, encoding) {\n  // Handle string cases:\n  if (typeof val === 'string') {\n    if (typeof start === 'string') {\n      encoding = start\n      start = 0\n      end = this.length\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = this.length\n    }\n    if (val.length === 1) {\n      var code = val.charCodeAt(0)\n      if (code < 256) {\n        val = code\n      }\n    }\n    if (encoding !== undefined && typeof encoding !== 'string') {\n      throw new TypeError('encoding must be a string')\n    }\n    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {\n      throw new TypeError('Unknown encoding: ' + encoding)\n    }\n  } else if (typeof val === 'number') {\n    val = val & 255\n  }\n\n  // Invalid ranges are not set to a default, so can range check early.\n  if (start < 0 || this.length < start || this.length < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (end <= start) {\n    return this\n  }\n\n  start = start >>> 0\n  end = end === undefined ? this.length : end >>> 0\n\n  if (!val) val = 0\n\n  var i\n  if (typeof val === 'number') {\n    for (i = start; i < end; ++i) {\n      this[i] = val\n    }\n  } else {\n    var bytes = Buffer.isBuffer(val)\n      ? val\n      : utf8ToBytes(new Buffer(val, encoding).toString())\n    var len = bytes.length\n    for (i = 0; i < end - start; ++i) {\n      this[i + start] = bytes[i % len]\n    }\n  }\n\n  return this\n}\n\n// HELPER FUNCTIONS\n// ================\n\nvar INVALID_BASE64_RE = /[^+\\/0-9A-Za-z-_]/g\n\nfunction base64clean (str) {\n  // Node strips out invalid characters like \\n and \\t from the string, base64-js does not\n  str = stringtrim(str).replace(INVALID_BASE64_RE, '')\n  // Node converts strings with length < 2 to ''\n  if (str.length < 2) return ''\n  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not\n  while (str.length % 4 !== 0) {\n    str = str + '='\n  }\n  return str\n}\n\nfunction stringtrim (str) {\n  if (str.trim) return str.trim()\n  return str.replace(/^\\s+|\\s+$/g, '')\n}\n\nfunction toHex (n) {\n  if (n < 16) return '0' + n.toString(16)\n  return n.toString(16)\n}\n\nfunction utf8ToBytes (string, units) {\n  units = units || Infinity\n  var codePoint\n  var length = string.length\n  var leadSurrogate = null\n  var bytes = []\n\n  for (var i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i)\n\n    // is surrogate component\n    if (codePoint > 0xD7FF && codePoint < 0xE000) {\n      // last char was a lead\n      if (!leadSurrogate) {\n        // no lead yet\n        if (codePoint > 0xDBFF) {\n          // unexpected trail\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        } else if (i + 1 === length) {\n          // unpaired lead\n          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n          continue\n        }\n\n        // valid lead\n        leadSurrogate = codePoint\n\n        continue\n      }\n\n      // 2 leads in a row\n      if (codePoint < 0xDC00) {\n        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n        leadSurrogate = codePoint\n        continue\n      }\n\n      // valid surrogate pair\n      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000\n    } else if (leadSurrogate) {\n      // valid bmp char, but last char was a lead\n      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)\n    }\n\n    leadSurrogate = null\n\n    // encode utf8\n    if (codePoint < 0x80) {\n      if ((units -= 1) < 0) break\n      bytes.push(codePoint)\n    } else if (codePoint < 0x800) {\n      if ((units -= 2) < 0) break\n      bytes.push(\n        codePoint >> 0x6 | 0xC0,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x10000) {\n      if ((units -= 3) < 0) break\n      bytes.push(\n        codePoint >> 0xC | 0xE0,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else if (codePoint < 0x110000) {\n      if ((units -= 4) < 0) break\n      bytes.push(\n        codePoint >> 0x12 | 0xF0,\n        codePoint >> 0xC & 0x3F | 0x80,\n        codePoint >> 0x6 & 0x3F | 0x80,\n        codePoint & 0x3F | 0x80\n      )\n    } else {\n      throw new Error('Invalid code point')\n    }\n  }\n\n  return bytes\n}\n\nfunction asciiToBytes (str) {\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    // Node's code seems to be doing this and not & 0x7F..\n    byteArray.push(str.charCodeAt(i) & 0xFF)\n  }\n  return byteArray\n}\n\nfunction utf16leToBytes (str, units) {\n  var c, hi, lo\n  var byteArray = []\n  for (var i = 0; i < str.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    c = str.charCodeAt(i)\n    hi = c >> 8\n    lo = c % 256\n    byteArray.push(lo)\n    byteArray.push(hi)\n  }\n\n  return byteArray\n}\n\nfunction base64ToBytes (str) {\n  return base64.toByteArray(base64clean(str))\n}\n\nfunction blitBuffer (src, dst, offset, length) {\n  for (var i = 0; i < length; ++i) {\n    if ((i + offset >= dst.length) || (i >= src.length)) break\n    dst[i + offset] = src[i]\n  }\n  return i\n}\n\nfunction isnan (val) {\n  return val !== val // eslint-disable-line no-self-compare\n}\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst util = require('./util');\nconst ActiveContextCache = require('./ActiveContextCache');\nconst JsonLdError = require('./JsonLdError');\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString,\n  isUndefined: _isUndefined\n} = require('./types');\n\nconst {\n  isAbsolute: _isAbsoluteIri,\n  isRelative: _isRelativeIri,\n  prependBase,\n  parse: parseUrl\n} = require('./url');\n\nconst MAX_CONTEXT_URLS = 10;\n\nconst api = {};\nmodule.exports = api;\n\napi.cache = new ActiveContextCache();\n\n/**\n * Processes a local context and returns a new active context.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param options the context processing options.\n *\n * @return the new active context.\n */\napi.process = ({activeCtx, localCtx, options}) => {\n  // normalize local context to an array of @context objects\n  if(_isObject(localCtx) && '@context' in localCtx &&\n    _isArray(localCtx['@context'])) {\n    localCtx = localCtx['@context'];\n  }\n  const ctxs = _isArray(localCtx) ? localCtx : [localCtx];\n\n  // no contexts in array, clone existing context\n  if(ctxs.length === 0) {\n    return activeCtx.clone();\n  }\n\n  // process each context in order, update active context\n  // on each iteration to ensure proper caching\n  let rval = activeCtx;\n  for(let i = 0; i < ctxs.length; ++i) {\n    let ctx = ctxs[i];\n\n    // reset to initial context\n    if(ctx === null) {\n      rval = activeCtx = api.getInitialContext(options);\n      continue;\n    }\n\n    // dereference @context key if present\n    if(_isObject(ctx) && '@context' in ctx) {\n      ctx = ctx['@context'];\n    }\n\n    // context must be an object by now, all URLs retrieved before this call\n    if(!_isObject(ctx)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context must be an object.',\n        'jsonld.SyntaxError', {code: 'invalid local context', context: ctx});\n    }\n\n    // get context from cache if available\n    if(api.cache) {\n      const cached = api.cache.get(activeCtx, ctx);\n      if(cached) {\n        rval = activeCtx = cached;\n        continue;\n      }\n    }\n\n    // update active context and clone new one before updating\n    activeCtx = rval;\n    rval = rval.clone();\n\n    // define context mappings for keys in local context\n    const defined = {};\n\n    // handle @version\n    if('@version' in ctx) {\n      if(ctx['@version'] !== 1.1) {\n        throw new JsonLdError(\n          'Unsupported JSON-LD version: ' + ctx['@version'],\n          'jsonld.UnsupportedVersion',\n          {code: 'invalid @version value', context: ctx});\n      }\n      if(activeCtx.processingMode &&\n        activeCtx.processingMode === 'json-ld-1.0') {\n        throw new JsonLdError(\n          '@version: ' + ctx['@version'] + ' not compatible with ' +\n          activeCtx.processingMode,\n          'jsonld.ProcessingModeConflict',\n          {code: 'processing mode conflict', context: ctx});\n      }\n      rval.processingMode = 'json-ld-1.1';\n      rval['@version'] = ctx['@version'];\n      defined['@version'] = true;\n    }\n\n    // if not set explicitly, set processingMode to \"json-ld-1.0\"\n    rval.processingMode =\n      rval.processingMode || activeCtx.processingMode || 'json-ld-1.0';\n\n    // handle @base\n    if('@base' in ctx) {\n      let base = ctx['@base'];\n\n      if(base === null) {\n        // no action\n      } else if(_isAbsoluteIri(base)) {\n        base = parseUrl(base);\n      } else if(_isRelativeIri(base)) {\n        base = parseUrl(prependBase(activeCtx['@base'].href, base));\n      } else {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@base\" in a ' +\n          '@context must be an absolute IRI, a relative IRI, or null.',\n          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});\n      }\n\n      rval['@base'] = base;\n      defined['@base'] = true;\n    }\n\n    // handle @vocab\n    if('@vocab' in ctx) {\n      const value = ctx['@vocab'];\n      if(value === null) {\n        delete rval['@vocab'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else if(!_isAbsoluteIri(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be an absolute IRI.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else {\n        rval['@vocab'] = value;\n      }\n      defined['@vocab'] = true;\n    }\n\n    // handle @language\n    if('@language' in ctx) {\n      const value = ctx['@language'];\n      if(value === null) {\n        delete rval['@language'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@language\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError',\n          {code: 'invalid default language', context: ctx});\n      } else {\n        rval['@language'] = value.toLowerCase();\n      }\n      defined['@language'] = true;\n    }\n\n    // process all other keys\n    for(const key in ctx) {\n      api.createTermDefinition(rval, ctx, key, defined);\n    }\n\n    // cache result\n    if(api.cache) {\n      api.cache.set(activeCtx, ctx, rval);\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Creates a term definition during context processing.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context being processed.\n * @param term the term in the local context to define the mapping for.\n * @param defined a map of defining/defined keys to detect cycles and prevent\n *          double definitions.\n */\napi.createTermDefinition = (activeCtx, localCtx, term, defined) => {\n  if(term in defined) {\n    // term already defined\n    if(defined[term]) {\n      return;\n    }\n    // cycle detected\n    throw new JsonLdError(\n      'Cyclical context definition detected.',\n      'jsonld.CyclicalContext',\n      {code: 'cyclic IRI mapping', context: localCtx, term: term});\n  }\n\n  // now defining term\n  defined[term] = false;\n\n  if(api.isKeyword(term)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; keywords cannot be overridden.',\n      'jsonld.SyntaxError',\n      {code: 'keyword redefinition', context: localCtx, term: term});\n  }\n\n  if(term === '') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a term cannot be an empty string.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // remove old mapping\n  if(activeCtx.mappings[term]) {\n    delete activeCtx.mappings[term];\n  }\n\n  // get context term value\n  let value = localCtx[term];\n\n  // clear context entry\n  if(value === null || (_isObject(value) && value['@id'] === null)) {\n    activeCtx.mappings[term] = null;\n    defined[term] = true;\n    return;\n  }\n\n  // convert short-hand value to object w/@id\n  let simpleTerm = false;\n  if(_isString(value)) {\n    simpleTerm = true;\n    value = {'@id': value};\n  }\n\n  if(!_isObject(value)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context term values must be ' +\n      'strings or objects.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // create new mapping\n  const mapping = activeCtx.mappings[term] = {};\n  mapping.reverse = false;\n\n  // make sure term definition only has expected keywords\n  const validKeys = ['@container', '@id', '@language', '@reverse', '@type'];\n\n  // JSON-LD 1.1 support\n  if(api.processingMode(activeCtx, 1.1)) {\n    validKeys.push('@context', '@nest', '@prefix');\n  }\n\n  for(const kw in value) {\n    if(!validKeys.includes(kw)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a term definition must not contain ' + kw,\n        'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n  }\n\n  // always compute whether term has a colon as an optimization for\n  // _compactIri\n  const colon = term.indexOf(':');\n  mapping._termHasColon = (colon !== -1);\n\n  if('@reverse' in value) {\n    if('@id' in value) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @reverse term definition must not ' +\n        'contain @id.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n    if('@nest' in value) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @reverse term definition must not ' +\n        'contain @nest.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n    const reverse = value['@reverse'];\n    if(!_isString(reverse)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n\n    // expand and add @id mapping\n    const id = api.expandIri(\n      activeCtx, reverse, {vocab: true, base: false}, localCtx, defined);\n    if(!_isAbsoluteIri(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be an ' +\n        'absolute IRI or a blank node identifier.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n    mapping['@id'] = id;\n    mapping.reverse = true;\n  } else if('@id' in value) {\n    let id = value['@id'];\n    if(!_isString(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @id value must be an array ' +\n        'of strings or a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n    if(id !== term) {\n      // expand and add @id mapping\n      id = api.expandIri(\n        activeCtx, id, {vocab: true, base: false}, localCtx, defined);\n      if(!_isAbsoluteIri(id) && !api.isKeyword(id)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a @context @id value must be an ' +\n          'absolute IRI, a blank node identifier, or a keyword.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx});\n      }\n      mapping['@id'] = id;\n      // indicate if this term may be used as a compact IRI prefix\n      mapping._prefix = (!mapping._termHasColon &&\n        id.match(/[:\\/\\?#\\[\\]@]$/) &&\n        (simpleTerm || api.processingMode(activeCtx, 1.0)));\n    }\n  }\n\n  if(!('@id' in mapping)) {\n    // see if the term has a prefix\n    if(mapping._termHasColon) {\n      const prefix = term.substr(0, colon);\n      if(prefix in localCtx) {\n        // define parent prefix\n        api.createTermDefinition(activeCtx, localCtx, prefix, defined);\n      }\n\n      if(activeCtx.mappings[prefix]) {\n        // set @id based on prefix parent\n        const suffix = term.substr(colon + 1);\n        mapping['@id'] = activeCtx.mappings[prefix]['@id'] + suffix;\n      } else {\n        // term is an absolute IRI\n        mapping['@id'] = term;\n      }\n    } else {\n      // non-IRIs *must* define @ids if @vocab is not available\n      if(!('@vocab' in activeCtx)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @context terms must define an @id.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx, term: term});\n      }\n      // prepend vocab to term\n      mapping['@id'] = activeCtx['@vocab'] + term;\n    }\n  }\n\n  // IRI mapping now defined\n  defined[term] = true;\n\n  if('@type' in value) {\n    let type = value['@type'];\n    if(!_isString(type)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an @context @type values must be a string.',\n        'jsonld.SyntaxError',\n        {code: 'invalid type mapping', context: localCtx});\n    }\n\n    if(type !== '@id' && type !== '@vocab') {\n      // expand @type to full IRI\n      type = api.expandIri(\n        activeCtx, type, {vocab: true, base: false}, localCtx, defined);\n      if(!_isAbsoluteIri(type)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must be an ' +\n          'absolute IRI.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n      if(type.indexOf('_:') === 0) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type values must be an IRI, ' +\n          'not a blank node identifier.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n    }\n\n    // add @type to mapping\n    mapping['@type'] = type;\n  }\n\n  if('@container' in value) {\n    // normalize container to an array form\n    const container = _isString(value['@container']) ?\n      [value['@container']] : (value['@container'] || []);\n    const validContainers = ['@list', '@set', '@index', '@language'];\n    let isValid = true;\n    const hasSet = container.includes('@set');\n\n    // JSON-LD 1.1 support\n    if(api.processingMode(activeCtx, 1.1)) {\n      validContainers.push('@graph', '@id', '@type');\n\n      // check container length\n      if(container.includes('@list')) {\n        if(container.length !== 1) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; @context @container with @list must ' +\n            'have no other values',\n            'jsonld.SyntaxError',\n            {code: 'invalid container mapping', context: localCtx});\n        }\n      } else if(container.includes('@graph')) {\n        if(container.some(key =>\n          key !== '@graph' && key !== '@id' && key !== '@index' &&\n          key !== '@set')) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; @context @container with @graph must ' +\n            'have no other values other than @id, @index, and @set',\n            'jsonld.SyntaxError',\n            {code: 'invalid container mapping', context: localCtx});\n        }\n      } else {\n        // otherwise, container may also include @set\n        isValid &= container.length <= (hasSet ? 2 : 1);\n      }\n    } else {\n      // in JSON-LD 1.0, container must not be an array (it must be a string,\n      // which is one of the validContainers)\n      isValid &= !_isArray(value['@container']);\n\n      // check container length\n      isValid &= container.length <= 1;\n    }\n\n    // check against valid containers\n    isValid &= container.every(c => validContainers.includes(c));\n\n    // @set not allowed with @list\n    isValid &= !(hasSet && container.includes('@list'));\n\n    if(!isValid) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value must be ' +\n        'one of the following: ' + validContainers.join(', '),\n        'jsonld.SyntaxError',\n        {code: 'invalid container mapping', context: localCtx});\n    }\n\n    if(mapping.reverse &&\n      !container.every(c => ['@index', '@set'].includes(c))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value for a @reverse ' +\n        'type definition must be @index or @set.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n\n    // add @container to mapping\n    mapping['@container'] = container;\n  }\n\n  // scoped contexts\n  if('@context' in value) {\n    mapping['@context'] = value['@context'];\n  }\n\n  if('@language' in value && !('@type' in value)) {\n    let language = value['@language'];\n    if(language !== null && !_isString(language)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @language value must be ' +\n        'a string or null.', 'jsonld.SyntaxError',\n        {code: 'invalid language mapping', context: localCtx});\n    }\n\n    // add @language to mapping\n    if(language !== null) {\n      language = language.toLowerCase();\n    }\n    mapping['@language'] = language;\n  }\n\n  // term may be used as a prefix\n  if('@prefix' in value) {\n    if(mapping._termHasColon) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @prefix used on a compact IRI term',\n        'jsonld.SyntaxError',\n        {code: 'invalid term definition', context: localCtx});\n    }\n    if(typeof value['@prefix'] === 'boolean') {\n      mapping._prefix = value['@prefix'] === true;\n    } else {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context value for @prefix must be boolean',\n        'jsonld.SyntaxError',\n        {code: 'invalid @prefix value', context: localCtx});\n    }\n  }\n\n  if('@nest' in value) {\n    const nest = value['@nest'];\n    if(!_isString(nest) || (nest !== '@nest' && nest.indexOf('@') === 0)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @nest value must be ' +\n        'a string which is not a keyword other than @nest.',\n        'jsonld.SyntaxError',\n        {code: 'invalid @nest value', context: localCtx});\n    }\n    mapping['@nest'] = nest;\n  }\n\n  // disallow aliasing @context and @preserve\n  const id = mapping['@id'];\n  if(id === '@context' || id === '@preserve') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context and @preserve cannot be aliased.',\n      'jsonld.SyntaxError', {code: 'invalid keyword alias', context: localCtx});\n  }\n};\n\n/**\n * Expands a string to a full IRI. The string may be a term, a prefix, a\n * relative IRI, or an absolute IRI. The associated absolute IRI will be\n * returned.\n *\n * @param activeCtx the current active context.\n * @param value the string to expand.\n * @param relativeTo options for how to resolve relative IRIs:\n *          base: true to resolve against the base IRI, false not to.\n *          vocab: true to concatenate after @vocab, false not to.\n * @param localCtx the local context being processed (only given if called\n *          during context processing).\n * @param defined a map for tracking cycles in context definitions (only given\n *          if called during context processing).\n *\n * @return the expanded value.\n */\napi.expandIri = (activeCtx, value, relativeTo, localCtx, defined) => {\n  // already expanded\n  if(value === null || !_isString(value) || api.isKeyword(value)) {\n    return value;\n  }\n\n  // define term dependency if not defined\n  if(localCtx && value in localCtx && defined[value] !== true) {\n    api.createTermDefinition(activeCtx, localCtx, value, defined);\n  }\n\n  relativeTo = relativeTo || {};\n  if(relativeTo.vocab) {\n    const mapping = activeCtx.mappings[value];\n\n    // value is explicitly ignored with a null mapping\n    if(mapping === null) {\n      return null;\n    }\n\n    if(mapping) {\n      // value is a term\n      return mapping['@id'];\n    }\n  }\n\n  // split value into prefix:suffix\n  const colon = value.indexOf(':');\n  if(colon !== -1) {\n    const prefix = value.substr(0, colon);\n    const suffix = value.substr(colon + 1);\n\n    // do not expand blank nodes (prefix of '_') or already-absolute\n    // IRIs (suffix of '//')\n    if(prefix === '_' || suffix.indexOf('//') === 0) {\n      return value;\n    }\n\n    // prefix dependency not defined, define it\n    if(localCtx && prefix in localCtx) {\n      api.createTermDefinition(activeCtx, localCtx, prefix, defined);\n    }\n\n    // use mapping if prefix is defined\n    const mapping = activeCtx.mappings[prefix];\n    if(mapping) {\n      return mapping['@id'] + suffix;\n    }\n\n    // already absolute IRI\n    return value;\n  }\n\n  // prepend vocab\n  if(relativeTo.vocab && '@vocab' in activeCtx) {\n    return activeCtx['@vocab'] + value;\n  }\n\n  // prepend base\n  if(relativeTo.base) {\n    return prependBase(activeCtx['@base'], value);\n  }\n\n  return value;\n};\n\n/**\n * Gets the initial context.\n *\n * @param options the options to use:\n *          [base] the document base IRI.\n *\n * @return the initial context.\n */\napi.getInitialContext = (options) => {\n  const base = parseUrl(options.base || '');\n  return {\n    '@base': base,\n    processingMode: options.processingMode,\n    mappings: {},\n    inverse: null,\n    getInverse: _createInverseContext,\n    clone: _cloneActiveContext\n  };\n\n  /**\n   * Generates an inverse context for use in the compaction algorithm, if\n   * not already generated for the given active context.\n   *\n   * @return the inverse context.\n   */\n  function _createInverseContext() {\n    const activeCtx = this;\n\n    // lazily create inverse\n    if(activeCtx.inverse) {\n      return activeCtx.inverse;\n    }\n    const inverse = activeCtx.inverse = {};\n\n    // variables for building fast CURIE map\n    const fastCurieMap = activeCtx.fastCurieMap = {};\n    const irisToTerms = {};\n\n    // handle default language\n    const defaultLanguage = activeCtx['@language'] || '@none';\n\n    // create term selections for each mapping in the context, ordered by\n    // shortest and then lexicographically least\n    const mappings = activeCtx.mappings;\n    const terms = Object.keys(mappings).sort(util.compareShortestLeast);\n    for(let i = 0; i < terms.length; ++i) {\n      const term = terms[i];\n      const mapping = mappings[term];\n      if(mapping === null) {\n        continue;\n      }\n\n      let container = mapping['@container'] || '@none';\n      container = [].concat(container).sort().join('');\n\n      // iterate over every IRI in the mapping\n      const ids = [].concat(mapping['@id']);\n      for(let ii = 0; ii < ids.length; ++ii) {\n        const iri = ids[ii];\n        let entry = inverse[iri];\n        const isKeyword = api.isKeyword(iri);\n\n        if(!entry) {\n          // initialize entry\n          inverse[iri] = entry = {};\n\n          if(!isKeyword && !mapping._termHasColon) {\n            // init IRI to term map and fast CURIE prefixes\n            irisToTerms[iri] = [term];\n            const fastCurieEntry = {iri: iri, terms: irisToTerms[iri]};\n            if(iri[0] in fastCurieMap) {\n              fastCurieMap[iri[0]].push(fastCurieEntry);\n            } else {\n              fastCurieMap[iri[0]] = [fastCurieEntry];\n            }\n          }\n        } else if(!isKeyword && !mapping._termHasColon) {\n          // add IRI to term match\n          irisToTerms[iri].push(term);\n        }\n\n        // add new entry\n        if(!entry[container]) {\n          entry[container] = {\n            '@language': {},\n            '@type': {},\n            '@any': {}\n          };\n        }\n        entry = entry[container];\n        _addPreferredTerm(term, entry['@any'], '@none');\n\n        if(mapping.reverse) {\n          // term is preferred for values using @reverse\n          _addPreferredTerm(term, entry['@type'], '@reverse');\n        } else if('@type' in mapping) {\n          // term is preferred for values using specific type\n          _addPreferredTerm(term, entry['@type'], mapping['@type']);\n        } else if('@language' in mapping) {\n          // term is preferred for values using specific language\n          const language = mapping['@language'] || '@null';\n          _addPreferredTerm(term, entry['@language'], language);\n        } else {\n          // term is preferred for values w/default language or no type and\n          // no language\n          // add an entry for the default language\n          _addPreferredTerm(term, entry['@language'], defaultLanguage);\n\n          // add entries for no type and no language\n          _addPreferredTerm(term, entry['@type'], '@none');\n          _addPreferredTerm(term, entry['@language'], '@none');\n        }\n      }\n    }\n\n    // build fast CURIE map\n    for(const key in fastCurieMap) {\n      _buildIriMap(fastCurieMap, key, 1);\n    }\n\n    return inverse;\n  }\n\n  /**\n   * Runs a recursive algorithm to build a lookup map for quickly finding\n   * potential CURIEs.\n   *\n   * @param iriMap the map to build.\n   * @param key the current key in the map to work on.\n   * @param idx the index into the IRI to compare.\n   */\n  function _buildIriMap(iriMap, key, idx) {\n    const entries = iriMap[key];\n    const next = iriMap[key] = {};\n\n    let iri;\n    let letter;\n    for(let i = 0; i < entries.length; ++i) {\n      iri = entries[i].iri;\n      if(idx >= iri.length) {\n        letter = '';\n      } else {\n        letter = iri[idx];\n      }\n      if(letter in next) {\n        next[letter].push(entries[i]);\n      } else {\n        next[letter] = [entries[i]];\n      }\n    }\n\n    for(const key in next) {\n      if(key === '') {\n        continue;\n      }\n      _buildIriMap(next, key, idx + 1);\n    }\n  }\n\n  /**\n   * Adds the term for the given entry if not already added.\n   *\n   * @param term the term to add.\n   * @param entry the inverse context typeOrLanguage entry to add to.\n   * @param typeOrLanguageValue the key in the entry to add to.\n   */\n  function _addPreferredTerm(term, entry, typeOrLanguageValue) {\n    if(!(typeOrLanguageValue in entry)) {\n      entry[typeOrLanguageValue] = term;\n    }\n  }\n\n  /**\n   * Clones an active context, creating a child active context.\n   *\n   * @return a clone (child) of the active context.\n   */\n  function _cloneActiveContext() {\n    const child = {};\n    child['@base'] = this['@base'];\n    child.mappings = util.clone(this.mappings);\n    child.clone = this.clone;\n    child.inverse = null;\n    child.getInverse = this.getInverse;\n    if('@language' in this) {\n      child['@language'] = this['@language'];\n    }\n    if('@vocab' in this) {\n      child['@vocab'] = this['@vocab'];\n    }\n    return child;\n  }\n};\n\n/**\n * Gets the value for the given active context key and type, null if none is\n * set.\n *\n * @param ctx the active context.\n * @param key the context key.\n * @param [type] the type of value to get (eg: '@id', '@type'), if not\n *          specified gets the entire entry for a key, null if not found.\n *\n * @return the value.\n */\napi.getContextValue = (ctx, key, type) => {\n  // return null for invalid key\n  if(key === null) {\n    return null;\n  }\n\n  // get specific entry information\n  if(ctx.mappings[key]) {\n    const entry = ctx.mappings[key];\n\n    if(_isUndefined(type)) {\n      // return whole entry\n      return entry;\n    }\n    if(type in entry) {\n      // return entry value for type\n      return entry[type];\n    }\n  }\n\n  // get default language\n  if(type === '@language' && (type in ctx)) {\n    return ctx[type];\n  }\n\n  return null;\n};\n\n/**\n * Retrieves external @context URLs using the given document loader. Every\n * instance of @context in the input that refers to a URL will be replaced\n * with the JSON @context found at that URL.\n *\n * @param input the JSON-LD input with possible contexts.\n * @param options the options to use:\n *          documentLoader(url, [callback(err, remoteDoc)]) the document loader.\n * @param callback(err, input) called once the operation completes.\n */\napi.getAllContexts = async (input, options) => {\n  return _retrieveContextUrls(input, options);\n};\n\n/**\n * Processing Mode check.\n *\n * @param activeCtx the current active context.\n * @param version the string or numeric version to check.\n *\n * @return boolean.\n */\napi.processingMode = (activeCtx, version) => {\n  if(version.toString() >= '1.1') {\n    return activeCtx.processingMode &&\n      activeCtx.processingMode >= 'json-ld-' + version.toString();\n  } else {\n    return !activeCtx.processingMode ||\n      activeCtx.processingMode === 'json-ld-1.0';\n  }\n};\n\n/**\n * Returns whether or not the given value is a keyword.\n *\n * @param v the value to check.\n *\n * @return true if the value is a keyword, false if not.\n */\napi.isKeyword = v => {\n  if(!_isString(v)) {\n    return false;\n  }\n  switch(v) {\n  case '@base':\n  case '@container':\n  case '@context':\n  case '@default':\n  case '@embed':\n  case '@explicit':\n  case '@graph':\n  case '@id':\n  case '@index':\n  case '@language':\n  case '@list':\n  case '@nest':\n  case '@none':\n  case '@omitDefault':\n  case '@prefix':\n  case '@preserve':\n  case '@requireAll':\n  case '@reverse':\n  case '@set':\n  case '@type':\n  case '@value':\n  case '@version':\n  case '@vocab':\n    return true;\n  }\n  return false;\n};\n\nasync function _retrieveContextUrls(input, options) {\n  const documentLoader = util.normalizeDocumentLoader(options.documentLoader);\n\n  // retrieve all @context URLs in input\n  const _urls = {};\n  await retrieve(input, {}, documentLoader);\n\n  return input;\n\n  // recursive function that will retrieve all @context URLs in documents\n  async function retrieve(doc, cycles, documentLoader) {\n    if(Object.keys(cycles).length > MAX_CONTEXT_URLS) {\n      throw new JsonLdError(\n        'Maximum number of @context URLs exceeded.',\n        'jsonld.ContextUrlError',\n        {code: 'loading remote context failed', max: MAX_CONTEXT_URLS});\n    }\n\n    // find all URLs in the given document, reusing already retrieved URLs\n    const urls = {};\n    Object.keys(_urls).forEach(url => {\n      if(_urls[url] !== false) {\n        urls[url] = _urls[url];\n      }\n    });\n    _findContextUrls(doc, urls, false, options.base);\n\n    // queue all unretrieved URLs\n    const queue = Object.keys(urls).filter(u => urls[u] === false);\n\n    // retrieve URLs in queue\n    return Promise.all(queue.map(async url => {\n      // check for context URL cycle\n      if(url in cycles) {\n        throw new JsonLdError(\n          'Cyclical @context URLs detected.',\n          'jsonld.ContextUrlError',\n          {code: 'recursive context inclusion', url: url});\n      }\n\n      const _cycles = util.clone(cycles);\n      _cycles[url] = true;\n      let remoteDoc;\n      let ctx;\n\n      try {\n        remoteDoc = await documentLoader(url);\n        ctx = remoteDoc.document || null;\n        // parse string context as JSON\n        if(_isString(ctx)) {\n          ctx = JSON.parse(ctx);\n        }\n      } catch(e) {\n        throw new JsonLdError(\n          'Dereferencing a URL did not result in a valid JSON-LD object. ' +\n          'Possible causes are an inaccessible URL perhaps due to ' +\n          'a same-origin policy (ensure the server uses CORS if you are ' +\n          'using client-side JavaScript), too many redirects, a ' +\n          'non-JSON response, or more than one HTTP Link Header was ' +\n          'provided for a remote context.',\n          'jsonld.InvalidUrl',\n          {code: 'loading remote context failed', url: url, cause: e});\n      }\n\n      // ensure ctx is an object\n      if(!_isObject(ctx)) {\n        throw new JsonLdError(\n          'Dereferencing a URL did not result in a JSON object. The ' +\n          'response was valid JSON, but it was not a JSON object.',\n          'jsonld.InvalidUrl',\n          {code: 'invalid remote context', url: url});\n      }\n\n      // use empty context if no @context key is present\n      if(!('@context' in ctx)) {\n        ctx = {'@context': {}};\n      } else {\n        ctx = {'@context': ctx['@context']};\n      }\n\n      // append @context URL to context if given\n      if(remoteDoc.contextUrl) {\n        if(!_isArray(ctx['@context'])) {\n          ctx['@context'] = [ctx['@context']];\n        }\n        ctx['@context'].push(remoteDoc.contextUrl);\n      }\n\n      // recurse\n      await retrieve(ctx, _cycles, documentLoader);\n\n      // store retrieved context w/replaced @context URLs\n      urls[url] = ctx['@context'];\n\n      // replace all @context URLs in the document\n      _findContextUrls(doc, urls, true, options.base);\n    }));\n  }\n}\n\n/**\n * Finds all @context URLs in the given JSON-LD input.\n *\n * @param input the JSON-LD input.\n * @param urls a map of URLs (url => false/@contexts).\n * @param replace true to replace the URLs in the given input with the\n *           @contexts from the urls map, false not to.\n * @param base the base IRI to use to resolve relative IRIs.\n *\n * @return true if new URLs to retrieve were found, false if not.\n */\nfunction _findContextUrls(input, urls, replace, base) {\n  if(_isArray(input)) {\n    for(let i = 0; i < input.length; ++i) {\n      _findContextUrls(input[i], urls, replace, base);\n    }\n    return;\n  }\n\n  if(!_isObject(input)) {\n    // no @context URLs can be found in non-object input\n    return;\n  }\n\n  // input is an object\n  for(const key in input) {\n    if(key !== '@context') {\n      _findContextUrls(input[key], urls, replace, base);\n      continue;\n    }\n\n    // get @context\n    let ctx = input[key];\n\n    if(_isArray(ctx)) {\n      // array @context\n      let length = ctx.length;\n      for(let i = 0; i < length; ++i) {\n        let _ctx = ctx[i];\n        if(_isString(_ctx)) {\n          _ctx = prependBase(base, _ctx);\n          // replace w/@context if requested\n          if(replace) {\n            if(urls[_ctx] !== false) {\n              _ctx = urls[_ctx];\n              if(_isArray(_ctx)) {\n                // add flattened context\n                Array.prototype.splice.apply(ctx, [i, 1].concat(_ctx));\n                i += _ctx.length - 1;\n                length = ctx.length;\n              } else {\n                ctx[i] = _ctx;\n              }\n            }\n          } else if(!(_ctx in urls)) {\n            // @context URL found\n            urls[_ctx] = false;\n          }\n        } else {\n          // look for scoped context\n          for(const key in _ctx) {\n            if(_isObject(_ctx[key])) {\n              _findContextUrls(_ctx[key], urls, replace, base);\n            }\n          }\n        }\n      }\n    } else if(_isString(ctx)) {\n      // string @context\n      ctx = prependBase(base, ctx);\n      // replace w/@context if requested\n      if(replace) {\n        if(urls[ctx] !== false) {\n          input[key] = urls[ctx];\n        }\n      } else if(!(ctx in urls)) {\n        // @context URL found\n        urls[ctx] = false;\n      }\n    } else {\n      // look for scoped context\n      for(const key in ctx) {\n        if(_isObject(ctx[key])) {\n          _findContextUrls(ctx[key], urls, replace, base);\n        }\n      }\n    }\n  }\n}\n","/*! *****************************************************************************\r\nCopyright (c) Microsoft Corporation. All rights reserved.\r\nLicensed under the Apache License, Version 2.0 (the \"License\"); you may not use\r\nthis file except in compliance with the License. You may obtain a copy of the\r\nLicense at http://www.apache.org/licenses/LICENSE-2.0\r\n\r\nTHIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\nKIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED\r\nWARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,\r\nMERCHANTABLITY OR NON-INFRINGEMENT.\r\n\r\nSee the Apache Version 2.0 License for specific language governing permissions\r\nand limitations under the License.\r\n***************************************************************************** */\r\n/* global Reflect, Promise */\r\n\r\nvar extendStatics = function(d, b) {\r\n    extendStatics = Object.setPrototypeOf ||\r\n        ({ __proto__: [] } instanceof Array && function (d, b) { d.__proto__ = b; }) ||\r\n        function (d, b) { for (var p in b) if (b.hasOwnProperty(p)) d[p] = b[p]; };\r\n    return extendStatics(d, b);\r\n};\r\n\r\nexport function __extends(d, b) {\r\n    extendStatics(d, b);\r\n    function __() { this.constructor = d; }\r\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\r\n}\r\n\r\nexport var __assign = function() {\r\n    __assign = Object.assign || function __assign(t) {\r\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\r\n            s = arguments[i];\r\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\r\n        }\r\n        return t;\r\n    }\r\n    return __assign.apply(this, arguments);\r\n}\r\n\r\nexport function __rest(s, e) {\r\n    var t = {};\r\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\r\n        t[p] = s[p];\r\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\r\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) if (e.indexOf(p[i]) < 0)\r\n            t[p[i]] = s[p[i]];\r\n    return t;\r\n}\r\n\r\nexport function __decorate(decorators, target, key, desc) {\r\n    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;\r\n    if (typeof Reflect === \"object\" && typeof Reflect.decorate === \"function\") r = Reflect.decorate(decorators, target, key, desc);\r\n    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\r\n    return c > 3 && r && Object.defineProperty(target, key, r), r;\r\n}\r\n\r\nexport function __param(paramIndex, decorator) {\r\n    return function (target, key) { decorator(target, key, paramIndex); }\r\n}\r\n\r\nexport function __metadata(metadataKey, metadataValue) {\r\n    if (typeof Reflect === \"object\" && typeof Reflect.metadata === \"function\") return Reflect.metadata(metadataKey, metadataValue);\r\n}\r\n\r\nexport function __awaiter(thisArg, _arguments, P, generator) {\r\n    return new (P || (P = Promise))(function (resolve, reject) {\r\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\r\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\r\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\r\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\r\n    });\r\n}\r\n\r\nexport function __generator(thisArg, body) {\r\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\r\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\r\n    function verb(n) { return function (v) { return step([n, v]); }; }\r\n    function step(op) {\r\n        if (f) throw new TypeError(\"Generator is already executing.\");\r\n        while (_) try {\r\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\r\n            if (y = 0, t) op = [op[0] & 2, t.value];\r\n            switch (op[0]) {\r\n                case 0: case 1: t = op; break;\r\n                case 4: _.label++; return { value: op[1], done: false };\r\n                case 5: _.label++; y = op[1]; op = [0]; continue;\r\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\r\n                default:\r\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\r\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\r\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\r\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\r\n                    if (t[2]) _.ops.pop();\r\n                    _.trys.pop(); continue;\r\n            }\r\n            op = body.call(thisArg, _);\r\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\r\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\r\n    }\r\n}\r\n\r\nexport function __exportStar(m, exports) {\r\n    for (var p in m) if (!exports.hasOwnProperty(p)) exports[p] = m[p];\r\n}\r\n\r\nexport function __values(o) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator], i = 0;\r\n    if (m) return m.call(o);\r\n    return {\r\n        next: function () {\r\n            if (o && i >= o.length) o = void 0;\r\n            return { value: o && o[i++], done: !o };\r\n        }\r\n    };\r\n}\r\n\r\nexport function __read(o, n) {\r\n    var m = typeof Symbol === \"function\" && o[Symbol.iterator];\r\n    if (!m) return o;\r\n    var i = m.call(o), r, ar = [], e;\r\n    try {\r\n        while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);\r\n    }\r\n    catch (error) { e = { error: error }; }\r\n    finally {\r\n        try {\r\n            if (r && !r.done && (m = i[\"return\"])) m.call(i);\r\n        }\r\n        finally { if (e) throw e.error; }\r\n    }\r\n    return ar;\r\n}\r\n\r\nexport function __spread() {\r\n    for (var ar = [], i = 0; i < arguments.length; i++)\r\n        ar = ar.concat(__read(arguments[i]));\r\n    return ar;\r\n}\r\n\r\nexport function __await(v) {\r\n    return this instanceof __await ? (this.v = v, this) : new __await(v);\r\n}\r\n\r\nexport function __asyncGenerator(thisArg, _arguments, generator) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var g = generator.apply(thisArg, _arguments || []), i, q = [];\r\n    return i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i;\r\n    function verb(n) { if (g[n]) i[n] = function (v) { return new Promise(function (a, b) { q.push([n, v, a, b]) > 1 || resume(n, v); }); }; }\r\n    function resume(n, v) { try { step(g[n](v)); } catch (e) { settle(q[0][3], e); } }\r\n    function step(r) { r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r); }\r\n    function fulfill(value) { resume(\"next\", value); }\r\n    function reject(value) { resume(\"throw\", value); }\r\n    function settle(f, v) { if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]); }\r\n}\r\n\r\nexport function __asyncDelegator(o) {\r\n    var i, p;\r\n    return i = {}, verb(\"next\"), verb(\"throw\", function (e) { throw e; }), verb(\"return\"), i[Symbol.iterator] = function () { return this; }, i;\r\n    function verb(n, f) { i[n] = o[n] ? function (v) { return (p = !p) ? { value: __await(o[n](v)), done: n === \"return\" } : f ? f(v) : v; } : f; }\r\n}\r\n\r\nexport function __asyncValues(o) {\r\n    if (!Symbol.asyncIterator) throw new TypeError(\"Symbol.asyncIterator is not defined.\");\r\n    var m = o[Symbol.asyncIterator], i;\r\n    return m ? m.call(o) : (o = typeof __values === \"function\" ? __values(o) : o[Symbol.iterator](), i = {}, verb(\"next\"), verb(\"throw\"), verb(\"return\"), i[Symbol.asyncIterator] = function () { return this; }, i);\r\n    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }\r\n    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }\r\n}\r\n\r\nexport function __makeTemplateObject(cooked, raw) {\r\n    if (Object.defineProperty) { Object.defineProperty(cooked, \"raw\", { value: raw }); } else { cooked.raw = raw; }\r\n    return cooked;\r\n};\r\n\r\nexport function __importStar(mod) {\r\n    if (mod && mod.__esModule) return mod;\r\n    var result = {};\r\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\r\n    result.default = mod;\r\n    return result;\r\n}\r\n\r\nexport function __importDefault(mod) {\r\n    return (mod && mod.__esModule) ? mod : { default: mod };\r\n}\r\n","/*!\n * @overview es6-promise - a tiny implementation of Promises/A+.\n * @copyright Copyright (c) 2014 Yehuda Katz, Tom Dale, Stefan Penner and contributors (Conversion to ES6 API by Jake Archibald)\n * @license   Licensed under MIT license\n *            See https://raw.githubusercontent.com/jakearchibald/es6-promise/master/LICENSE\n * @version   2.3.0\n */\n\n(function() {\n    \"use strict\";\n    function lib$es6$promise$utils$$objectOrFunction(x) {\n      return typeof x === 'function' || (typeof x === 'object' && x !== null);\n    }\n\n    function lib$es6$promise$utils$$isFunction(x) {\n      return typeof x === 'function';\n    }\n\n    function lib$es6$promise$utils$$isMaybeThenable(x) {\n      return typeof x === 'object' && x !== null;\n    }\n\n    var lib$es6$promise$utils$$_isArray;\n    if (!Array.isArray) {\n      lib$es6$promise$utils$$_isArray = function (x) {\n        return Object.prototype.toString.call(x) === '[object Array]';\n      };\n    } else {\n      lib$es6$promise$utils$$_isArray = Array.isArray;\n    }\n\n    var lib$es6$promise$utils$$isArray = lib$es6$promise$utils$$_isArray;\n    var lib$es6$promise$asap$$len = 0;\n    var lib$es6$promise$asap$$toString = {}.toString;\n    var lib$es6$promise$asap$$vertxNext;\n    var lib$es6$promise$asap$$customSchedulerFn;\n\n    var lib$es6$promise$asap$$asap = function asap(callback, arg) {\n      lib$es6$promise$asap$$queue[lib$es6$promise$asap$$len] = callback;\n      lib$es6$promise$asap$$queue[lib$es6$promise$asap$$len + 1] = arg;\n      lib$es6$promise$asap$$len += 2;\n      if (lib$es6$promise$asap$$len === 2) {\n        // If len is 2, that means that we need to schedule an async flush.\n        // If additional callbacks are queued before the queue is flushed, they\n        // will be processed by this flush that we are scheduling.\n        if (lib$es6$promise$asap$$customSchedulerFn) {\n          lib$es6$promise$asap$$customSchedulerFn(lib$es6$promise$asap$$flush);\n        } else {\n          lib$es6$promise$asap$$scheduleFlush();\n        }\n      }\n    }\n\n    function lib$es6$promise$asap$$setScheduler(scheduleFn) {\n      lib$es6$promise$asap$$customSchedulerFn = scheduleFn;\n    }\n\n    function lib$es6$promise$asap$$setAsap(asapFn) {\n      lib$es6$promise$asap$$asap = asapFn;\n    }\n\n    var lib$es6$promise$asap$$browserWindow = (typeof window !== 'undefined') ? window : undefined;\n    var lib$es6$promise$asap$$browserGlobal = lib$es6$promise$asap$$browserWindow || {};\n    var lib$es6$promise$asap$$BrowserMutationObserver = lib$es6$promise$asap$$browserGlobal.MutationObserver || lib$es6$promise$asap$$browserGlobal.WebKitMutationObserver;\n    var lib$es6$promise$asap$$isNode = typeof process !== 'undefined' && {}.toString.call(process) === '[object process]';\n\n    // test for web worker but not in IE10\n    var lib$es6$promise$asap$$isWorker = typeof Uint8ClampedArray !== 'undefined' &&\n      typeof importScripts !== 'undefined' &&\n      typeof MessageChannel !== 'undefined';\n\n    // node\n    function lib$es6$promise$asap$$useNextTick() {\n      var nextTick = process.nextTick;\n      // node version 0.10.x displays a deprecation warning when nextTick is used recursively\n      // setImmediate should be used instead instead\n      var version = process.versions.node.match(/^(?:(\\d+)\\.)?(?:(\\d+)\\.)?(\\*|\\d+)$/);\n      if (Array.isArray(version) && version[1] === '0' && version[2] === '10') {\n        nextTick = setImmediate;\n      }\n      return function() {\n        nextTick(lib$es6$promise$asap$$flush);\n      };\n    }\n\n    // vertx\n    function lib$es6$promise$asap$$useVertxTimer() {\n      return function() {\n        lib$es6$promise$asap$$vertxNext(lib$es6$promise$asap$$flush);\n      };\n    }\n\n    function lib$es6$promise$asap$$useMutationObserver() {\n      var iterations = 0;\n      var observer = new lib$es6$promise$asap$$BrowserMutationObserver(lib$es6$promise$asap$$flush);\n      var node = document.createTextNode('');\n      observer.observe(node, { characterData: true });\n\n      return function() {\n        node.data = (iterations = ++iterations % 2);\n      };\n    }\n\n    // web worker\n    function lib$es6$promise$asap$$useMessageChannel() {\n      var channel = new MessageChannel();\n      channel.port1.onmessage = lib$es6$promise$asap$$flush;\n      return function () {\n        channel.port2.postMessage(0);\n      };\n    }\n\n    function lib$es6$promise$asap$$useSetTimeout() {\n      return function() {\n        setTimeout(lib$es6$promise$asap$$flush, 1);\n      };\n    }\n\n    var lib$es6$promise$asap$$queue = new Array(1000);\n    function lib$es6$promise$asap$$flush() {\n      for (var i = 0; i < lib$es6$promise$asap$$len; i+=2) {\n        var callback = lib$es6$promise$asap$$queue[i];\n        var arg = lib$es6$promise$asap$$queue[i+1];\n\n        callback(arg);\n\n        lib$es6$promise$asap$$queue[i] = undefined;\n        lib$es6$promise$asap$$queue[i+1] = undefined;\n      }\n\n      lib$es6$promise$asap$$len = 0;\n    }\n\n    function lib$es6$promise$asap$$attemptVertex() {\n      try {\n        var r = require;\n        var vertx = r('vertx');\n        lib$es6$promise$asap$$vertxNext = vertx.runOnLoop || vertx.runOnContext;\n        return lib$es6$promise$asap$$useVertxTimer();\n      } catch(e) {\n        return lib$es6$promise$asap$$useSetTimeout();\n      }\n    }\n\n    var lib$es6$promise$asap$$scheduleFlush;\n    // Decide what async method to use to triggering processing of queued callbacks:\n    if (lib$es6$promise$asap$$isNode) {\n      lib$es6$promise$asap$$scheduleFlush = lib$es6$promise$asap$$useNextTick();\n    } else if (lib$es6$promise$asap$$BrowserMutationObserver) {\n      lib$es6$promise$asap$$scheduleFlush = lib$es6$promise$asap$$useMutationObserver();\n    } else if (lib$es6$promise$asap$$isWorker) {\n      lib$es6$promise$asap$$scheduleFlush = lib$es6$promise$asap$$useMessageChannel();\n    } else if (lib$es6$promise$asap$$browserWindow === undefined && typeof require === 'function') {\n      lib$es6$promise$asap$$scheduleFlush = lib$es6$promise$asap$$attemptVertex();\n    } else {\n      lib$es6$promise$asap$$scheduleFlush = lib$es6$promise$asap$$useSetTimeout();\n    }\n\n    function lib$es6$promise$$internal$$noop() {}\n\n    var lib$es6$promise$$internal$$PENDING   = void 0;\n    var lib$es6$promise$$internal$$FULFILLED = 1;\n    var lib$es6$promise$$internal$$REJECTED  = 2;\n\n    var lib$es6$promise$$internal$$GET_THEN_ERROR = new lib$es6$promise$$internal$$ErrorObject();\n\n    function lib$es6$promise$$internal$$selfFullfillment() {\n      return new TypeError(\"You cannot resolve a promise with itself\");\n    }\n\n    function lib$es6$promise$$internal$$cannotReturnOwn() {\n      return new TypeError('A promises callback cannot return that same promise.');\n    }\n\n    function lib$es6$promise$$internal$$getThen(promise) {\n      try {\n        return promise.then;\n      } catch(error) {\n        lib$es6$promise$$internal$$GET_THEN_ERROR.error = error;\n        return lib$es6$promise$$internal$$GET_THEN_ERROR;\n      }\n    }\n\n    function lib$es6$promise$$internal$$tryThen(then, value, fulfillmentHandler, rejectionHandler) {\n      try {\n        then.call(value, fulfillmentHandler, rejectionHandler);\n      } catch(e) {\n        return e;\n      }\n    }\n\n    function lib$es6$promise$$internal$$handleForeignThenable(promise, thenable, then) {\n       lib$es6$promise$asap$$asap(function(promise) {\n        var sealed = false;\n        var error = lib$es6$promise$$internal$$tryThen(then, thenable, function(value) {\n          if (sealed) { return; }\n          sealed = true;\n          if (thenable !== value) {\n            lib$es6$promise$$internal$$resolve(promise, value);\n          } else {\n            lib$es6$promise$$internal$$fulfill(promise, value);\n          }\n        }, function(reason) {\n          if (sealed) { return; }\n          sealed = true;\n\n          lib$es6$promise$$internal$$reject(promise, reason);\n        }, 'Settle: ' + (promise._label || ' unknown promise'));\n\n        if (!sealed && error) {\n          sealed = true;\n          lib$es6$promise$$internal$$reject(promise, error);\n        }\n      }, promise);\n    }\n\n    function lib$es6$promise$$internal$$handleOwnThenable(promise, thenable) {\n      if (thenable._state === lib$es6$promise$$internal$$FULFILLED) {\n        lib$es6$promise$$internal$$fulfill(promise, thenable._result);\n      } else if (thenable._state === lib$es6$promise$$internal$$REJECTED) {\n        lib$es6$promise$$internal$$reject(promise, thenable._result);\n      } else {\n        lib$es6$promise$$internal$$subscribe(thenable, undefined, function(value) {\n          lib$es6$promise$$internal$$resolve(promise, value);\n        }, function(reason) {\n          lib$es6$promise$$internal$$reject(promise, reason);\n        });\n      }\n    }\n\n    function lib$es6$promise$$internal$$handleMaybeThenable(promise, maybeThenable) {\n      if (maybeThenable.constructor === promise.constructor) {\n        lib$es6$promise$$internal$$handleOwnThenable(promise, maybeThenable);\n      } else {\n        var then = lib$es6$promise$$internal$$getThen(maybeThenable);\n\n        if (then === lib$es6$promise$$internal$$GET_THEN_ERROR) {\n          lib$es6$promise$$internal$$reject(promise, lib$es6$promise$$internal$$GET_THEN_ERROR.error);\n        } else if (then === undefined) {\n          lib$es6$promise$$internal$$fulfill(promise, maybeThenable);\n        } else if (lib$es6$promise$utils$$isFunction(then)) {\n          lib$es6$promise$$internal$$handleForeignThenable(promise, maybeThenable, then);\n        } else {\n          lib$es6$promise$$internal$$fulfill(promise, maybeThenable);\n        }\n      }\n    }\n\n    function lib$es6$promise$$internal$$resolve(promise, value) {\n      if (promise === value) {\n        lib$es6$promise$$internal$$reject(promise, lib$es6$promise$$internal$$selfFullfillment());\n      } else if (lib$es6$promise$utils$$objectOrFunction(value)) {\n        lib$es6$promise$$internal$$handleMaybeThenable(promise, value);\n      } else {\n        lib$es6$promise$$internal$$fulfill(promise, value);\n      }\n    }\n\n    function lib$es6$promise$$internal$$publishRejection(promise) {\n      if (promise._onerror) {\n        promise._onerror(promise._result);\n      }\n\n      lib$es6$promise$$internal$$publish(promise);\n    }\n\n    function lib$es6$promise$$internal$$fulfill(promise, value) {\n      if (promise._state !== lib$es6$promise$$internal$$PENDING) { return; }\n\n      promise._result = value;\n      promise._state = lib$es6$promise$$internal$$FULFILLED;\n\n      if (promise._subscribers.length !== 0) {\n        lib$es6$promise$asap$$asap(lib$es6$promise$$internal$$publish, promise);\n      }\n    }\n\n    function lib$es6$promise$$internal$$reject(promise, reason) {\n      if (promise._state !== lib$es6$promise$$internal$$PENDING) { return; }\n      promise._state = lib$es6$promise$$internal$$REJECTED;\n      promise._result = reason;\n\n      lib$es6$promise$asap$$asap(lib$es6$promise$$internal$$publishRejection, promise);\n    }\n\n    function lib$es6$promise$$internal$$subscribe(parent, child, onFulfillment, onRejection) {\n      var subscribers = parent._subscribers;\n      var length = subscribers.length;\n\n      parent._onerror = null;\n\n      subscribers[length] = child;\n      subscribers[length + lib$es6$promise$$internal$$FULFILLED] = onFulfillment;\n      subscribers[length + lib$es6$promise$$internal$$REJECTED]  = onRejection;\n\n      if (length === 0 && parent._state) {\n        lib$es6$promise$asap$$asap(lib$es6$promise$$internal$$publish, parent);\n      }\n    }\n\n    function lib$es6$promise$$internal$$publish(promise) {\n      var subscribers = promise._subscribers;\n      var settled = promise._state;\n\n      if (subscribers.length === 0) { return; }\n\n      var child, callback, detail = promise._result;\n\n      for (var i = 0; i < subscribers.length; i += 3) {\n        child = subscribers[i];\n        callback = subscribers[i + settled];\n\n        if (child) {\n          lib$es6$promise$$internal$$invokeCallback(settled, child, callback, detail);\n        } else {\n          callback(detail);\n        }\n      }\n\n      promise._subscribers.length = 0;\n    }\n\n    function lib$es6$promise$$internal$$ErrorObject() {\n      this.error = null;\n    }\n\n    var lib$es6$promise$$internal$$TRY_CATCH_ERROR = new lib$es6$promise$$internal$$ErrorObject();\n\n    function lib$es6$promise$$internal$$tryCatch(callback, detail) {\n      try {\n        return callback(detail);\n      } catch(e) {\n        lib$es6$promise$$internal$$TRY_CATCH_ERROR.error = e;\n        return lib$es6$promise$$internal$$TRY_CATCH_ERROR;\n      }\n    }\n\n    function lib$es6$promise$$internal$$invokeCallback(settled, promise, callback, detail) {\n      var hasCallback = lib$es6$promise$utils$$isFunction(callback),\n          value, error, succeeded, failed;\n\n      if (hasCallback) {\n        value = lib$es6$promise$$internal$$tryCatch(callback, detail);\n\n        if (value === lib$es6$promise$$internal$$TRY_CATCH_ERROR) {\n          failed = true;\n          error = value.error;\n          value = null;\n        } else {\n          succeeded = true;\n        }\n\n        if (promise === value) {\n          lib$es6$promise$$internal$$reject(promise, lib$es6$promise$$internal$$cannotReturnOwn());\n          return;\n        }\n\n      } else {\n        value = detail;\n        succeeded = true;\n      }\n\n      if (promise._state !== lib$es6$promise$$internal$$PENDING) {\n        // noop\n      } else if (hasCallback && succeeded) {\n        lib$es6$promise$$internal$$resolve(promise, value);\n      } else if (failed) {\n        lib$es6$promise$$internal$$reject(promise, error);\n      } else if (settled === lib$es6$promise$$internal$$FULFILLED) {\n        lib$es6$promise$$internal$$fulfill(promise, value);\n      } else if (settled === lib$es6$promise$$internal$$REJECTED) {\n        lib$es6$promise$$internal$$reject(promise, value);\n      }\n    }\n\n    function lib$es6$promise$$internal$$initializePromise(promise, resolver) {\n      try {\n        resolver(function resolvePromise(value){\n          lib$es6$promise$$internal$$resolve(promise, value);\n        }, function rejectPromise(reason) {\n          lib$es6$promise$$internal$$reject(promise, reason);\n        });\n      } catch(e) {\n        lib$es6$promise$$internal$$reject(promise, e);\n      }\n    }\n\n    function lib$es6$promise$enumerator$$Enumerator(Constructor, input) {\n      var enumerator = this;\n\n      enumerator._instanceConstructor = Constructor;\n      enumerator.promise = new Constructor(lib$es6$promise$$internal$$noop);\n\n      if (enumerator._validateInput(input)) {\n        enumerator._input     = input;\n        enumerator.length     = input.length;\n        enumerator._remaining = input.length;\n\n        enumerator._init();\n\n        if (enumerator.length === 0) {\n          lib$es6$promise$$internal$$fulfill(enumerator.promise, enumerator._result);\n        } else {\n          enumerator.length = enumerator.length || 0;\n          enumerator._enumerate();\n          if (enumerator._remaining === 0) {\n            lib$es6$promise$$internal$$fulfill(enumerator.promise, enumerator._result);\n          }\n        }\n      } else {\n        lib$es6$promise$$internal$$reject(enumerator.promise, enumerator._validationError());\n      }\n    }\n\n    lib$es6$promise$enumerator$$Enumerator.prototype._validateInput = function(input) {\n      return lib$es6$promise$utils$$isArray(input);\n    };\n\n    lib$es6$promise$enumerator$$Enumerator.prototype._validationError = function() {\n      return new Error('Array Methods must be provided an Array');\n    };\n\n    lib$es6$promise$enumerator$$Enumerator.prototype._init = function() {\n      this._result = new Array(this.length);\n    };\n\n    var lib$es6$promise$enumerator$$default = lib$es6$promise$enumerator$$Enumerator;\n\n    lib$es6$promise$enumerator$$Enumerator.prototype._enumerate = function() {\n      var enumerator = this;\n\n      var length  = enumerator.length;\n      var promise = enumerator.promise;\n      var input   = enumerator._input;\n\n      for (var i = 0; promise._state === lib$es6$promise$$internal$$PENDING && i < length; i++) {\n        enumerator._eachEntry(input[i], i);\n      }\n    };\n\n    lib$es6$promise$enumerator$$Enumerator.prototype._eachEntry = function(entry, i) {\n      var enumerator = this;\n      var c = enumerator._instanceConstructor;\n\n      if (lib$es6$promise$utils$$isMaybeThenable(entry)) {\n        if (entry.constructor === c && entry._state !== lib$es6$promise$$internal$$PENDING) {\n          entry._onerror = null;\n          enumerator._settledAt(entry._state, i, entry._result);\n        } else {\n          enumerator._willSettleAt(c.resolve(entry), i);\n        }\n      } else {\n        enumerator._remaining--;\n        enumerator._result[i] = entry;\n      }\n    };\n\n    lib$es6$promise$enumerator$$Enumerator.prototype._settledAt = function(state, i, value) {\n      var enumerator = this;\n      var promise = enumerator.promise;\n\n      if (promise._state === lib$es6$promise$$internal$$PENDING) {\n        enumerator._remaining--;\n\n        if (state === lib$es6$promise$$internal$$REJECTED) {\n          lib$es6$promise$$internal$$reject(promise, value);\n        } else {\n          enumerator._result[i] = value;\n        }\n      }\n\n      if (enumerator._remaining === 0) {\n        lib$es6$promise$$internal$$fulfill(promise, enumerator._result);\n      }\n    };\n\n    lib$es6$promise$enumerator$$Enumerator.prototype._willSettleAt = function(promise, i) {\n      var enumerator = this;\n\n      lib$es6$promise$$internal$$subscribe(promise, undefined, function(value) {\n        enumerator._settledAt(lib$es6$promise$$internal$$FULFILLED, i, value);\n      }, function(reason) {\n        enumerator._settledAt(lib$es6$promise$$internal$$REJECTED, i, reason);\n      });\n    };\n    function lib$es6$promise$promise$all$$all(entries) {\n      return new lib$es6$promise$enumerator$$default(this, entries).promise;\n    }\n    var lib$es6$promise$promise$all$$default = lib$es6$promise$promise$all$$all;\n    function lib$es6$promise$promise$race$$race(entries) {\n      /*jshint validthis:true */\n      var Constructor = this;\n\n      var promise = new Constructor(lib$es6$promise$$internal$$noop);\n\n      if (!lib$es6$promise$utils$$isArray(entries)) {\n        lib$es6$promise$$internal$$reject(promise, new TypeError('You must pass an array to race.'));\n        return promise;\n      }\n\n      var length = entries.length;\n\n      function onFulfillment(value) {\n        lib$es6$promise$$internal$$resolve(promise, value);\n      }\n\n      function onRejection(reason) {\n        lib$es6$promise$$internal$$reject(promise, reason);\n      }\n\n      for (var i = 0; promise._state === lib$es6$promise$$internal$$PENDING && i < length; i++) {\n        lib$es6$promise$$internal$$subscribe(Constructor.resolve(entries[i]), undefined, onFulfillment, onRejection);\n      }\n\n      return promise;\n    }\n    var lib$es6$promise$promise$race$$default = lib$es6$promise$promise$race$$race;\n    function lib$es6$promise$promise$resolve$$resolve(object) {\n      /*jshint validthis:true */\n      var Constructor = this;\n\n      if (object && typeof object === 'object' && object.constructor === Constructor) {\n        return object;\n      }\n\n      var promise = new Constructor(lib$es6$promise$$internal$$noop);\n      lib$es6$promise$$internal$$resolve(promise, object);\n      return promise;\n    }\n    var lib$es6$promise$promise$resolve$$default = lib$es6$promise$promise$resolve$$resolve;\n    function lib$es6$promise$promise$reject$$reject(reason) {\n      /*jshint validthis:true */\n      var Constructor = this;\n      var promise = new Constructor(lib$es6$promise$$internal$$noop);\n      lib$es6$promise$$internal$$reject(promise, reason);\n      return promise;\n    }\n    var lib$es6$promise$promise$reject$$default = lib$es6$promise$promise$reject$$reject;\n\n    var lib$es6$promise$promise$$counter = 0;\n\n    function lib$es6$promise$promise$$needsResolver() {\n      throw new TypeError('You must pass a resolver function as the first argument to the promise constructor');\n    }\n\n    function lib$es6$promise$promise$$needsNew() {\n      throw new TypeError(\"Failed to construct 'Promise': Please use the 'new' operator, this object constructor cannot be called as a function.\");\n    }\n\n    var lib$es6$promise$promise$$default = lib$es6$promise$promise$$Promise;\n    /**\n      Promise objects represent the eventual result of an asynchronous operation. The\n      primary way of interacting with a promise is through its `then` method, which\n      registers callbacks to receive either a promise's eventual value or the reason\n      why the promise cannot be fulfilled.\n\n      Terminology\n      -----------\n\n      - `promise` is an object or function with a `then` method whose behavior conforms to this specification.\n      - `thenable` is an object or function that defines a `then` method.\n      - `value` is any legal JavaScript value (including undefined, a thenable, or a promise).\n      - `exception` is a value that is thrown using the throw statement.\n      - `reason` is a value that indicates why a promise was rejected.\n      - `settled` the final resting state of a promise, fulfilled or rejected.\n\n      A promise can be in one of three states: pending, fulfilled, or rejected.\n\n      Promises that are fulfilled have a fulfillment value and are in the fulfilled\n      state.  Promises that are rejected have a rejection reason and are in the\n      rejected state.  A fulfillment value is never a thenable.\n\n      Promises can also be said to *resolve* a value.  If this value is also a\n      promise, then the original promise's settled state will match the value's\n      settled state.  So a promise that *resolves* a promise that rejects will\n      itself reject, and a promise that *resolves* a promise that fulfills will\n      itself fulfill.\n\n\n      Basic Usage:\n      ------------\n\n      ```js\n      var promise = new Promise(function(resolve, reject) {\n        // on success\n        resolve(value);\n\n        // on failure\n        reject(reason);\n      });\n\n      promise.then(function(value) {\n        // on fulfillment\n      }, function(reason) {\n        // on rejection\n      });\n      ```\n\n      Advanced Usage:\n      ---------------\n\n      Promises shine when abstracting away asynchronous interactions such as\n      `XMLHttpRequest`s.\n\n      ```js\n      function getJSON(url) {\n        return new Promise(function(resolve, reject){\n          var xhr = new XMLHttpRequest();\n\n          xhr.open('GET', url);\n          xhr.onreadystatechange = handler;\n          xhr.responseType = 'json';\n          xhr.setRequestHeader('Accept', 'application/json');\n          xhr.send();\n\n          function handler() {\n            if (this.readyState === this.DONE) {\n              if (this.status === 200) {\n                resolve(this.response);\n              } else {\n                reject(new Error('getJSON: `' + url + '` failed with status: [' + this.status + ']'));\n              }\n            }\n          };\n        });\n      }\n\n      getJSON('/posts.json').then(function(json) {\n        // on fulfillment\n      }, function(reason) {\n        // on rejection\n      });\n      ```\n\n      Unlike callbacks, promises are great composable primitives.\n\n      ```js\n      Promise.all([\n        getJSON('/posts'),\n        getJSON('/comments')\n      ]).then(function(values){\n        values[0] // => postsJSON\n        values[1] // => commentsJSON\n\n        return values;\n      });\n      ```\n\n      @class Promise\n      @param {function} resolver\n      Useful for tooling.\n      @constructor\n    */\n    function lib$es6$promise$promise$$Promise(resolver) {\n      this._id = lib$es6$promise$promise$$counter++;\n      this._state = undefined;\n      this._result = undefined;\n      this._subscribers = [];\n\n      if (lib$es6$promise$$internal$$noop !== resolver) {\n        if (!lib$es6$promise$utils$$isFunction(resolver)) {\n          lib$es6$promise$promise$$needsResolver();\n        }\n\n        if (!(this instanceof lib$es6$promise$promise$$Promise)) {\n          lib$es6$promise$promise$$needsNew();\n        }\n\n        lib$es6$promise$$internal$$initializePromise(this, resolver);\n      }\n    }\n\n    lib$es6$promise$promise$$Promise.all = lib$es6$promise$promise$all$$default;\n    lib$es6$promise$promise$$Promise.race = lib$es6$promise$promise$race$$default;\n    lib$es6$promise$promise$$Promise.resolve = lib$es6$promise$promise$resolve$$default;\n    lib$es6$promise$promise$$Promise.reject = lib$es6$promise$promise$reject$$default;\n    lib$es6$promise$promise$$Promise._setScheduler = lib$es6$promise$asap$$setScheduler;\n    lib$es6$promise$promise$$Promise._setAsap = lib$es6$promise$asap$$setAsap;\n    lib$es6$promise$promise$$Promise._asap = lib$es6$promise$asap$$asap;\n\n    lib$es6$promise$promise$$Promise.prototype = {\n      constructor: lib$es6$promise$promise$$Promise,\n\n    /**\n      The primary way of interacting with a promise is through its `then` method,\n      which registers callbacks to receive either a promise's eventual value or the\n      reason why the promise cannot be fulfilled.\n\n      ```js\n      findUser().then(function(user){\n        // user is available\n      }, function(reason){\n        // user is unavailable, and you are given the reason why\n      });\n      ```\n\n      Chaining\n      --------\n\n      The return value of `then` is itself a promise.  This second, 'downstream'\n      promise is resolved with the return value of the first promise's fulfillment\n      or rejection handler, or rejected if the handler throws an exception.\n\n      ```js\n      findUser().then(function (user) {\n        return user.name;\n      }, function (reason) {\n        return 'default name';\n      }).then(function (userName) {\n        // If `findUser` fulfilled, `userName` will be the user's name, otherwise it\n        // will be `'default name'`\n      });\n\n      findUser().then(function (user) {\n        throw new Error('Found user, but still unhappy');\n      }, function (reason) {\n        throw new Error('`findUser` rejected and we're unhappy');\n      }).then(function (value) {\n        // never reached\n      }, function (reason) {\n        // if `findUser` fulfilled, `reason` will be 'Found user, but still unhappy'.\n        // If `findUser` rejected, `reason` will be '`findUser` rejected and we're unhappy'.\n      });\n      ```\n      If the downstream promise does not specify a rejection handler, rejection reasons will be propagated further downstream.\n\n      ```js\n      findUser().then(function (user) {\n        throw new PedagogicalException('Upstream error');\n      }).then(function (value) {\n        // never reached\n      }).then(function (value) {\n        // never reached\n      }, function (reason) {\n        // The `PedgagocialException` is propagated all the way down to here\n      });\n      ```\n\n      Assimilation\n      ------------\n\n      Sometimes the value you want to propagate to a downstream promise can only be\n      retrieved asynchronously. This can be achieved by returning a promise in the\n      fulfillment or rejection handler. The downstream promise will then be pending\n      until the returned promise is settled. This is called *assimilation*.\n\n      ```js\n      findUser().then(function (user) {\n        return findCommentsByAuthor(user);\n      }).then(function (comments) {\n        // The user's comments are now available\n      });\n      ```\n\n      If the assimliated promise rejects, then the downstream promise will also reject.\n\n      ```js\n      findUser().then(function (user) {\n        return findCommentsByAuthor(user);\n      }).then(function (comments) {\n        // If `findCommentsByAuthor` fulfills, we'll have the value here\n      }, function (reason) {\n        // If `findCommentsByAuthor` rejects, we'll have the reason here\n      });\n      ```\n\n      Simple Example\n      --------------\n\n      Synchronous Example\n\n      ```javascript\n      var result;\n\n      try {\n        result = findResult();\n        // success\n      } catch(reason) {\n        // failure\n      }\n      ```\n\n      Errback Example\n\n      ```js\n      findResult(function(result, err){\n        if (err) {\n          // failure\n        } else {\n          // success\n        }\n      });\n      ```\n\n      Promise Example;\n\n      ```javascript\n      findResult().then(function(result){\n        // success\n      }, function(reason){\n        // failure\n      });\n      ```\n\n      Advanced Example\n      --------------\n\n      Synchronous Example\n\n      ```javascript\n      var author, books;\n\n      try {\n        author = findAuthor();\n        books  = findBooksByAuthor(author);\n        // success\n      } catch(reason) {\n        // failure\n      }\n      ```\n\n      Errback Example\n\n      ```js\n\n      function foundBooks(books) {\n\n      }\n\n      function failure(reason) {\n\n      }\n\n      findAuthor(function(author, err){\n        if (err) {\n          failure(err);\n          // failure\n        } else {\n          try {\n            findBoooksByAuthor(author, function(books, err) {\n              if (err) {\n                failure(err);\n              } else {\n                try {\n                  foundBooks(books);\n                } catch(reason) {\n                  failure(reason);\n                }\n              }\n            });\n          } catch(error) {\n            failure(err);\n          }\n          // success\n        }\n      });\n      ```\n\n      Promise Example;\n\n      ```javascript\n      findAuthor().\n        then(findBooksByAuthor).\n        then(function(books){\n          // found books\n      }).catch(function(reason){\n        // something went wrong\n      });\n      ```\n\n      @method then\n      @param {Function} onFulfilled\n      @param {Function} onRejected\n      Useful for tooling.\n      @return {Promise}\n    */\n      then: function(onFulfillment, onRejection) {\n        var parent = this;\n        var state = parent._state;\n\n        if (state === lib$es6$promise$$internal$$FULFILLED && !onFulfillment || state === lib$es6$promise$$internal$$REJECTED && !onRejection) {\n          return this;\n        }\n\n        var child = new this.constructor(lib$es6$promise$$internal$$noop);\n        var result = parent._result;\n\n        if (state) {\n          var callback = arguments[state - 1];\n          lib$es6$promise$asap$$asap(function(){\n            lib$es6$promise$$internal$$invokeCallback(state, child, callback, result);\n          });\n        } else {\n          lib$es6$promise$$internal$$subscribe(parent, child, onFulfillment, onRejection);\n        }\n\n        return child;\n      },\n\n    /**\n      `catch` is simply sugar for `then(undefined, onRejection)` which makes it the same\n      as the catch block of a try/catch statement.\n\n      ```js\n      function findAuthor(){\n        throw new Error('couldn't find that author');\n      }\n\n      // synchronous\n      try {\n        findAuthor();\n      } catch(reason) {\n        // something went wrong\n      }\n\n      // async with promises\n      findAuthor().catch(function(reason){\n        // something went wrong\n      });\n      ```\n\n      @method catch\n      @param {Function} onRejection\n      Useful for tooling.\n      @return {Promise}\n    */\n      'catch': function(onRejection) {\n        return this.then(null, onRejection);\n      }\n    };\n    function lib$es6$promise$polyfill$$polyfill() {\n      var local;\n\n      if (typeof global !== 'undefined') {\n          local = global;\n      } else if (typeof self !== 'undefined') {\n          local = self;\n      } else {\n          try {\n              local = Function('return this')();\n          } catch (e) {\n              throw new Error('polyfill failed because global object is unavailable in this environment');\n          }\n      }\n\n      var P = local.Promise;\n\n      if (P && Object.prototype.toString.call(P.resolve()) === '[object Promise]' && !P.cast) {\n        return;\n      }\n\n      local.Promise = lib$es6$promise$promise$$default;\n    }\n    var lib$es6$promise$polyfill$$default = lib$es6$promise$polyfill$$polyfill;\n\n    var lib$es6$promise$umd$$ES6Promise = {\n      'Promise': lib$es6$promise$promise$$default,\n      'polyfill': lib$es6$promise$polyfill$$default\n    };\n\n    /* global define:true module:true window: true */\n    if (typeof define === 'function' && define['amd']) {\n      define(function() { return lib$es6$promise$umd$$ES6Promise; });\n    } else if (typeof module !== 'undefined' && module['exports']) {\n      module['exports'] = lib$es6$promise$umd$$ES6Promise;\n    } else if (typeof this !== 'undefined') {\n      this['ES6Promise'] = lib$es6$promise$umd$$ES6Promise;\n    }\n\n    lib$es6$promise$polyfill$$default();\n}).call(this);\n\n","\"use strict\";\n/*! @license MIT ©2013-2016 Ruben Verborgh, Ghent University - imec */\n/* Single-function HTTP(S) request module for browsers */\n/* Translated from https://github.com/LinkedDataFragments/Client.js/blob/master/lib/browser/Request.js */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst events_1 = require(\"events\");\nconst parseLink = require(\"parse-link-header\");\nconst stream_1 = require(\"stream\");\n// Headers we cannot send (see https://www.w3.org/TR/XMLHttpRequest/#the-setrequestheader()-method)\nconst UNSAFE_REQUEST_HEADERS = { 'accept-encoding': true, 'user-agent': true, 'referer': true };\nclass Requester {\n    constructor() {\n        this.negotiatedResources = {};\n    }\n    // Creates an HTTP request with the given settings\n    createRequest(settings) {\n        // PERFORMANCE HACK:\n        // Reduce OPTIONS preflight requests by removing the Accept-Datetime header\n        // on requests for resources that are presumed to have been time-negotiated\n        if (this.negotiatedResources[this.removeQuery(settings.url)]) {\n            delete settings.headers['accept-datetime'];\n        }\n        // Create the actual XMLHttpRequest\n        const request = new XMLHttpRequest();\n        const reqHeaders = settings.headers;\n        request.open(settings.method, settings.url, true);\n        request.timeout = settings.timeout;\n        for (const header in reqHeaders) {\n            if (!(header in UNSAFE_REQUEST_HEADERS) && reqHeaders[header]) {\n                request.setRequestHeader(header, reqHeaders[header]);\n            }\n        }\n        // Create a proxy for the XMLHttpRequest\n        const requestProxy = new events_1.EventEmitter();\n        requestProxy.abort = () => { request.abort(); };\n        // Handle the arrival of a response\n        request.onload = () => {\n            // Convert the response into an iterator\n            const response = new stream_1.Readable();\n            response.push(request.responseText || '');\n            response.push(null);\n            response.statusCode = request.status;\n            response.responseUrl = request.responseURL;\n            // Parse the response headers\n            response.headers = {};\n            const resHeaders = response.headers;\n            const rawHeaders = request.getAllResponseHeaders() || '';\n            const headerMatcher = /^([^:\\n\\r]+):[ \\t]*([^\\r\\n]*)$/mg;\n            let match = headerMatcher.exec(rawHeaders);\n            while (match) {\n                resHeaders[match[1].toLowerCase()] = match[2];\n                match = headerMatcher.exec(rawHeaders);\n            }\n            // Emit the response\n            requestProxy.emit('response', response);\n            // If the resource was time-negotiated, store its queryless URI\n            // to enable the PERFORMANCE HACK explained above\n            if (reqHeaders['accept-datetime'] && resHeaders['memento-datetime']) {\n                const resource = this.removeQuery(resHeaders['content-location'] || settings.url);\n                if (!this.negotiatedResources[resource]) {\n                    // Ensure the resource is not a timegate\n                    const links = resHeaders.link && parseLink(resHeaders.link);\n                    const timegate = this.removeQuery(links && links.timegate && links.timegate.url);\n                    if (resource !== timegate) {\n                        this.negotiatedResources[resource] = true;\n                    }\n                }\n            }\n        };\n        // Report errors and timeouts\n        request.onerror = () => {\n            requestProxy.emit('error', new Error('Error requesting ' + settings.url));\n        };\n        request.ontimeout = () => {\n            requestProxy.emit('error', new Error('Timeout requesting ' + settings.url));\n        };\n        // Execute the request\n        request.send();\n        return requestProxy;\n    }\n    // Removes the query string from a URL\n    removeQuery(url) {\n        return url ? url.replace(/\\?.*$/, '') : '';\n    }\n}\nexports.default = Requester;\n//# sourceMappingURL=Requester-browser.js.map","/*! https://mths.be/punycode v1.4.1 by @mathias */\n;(function(root) {\n\n\t/** Detect free variables */\n\tvar freeExports = typeof exports == 'object' && exports &&\n\t\t!exports.nodeType && exports;\n\tvar freeModule = typeof module == 'object' && module &&\n\t\t!module.nodeType && module;\n\tvar freeGlobal = typeof global == 'object' && global;\n\tif (\n\t\tfreeGlobal.global === freeGlobal ||\n\t\tfreeGlobal.window === freeGlobal ||\n\t\tfreeGlobal.self === freeGlobal\n\t) {\n\t\troot = freeGlobal;\n\t}\n\n\t/**\n\t * The `punycode` object.\n\t * @name punycode\n\t * @type Object\n\t */\n\tvar punycode,\n\n\t/** Highest positive signed 32-bit float value */\n\tmaxInt = 2147483647, // aka. 0x7FFFFFFF or 2^31-1\n\n\t/** Bootstring parameters */\n\tbase = 36,\n\ttMin = 1,\n\ttMax = 26,\n\tskew = 38,\n\tdamp = 700,\n\tinitialBias = 72,\n\tinitialN = 128, // 0x80\n\tdelimiter = '-', // '\\x2D'\n\n\t/** Regular expressions */\n\tregexPunycode = /^xn--/,\n\tregexNonASCII = /[^\\x20-\\x7E]/, // unprintable ASCII chars + non-ASCII chars\n\tregexSeparators = /[\\x2E\\u3002\\uFF0E\\uFF61]/g, // RFC 3490 separators\n\n\t/** Error messages */\n\terrors = {\n\t\t'overflow': 'Overflow: input needs wider integers to process',\n\t\t'not-basic': 'Illegal input >= 0x80 (not a basic code point)',\n\t\t'invalid-input': 'Invalid input'\n\t},\n\n\t/** Convenience shortcuts */\n\tbaseMinusTMin = base - tMin,\n\tfloor = Math.floor,\n\tstringFromCharCode = String.fromCharCode,\n\n\t/** Temporary variable */\n\tkey;\n\n\t/*--------------------------------------------------------------------------*/\n\n\t/**\n\t * A generic error utility function.\n\t * @private\n\t * @param {String} type The error type.\n\t * @returns {Error} Throws a `RangeError` with the applicable error message.\n\t */\n\tfunction error(type) {\n\t\tthrow new RangeError(errors[type]);\n\t}\n\n\t/**\n\t * A generic `Array#map` utility function.\n\t * @private\n\t * @param {Array} array The array to iterate over.\n\t * @param {Function} callback The function that gets called for every array\n\t * item.\n\t * @returns {Array} A new array of values returned by the callback function.\n\t */\n\tfunction map(array, fn) {\n\t\tvar length = array.length;\n\t\tvar result = [];\n\t\twhile (length--) {\n\t\t\tresult[length] = fn(array[length]);\n\t\t}\n\t\treturn result;\n\t}\n\n\t/**\n\t * A simple `Array#map`-like wrapper to work with domain name strings or email\n\t * addresses.\n\t * @private\n\t * @param {String} domain The domain name or email address.\n\t * @param {Function} callback The function that gets called for every\n\t * character.\n\t * @returns {Array} A new string of characters returned by the callback\n\t * function.\n\t */\n\tfunction mapDomain(string, fn) {\n\t\tvar parts = string.split('@');\n\t\tvar result = '';\n\t\tif (parts.length > 1) {\n\t\t\t// In email addresses, only the domain name should be punycoded. Leave\n\t\t\t// the local part (i.e. everything up to `@`) intact.\n\t\t\tresult = parts[0] + '@';\n\t\t\tstring = parts[1];\n\t\t}\n\t\t// Avoid `split(regex)` for IE8 compatibility. See #17.\n\t\tstring = string.replace(regexSeparators, '\\x2E');\n\t\tvar labels = string.split('.');\n\t\tvar encoded = map(labels, fn).join('.');\n\t\treturn result + encoded;\n\t}\n\n\t/**\n\t * Creates an array containing the numeric code points of each Unicode\n\t * character in the string. While JavaScript uses UCS-2 internally,\n\t * this function will convert a pair of surrogate halves (each of which\n\t * UCS-2 exposes as separate characters) into a single code point,\n\t * matching UTF-16.\n\t * @see `punycode.ucs2.encode`\n\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t * @memberOf punycode.ucs2\n\t * @name decode\n\t * @param {String} string The Unicode input string (UCS-2).\n\t * @returns {Array} The new array of code points.\n\t */\n\tfunction ucs2decode(string) {\n\t\tvar output = [],\n\t\t    counter = 0,\n\t\t    length = string.length,\n\t\t    value,\n\t\t    extra;\n\t\twhile (counter < length) {\n\t\t\tvalue = string.charCodeAt(counter++);\n\t\t\tif (value >= 0xD800 && value <= 0xDBFF && counter < length) {\n\t\t\t\t// high surrogate, and there is a next character\n\t\t\t\textra = string.charCodeAt(counter++);\n\t\t\t\tif ((extra & 0xFC00) == 0xDC00) { // low surrogate\n\t\t\t\t\toutput.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);\n\t\t\t\t} else {\n\t\t\t\t\t// unmatched surrogate; only append this code unit, in case the next\n\t\t\t\t\t// code unit is the high surrogate of a surrogate pair\n\t\t\t\t\toutput.push(value);\n\t\t\t\t\tcounter--;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\toutput.push(value);\n\t\t\t}\n\t\t}\n\t\treturn output;\n\t}\n\n\t/**\n\t * Creates a string based on an array of numeric code points.\n\t * @see `punycode.ucs2.decode`\n\t * @memberOf punycode.ucs2\n\t * @name encode\n\t * @param {Array} codePoints The array of numeric code points.\n\t * @returns {String} The new Unicode string (UCS-2).\n\t */\n\tfunction ucs2encode(array) {\n\t\treturn map(array, function(value) {\n\t\t\tvar output = '';\n\t\t\tif (value > 0xFFFF) {\n\t\t\t\tvalue -= 0x10000;\n\t\t\t\toutput += stringFromCharCode(value >>> 10 & 0x3FF | 0xD800);\n\t\t\t\tvalue = 0xDC00 | value & 0x3FF;\n\t\t\t}\n\t\t\toutput += stringFromCharCode(value);\n\t\t\treturn output;\n\t\t}).join('');\n\t}\n\n\t/**\n\t * Converts a basic code point into a digit/integer.\n\t * @see `digitToBasic()`\n\t * @private\n\t * @param {Number} codePoint The basic numeric code point value.\n\t * @returns {Number} The numeric value of a basic code point (for use in\n\t * representing integers) in the range `0` to `base - 1`, or `base` if\n\t * the code point does not represent a value.\n\t */\n\tfunction basicToDigit(codePoint) {\n\t\tif (codePoint - 48 < 10) {\n\t\t\treturn codePoint - 22;\n\t\t}\n\t\tif (codePoint - 65 < 26) {\n\t\t\treturn codePoint - 65;\n\t\t}\n\t\tif (codePoint - 97 < 26) {\n\t\t\treturn codePoint - 97;\n\t\t}\n\t\treturn base;\n\t}\n\n\t/**\n\t * Converts a digit/integer into a basic code point.\n\t * @see `basicToDigit()`\n\t * @private\n\t * @param {Number} digit The numeric value of a basic code point.\n\t * @returns {Number} The basic code point whose value (when used for\n\t * representing integers) is `digit`, which needs to be in the range\n\t * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is\n\t * used; else, the lowercase form is used. The behavior is undefined\n\t * if `flag` is non-zero and `digit` has no uppercase form.\n\t */\n\tfunction digitToBasic(digit, flag) {\n\t\t//  0..25 map to ASCII a..z or A..Z\n\t\t// 26..35 map to ASCII 0..9\n\t\treturn digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);\n\t}\n\n\t/**\n\t * Bias adaptation function as per section 3.4 of RFC 3492.\n\t * https://tools.ietf.org/html/rfc3492#section-3.4\n\t * @private\n\t */\n\tfunction adapt(delta, numPoints, firstTime) {\n\t\tvar k = 0;\n\t\tdelta = firstTime ? floor(delta / damp) : delta >> 1;\n\t\tdelta += floor(delta / numPoints);\n\t\tfor (/* no initialization */; delta > baseMinusTMin * tMax >> 1; k += base) {\n\t\t\tdelta = floor(delta / baseMinusTMin);\n\t\t}\n\t\treturn floor(k + (baseMinusTMin + 1) * delta / (delta + skew));\n\t}\n\n\t/**\n\t * Converts a Punycode string of ASCII-only symbols to a string of Unicode\n\t * symbols.\n\t * @memberOf punycode\n\t * @param {String} input The Punycode string of ASCII-only symbols.\n\t * @returns {String} The resulting string of Unicode symbols.\n\t */\n\tfunction decode(input) {\n\t\t// Don't use UCS-2\n\t\tvar output = [],\n\t\t    inputLength = input.length,\n\t\t    out,\n\t\t    i = 0,\n\t\t    n = initialN,\n\t\t    bias = initialBias,\n\t\t    basic,\n\t\t    j,\n\t\t    index,\n\t\t    oldi,\n\t\t    w,\n\t\t    k,\n\t\t    digit,\n\t\t    t,\n\t\t    /** Cached calculation results */\n\t\t    baseMinusT;\n\n\t\t// Handle the basic code points: let `basic` be the number of input code\n\t\t// points before the last delimiter, or `0` if there is none, then copy\n\t\t// the first basic code points to the output.\n\n\t\tbasic = input.lastIndexOf(delimiter);\n\t\tif (basic < 0) {\n\t\t\tbasic = 0;\n\t\t}\n\n\t\tfor (j = 0; j < basic; ++j) {\n\t\t\t// if it's not a basic code point\n\t\t\tif (input.charCodeAt(j) >= 0x80) {\n\t\t\t\terror('not-basic');\n\t\t\t}\n\t\t\toutput.push(input.charCodeAt(j));\n\t\t}\n\n\t\t// Main decoding loop: start just after the last delimiter if any basic code\n\t\t// points were copied; start at the beginning otherwise.\n\n\t\tfor (index = basic > 0 ? basic + 1 : 0; index < inputLength; /* no final expression */) {\n\n\t\t\t// `index` is the index of the next character to be consumed.\n\t\t\t// Decode a generalized variable-length integer into `delta`,\n\t\t\t// which gets added to `i`. The overflow checking is easier\n\t\t\t// if we increase `i` as we go, then subtract off its starting\n\t\t\t// value at the end to obtain `delta`.\n\t\t\tfor (oldi = i, w = 1, k = base; /* no condition */; k += base) {\n\n\t\t\t\tif (index >= inputLength) {\n\t\t\t\t\terror('invalid-input');\n\t\t\t\t}\n\n\t\t\t\tdigit = basicToDigit(input.charCodeAt(index++));\n\n\t\t\t\tif (digit >= base || digit > floor((maxInt - i) / w)) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\ti += digit * w;\n\t\t\t\tt = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\n\t\t\t\tif (digit < t) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tbaseMinusT = base - t;\n\t\t\t\tif (w > floor(maxInt / baseMinusT)) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\tw *= baseMinusT;\n\n\t\t\t}\n\n\t\t\tout = output.length + 1;\n\t\t\tbias = adapt(i - oldi, out, oldi == 0);\n\n\t\t\t// `i` was supposed to wrap around from `out` to `0`,\n\t\t\t// incrementing `n` each time, so we'll fix that now:\n\t\t\tif (floor(i / out) > maxInt - n) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tn += floor(i / out);\n\t\t\ti %= out;\n\n\t\t\t// Insert `n` at position `i` of the output\n\t\t\toutput.splice(i++, 0, n);\n\n\t\t}\n\n\t\treturn ucs2encode(output);\n\t}\n\n\t/**\n\t * Converts a string of Unicode symbols (e.g. a domain name label) to a\n\t * Punycode string of ASCII-only symbols.\n\t * @memberOf punycode\n\t * @param {String} input The string of Unicode symbols.\n\t * @returns {String} The resulting Punycode string of ASCII-only symbols.\n\t */\n\tfunction encode(input) {\n\t\tvar n,\n\t\t    delta,\n\t\t    handledCPCount,\n\t\t    basicLength,\n\t\t    bias,\n\t\t    j,\n\t\t    m,\n\t\t    q,\n\t\t    k,\n\t\t    t,\n\t\t    currentValue,\n\t\t    output = [],\n\t\t    /** `inputLength` will hold the number of code points in `input`. */\n\t\t    inputLength,\n\t\t    /** Cached calculation results */\n\t\t    handledCPCountPlusOne,\n\t\t    baseMinusT,\n\t\t    qMinusT;\n\n\t\t// Convert the input in UCS-2 to Unicode\n\t\tinput = ucs2decode(input);\n\n\t\t// Cache the length\n\t\tinputLength = input.length;\n\n\t\t// Initialize the state\n\t\tn = initialN;\n\t\tdelta = 0;\n\t\tbias = initialBias;\n\n\t\t// Handle the basic code points\n\t\tfor (j = 0; j < inputLength; ++j) {\n\t\t\tcurrentValue = input[j];\n\t\t\tif (currentValue < 0x80) {\n\t\t\t\toutput.push(stringFromCharCode(currentValue));\n\t\t\t}\n\t\t}\n\n\t\thandledCPCount = basicLength = output.length;\n\n\t\t// `handledCPCount` is the number of code points that have been handled;\n\t\t// `basicLength` is the number of basic code points.\n\n\t\t// Finish the basic string - if it is not empty - with a delimiter\n\t\tif (basicLength) {\n\t\t\toutput.push(delimiter);\n\t\t}\n\n\t\t// Main encoding loop:\n\t\twhile (handledCPCount < inputLength) {\n\n\t\t\t// All non-basic code points < n have been handled already. Find the next\n\t\t\t// larger one:\n\t\t\tfor (m = maxInt, j = 0; j < inputLength; ++j) {\n\t\t\t\tcurrentValue = input[j];\n\t\t\t\tif (currentValue >= n && currentValue < m) {\n\t\t\t\t\tm = currentValue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,\n\t\t\t// but guard against overflow\n\t\t\thandledCPCountPlusOne = handledCPCount + 1;\n\t\t\tif (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tdelta += (m - n) * handledCPCountPlusOne;\n\t\t\tn = m;\n\n\t\t\tfor (j = 0; j < inputLength; ++j) {\n\t\t\t\tcurrentValue = input[j];\n\n\t\t\t\tif (currentValue < n && ++delta > maxInt) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\tif (currentValue == n) {\n\t\t\t\t\t// Represent delta as a generalized variable-length integer\n\t\t\t\t\tfor (q = delta, k = base; /* no condition */; k += base) {\n\t\t\t\t\t\tt = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\t\t\t\t\t\tif (q < t) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tqMinusT = q - t;\n\t\t\t\t\t\tbaseMinusT = base - t;\n\t\t\t\t\t\toutput.push(\n\t\t\t\t\t\t\tstringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0))\n\t\t\t\t\t\t);\n\t\t\t\t\t\tq = floor(qMinusT / baseMinusT);\n\t\t\t\t\t}\n\n\t\t\t\t\toutput.push(stringFromCharCode(digitToBasic(q, 0)));\n\t\t\t\t\tbias = adapt(delta, handledCPCountPlusOne, handledCPCount == basicLength);\n\t\t\t\t\tdelta = 0;\n\t\t\t\t\t++handledCPCount;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t++delta;\n\t\t\t++n;\n\n\t\t}\n\t\treturn output.join('');\n\t}\n\n\t/**\n\t * Converts a Punycode string representing a domain name or an email address\n\t * to Unicode. Only the Punycoded parts of the input will be converted, i.e.\n\t * it doesn't matter if you call it on a string that has already been\n\t * converted to Unicode.\n\t * @memberOf punycode\n\t * @param {String} input The Punycoded domain name or email address to\n\t * convert to Unicode.\n\t * @returns {String} The Unicode representation of the given Punycode\n\t * string.\n\t */\n\tfunction toUnicode(input) {\n\t\treturn mapDomain(input, function(string) {\n\t\t\treturn regexPunycode.test(string)\n\t\t\t\t? decode(string.slice(4).toLowerCase())\n\t\t\t\t: string;\n\t\t});\n\t}\n\n\t/**\n\t * Converts a Unicode string representing a domain name or an email address to\n\t * Punycode. Only the non-ASCII parts of the domain name will be converted,\n\t * i.e. it doesn't matter if you call it with a domain that's already in\n\t * ASCII.\n\t * @memberOf punycode\n\t * @param {String} input The domain name or email address to convert, as a\n\t * Unicode string.\n\t * @returns {String} The Punycode representation of the given domain name or\n\t * email address.\n\t */\n\tfunction toASCII(input) {\n\t\treturn mapDomain(input, function(string) {\n\t\t\treturn regexNonASCII.test(string)\n\t\t\t\t? 'xn--' + encode(string)\n\t\t\t\t: string;\n\t\t});\n\t}\n\n\t/*--------------------------------------------------------------------------*/\n\n\t/** Define the public API */\n\tpunycode = {\n\t\t/**\n\t\t * A string representing the current Punycode.js version number.\n\t\t * @memberOf punycode\n\t\t * @type String\n\t\t */\n\t\t'version': '1.4.1',\n\t\t/**\n\t\t * An object of methods to convert from JavaScript's internal character\n\t\t * representation (UCS-2) to Unicode code points, and back.\n\t\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t\t * @memberOf punycode\n\t\t * @type Object\n\t\t */\n\t\t'ucs2': {\n\t\t\t'decode': ucs2decode,\n\t\t\t'encode': ucs2encode\n\t\t},\n\t\t'decode': decode,\n\t\t'encode': encode,\n\t\t'toASCII': toASCII,\n\t\t'toUnicode': toUnicode\n\t};\n\n\t/** Expose `punycode` */\n\t// Some AMD build optimizers, like r.js, check for specific condition patterns\n\t// like the following:\n\tif (\n\t\ttypeof define == 'function' &&\n\t\ttypeof define.amd == 'object' &&\n\t\tdefine.amd\n\t) {\n\t\tdefine('punycode', function() {\n\t\t\treturn punycode;\n\t\t});\n\t} else if (freeExports && freeModule) {\n\t\tif (module.exports == freeExports) {\n\t\t\t// in Node.js, io.js, or RingoJS v0.8.0+\n\t\t\tfreeModule.exports = punycode;\n\t\t} else {\n\t\t\t// in Narwhal or RingoJS v0.7.0-\n\t\t\tfor (key in punycode) {\n\t\t\t\tpunycode.hasOwnProperty(key) && (freeExports[key] = punycode[key]);\n\t\t\t}\n\t\t}\n\t} else {\n\t\t// in Rhino or a web browser\n\t\troot.punycode = punycode;\n\t}\n\n}(this));\n","/**\n * A JavaScript implementation of the JSON-LD API.\n *\n * @author Dave Longley\n *\n * @license BSD 3-Clause License\n * Copyright (c) 2011-2015 Digital Bazaar, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * Neither the name of the Digital Bazaar, Inc. nor the names of its\n * contributors may be used to endorse or promote products derived from\n * this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n(function() {\n\n// determine if in-browser or using node.js\nvar _nodejs = (\n  typeof process !== 'undefined' && process.versions && process.versions.node);\nvar _browser = !_nodejs &&\n  (typeof window !== 'undefined' || typeof self !== 'undefined');\nif(_browser) {\n  if(typeof global === 'undefined') {\n    if(typeof window !== 'undefined') {\n      global = window;\n    } else if(typeof self !== 'undefined') {\n      global = self;\n    } else if(typeof $ !== 'undefined') {\n      global = $;\n    }\n  }\n}\n\n// attaches jsonld API to the given object\nvar wrapper = function(jsonld) {\n\n/* Core API */\n\n/**\n * Performs JSON-LD compaction.\n *\n * @param input the JSON-LD input to compact.\n * @param ctx the context to compact with.\n * @param [options] options to use:\n *          [base] the base IRI to use.\n *          [compactArrays] true to compact arrays to single values when\n *            appropriate, false not to (default: true).\n *          [graph] true to always output a top-level graph (default: false).\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, compacted, ctx) called once the operation completes.\n */\njsonld.compact = function(input, ctx, options, callback) {\n  if(arguments.length < 2) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not compact, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  if(ctx === null) {\n    return jsonld.nextTick(function() {\n      callback(new JsonLdError(\n        'The compaction context must not be null.',\n        'jsonld.CompactError', {code: 'invalid local context'}));\n    });\n  }\n\n  // nothing to compact\n  if(input === null) {\n    return jsonld.nextTick(function() {\n      callback(null, null);\n    });\n  }\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('compactArrays' in options)) {\n    options.compactArrays = true;\n  }\n  if(!('graph' in options)) {\n    options.graph = false;\n  }\n  if(!('skipExpansion' in options)) {\n    options.skipExpansion = false;\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n  if(!('link' in options)) {\n    options.link = false;\n  }\n  if(options.link) {\n    // force skip expansion when linking, \"link\" is not part of the public\n    // API, it should only be called from framing\n    options.skipExpansion = true;\n  }\n\n  var expand = function(input, options, callback) {\n    if(options.skipExpansion) {\n      return jsonld.nextTick(function() {\n        callback(null, input);\n      });\n    }\n    jsonld.expand(input, options, callback);\n  };\n\n  // expand input then do compaction\n  expand(input, options, function(err, expanded) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before compaction.',\n        'jsonld.CompactError', {cause: err}));\n    }\n\n    // process context\n    var activeCtx = _getInitialContext(options);\n    jsonld.processContext(activeCtx, ctx, options, function(err, activeCtx) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not process context before compaction.',\n          'jsonld.CompactError', {cause: err}));\n      }\n\n      var compacted;\n      try {\n        // do compaction\n        compacted = new Processor().compact(activeCtx, null, expanded, options);\n      } catch(ex) {\n        return callback(ex);\n      }\n\n      cleanup(null, compacted, activeCtx, options);\n    });\n  });\n\n  // performs clean up after compaction\n  function cleanup(err, compacted, activeCtx, options) {\n    if(err) {\n      return callback(err);\n    }\n\n    if(options.compactArrays && !options.graph && _isArray(compacted)) {\n      if(compacted.length === 1) {\n        // simplify to a single item\n        compacted = compacted[0];\n      } else if(compacted.length === 0) {\n        // simplify to an empty object\n        compacted = {};\n      }\n    } else if(options.graph && _isObject(compacted)) {\n      // always use array if graph option is on\n      compacted = [compacted];\n    }\n\n    // follow @context key\n    if(_isObject(ctx) && '@context' in ctx) {\n      ctx = ctx['@context'];\n    }\n\n    // build output context\n    ctx = _clone(ctx);\n    if(!_isArray(ctx)) {\n      ctx = [ctx];\n    }\n    // remove empty contexts\n    var tmp = ctx;\n    ctx = [];\n    for(var i = 0; i < tmp.length; ++i) {\n      if(!_isObject(tmp[i]) || Object.keys(tmp[i]).length > 0) {\n        ctx.push(tmp[i]);\n      }\n    }\n\n    // remove array if only one context\n    var hasContext = (ctx.length > 0);\n    if(ctx.length === 1) {\n      ctx = ctx[0];\n    }\n\n    // add context and/or @graph\n    if(_isArray(compacted)) {\n      // use '@graph' keyword\n      var kwgraph = _compactIri(activeCtx, '@graph');\n      var graph = compacted;\n      compacted = {};\n      if(hasContext) {\n        compacted['@context'] = ctx;\n      }\n      compacted[kwgraph] = graph;\n    } else if(_isObject(compacted) && hasContext) {\n      // reorder keys so @context is first\n      var graph = compacted;\n      compacted = {'@context': ctx};\n      for(var key in graph) {\n        compacted[key] = graph[key];\n      }\n    }\n\n    callback(null, compacted, activeCtx);\n  }\n};\n\n/**\n * Performs JSON-LD expansion.\n *\n * @param input the JSON-LD input to expand.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [keepFreeFloatingNodes] true to keep free-floating nodes,\n *            false not to, defaults to false.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, expanded) called once the operation completes.\n */\njsonld.expand = function(input, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not expand, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n  if(!('keepFreeFloatingNodes' in options)) {\n    options.keepFreeFloatingNodes = false;\n  }\n\n  jsonld.nextTick(function() {\n    // if input is a string, attempt to dereference remote document\n    if(typeof input === 'string') {\n      var done = function(err, remoteDoc) {\n        if(err) {\n          return callback(err);\n        }\n        try {\n          if(!remoteDoc.document) {\n            throw new JsonLdError(\n              'No remote document found at the given URL.',\n              'jsonld.NullRemoteDocument');\n          }\n          if(typeof remoteDoc.document === 'string') {\n            remoteDoc.document = JSON.parse(remoteDoc.document);\n          }\n        } catch(ex) {\n          return callback(new JsonLdError(\n            'Could not retrieve a JSON-LD document from the URL. URL ' +\n            'dereferencing not implemented.', 'jsonld.LoadDocumentError', {\n              code: 'loading document failed',\n              cause: ex,\n              remoteDoc: remoteDoc\n          }));\n        }\n        expand(remoteDoc);\n      };\n      var promise = options.documentLoader(input, done);\n      if(promise && 'then' in promise) {\n        promise.then(done.bind(null, null), done);\n      }\n      return;\n    }\n    // nothing to load\n    expand({contextUrl: null, documentUrl: null, document: input});\n  });\n\n  function expand(remoteDoc) {\n    // set default base\n    if(!('base' in options)) {\n      options.base = remoteDoc.documentUrl || '';\n    }\n    // build meta-object and retrieve all @context URLs\n    var input = {\n      document: _clone(remoteDoc.document),\n      remoteContext: {'@context': remoteDoc.contextUrl}\n    };\n    if('expandContext' in options) {\n      var expandContext = _clone(options.expandContext);\n      if(typeof expandContext === 'object' && '@context' in expandContext) {\n        input.expandContext = expandContext;\n      } else {\n        input.expandContext = {'@context': expandContext};\n      }\n    }\n    _retrieveContextUrls(input, options, function(err, input) {\n      if(err) {\n        return callback(err);\n      }\n\n      var expanded;\n      try {\n        var processor = new Processor();\n        var activeCtx = _getInitialContext(options);\n        var document = input.document;\n        var remoteContext = input.remoteContext['@context'];\n\n        // process optional expandContext\n        if(input.expandContext) {\n          activeCtx = processor.processContext(\n            activeCtx, input.expandContext['@context'], options);\n        }\n\n        // process remote context from HTTP Link Header\n        if(remoteContext) {\n          activeCtx = processor.processContext(\n            activeCtx, remoteContext, options);\n        }\n\n        // expand document\n        expanded = processor.expand(\n          activeCtx, null, document, options, false);\n\n        // optimize away @graph with no other properties\n        if(_isObject(expanded) && ('@graph' in expanded) &&\n          Object.keys(expanded).length === 1) {\n          expanded = expanded['@graph'];\n        } else if(expanded === null) {\n          expanded = [];\n        }\n\n        // normalize to an array\n        if(!_isArray(expanded)) {\n          expanded = [expanded];\n        }\n      } catch(ex) {\n        return callback(ex);\n      }\n      callback(null, expanded);\n    });\n  }\n};\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the JSON-LD to flatten.\n * @param ctx the context to use to compact the flattened output, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, flattened) called once the operation completes.\n */\njsonld.flatten = function(input, ctx, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not flatten, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  } else if(typeof ctx === 'function') {\n    callback = ctx;\n    ctx = null;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // expand input\n  jsonld.expand(input, options, function(err, _input) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before flattening.',\n        'jsonld.FlattenError', {cause: err}));\n    }\n\n    var flattened;\n    try {\n      // do flattening\n      flattened = new Processor().flatten(_input);\n    } catch(ex) {\n      return callback(ex);\n    }\n\n    if(ctx === null) {\n      return callback(null, flattened);\n    }\n\n    // compact result (force @graph option to true, skip expansion)\n    options.graph = true;\n    options.skipExpansion = true;\n    jsonld.compact(flattened, ctx, options, function(err, compacted) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not compact flattened output.',\n          'jsonld.FlattenError', {cause: err}));\n      }\n      callback(null, compacted);\n    });\n  });\n};\n\n/**\n * Performs JSON-LD framing.\n *\n * @param input the JSON-LD input to frame.\n * @param frame the JSON-LD frame to use.\n * @param [options] the framing options.\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [embed] default @embed flag: '@last', '@always', '@never', '@link'\n *            (default: '@last').\n *          [explicit] default @explicit flag (default: false).\n *          [requireAll] default @requireAll flag (default: true).\n *          [omitDefault] default @omitDefault flag (default: false).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, framed) called once the operation completes.\n */\njsonld.frame = function(input, frame, options, callback) {\n  if(arguments.length < 2) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not frame, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n  if(!('embed' in options)) {\n    options.embed = '@last';\n  }\n  options.explicit = options.explicit || false;\n  if(!('requireAll' in options)) {\n    options.requireAll = true;\n  }\n  options.omitDefault = options.omitDefault || false;\n\n  jsonld.nextTick(function() {\n    // if frame is a string, attempt to dereference remote document\n    if(typeof frame === 'string') {\n      var done = function(err, remoteDoc) {\n        if(err) {\n          return callback(err);\n        }\n        try {\n          if(!remoteDoc.document) {\n            throw new JsonLdError(\n              'No remote document found at the given URL.',\n              'jsonld.NullRemoteDocument');\n          }\n          if(typeof remoteDoc.document === 'string') {\n            remoteDoc.document = JSON.parse(remoteDoc.document);\n          }\n        } catch(ex) {\n          return callback(new JsonLdError(\n            'Could not retrieve a JSON-LD document from the URL. URL ' +\n            'dereferencing not implemented.', 'jsonld.LoadDocumentError', {\n              code: 'loading document failed',\n              cause: ex,\n              remoteDoc: remoteDoc\n          }));\n        }\n        doFrame(remoteDoc);\n      };\n      var promise = options.documentLoader(frame, done);\n      if(promise && 'then' in promise) {\n        promise.then(done.bind(null, null), done);\n      }\n      return;\n    }\n    // nothing to load\n    doFrame({contextUrl: null, documentUrl: null, document: frame});\n  });\n\n  function doFrame(remoteFrame) {\n    // preserve frame context and add any Link header context\n    var frame = remoteFrame.document;\n    var ctx;\n    if(frame) {\n      ctx = frame['@context'];\n      if(remoteFrame.contextUrl) {\n        if(!ctx) {\n          ctx = remoteFrame.contextUrl;\n        } else if(_isArray(ctx)) {\n          ctx.push(remoteFrame.contextUrl);\n        } else {\n          ctx = [ctx, remoteFrame.contextUrl];\n        }\n        frame['@context'] = ctx;\n      } else {\n        ctx = ctx || {};\n      }\n    } else {\n      ctx = {};\n    }\n\n    // expand input\n    jsonld.expand(input, options, function(err, expanded) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not expand input before framing.',\n          'jsonld.FrameError', {cause: err}));\n      }\n\n      // expand frame\n      var opts = _clone(options);\n      opts.isFrame = true;\n      opts.keepFreeFloatingNodes = true;\n      jsonld.expand(frame, opts, function(err, expandedFrame) {\n        if(err) {\n          return callback(new JsonLdError(\n            'Could not expand frame before framing.',\n            'jsonld.FrameError', {cause: err}));\n        }\n\n        var framed;\n        try {\n          // do framing\n          framed = new Processor().frame(expanded, expandedFrame, opts);\n        } catch(ex) {\n          return callback(ex);\n        }\n\n        // compact result (force @graph option to true, skip expansion,\n        // check for linked embeds)\n        opts.graph = true;\n        opts.skipExpansion = true;\n        opts.link = {};\n        jsonld.compact(framed, ctx, opts, function(err, compacted, ctx) {\n          if(err) {\n            return callback(new JsonLdError(\n              'Could not compact framed output.',\n              'jsonld.FrameError', {cause: err}));\n          }\n          // get graph alias\n          var graph = _compactIri(ctx, '@graph');\n          // remove @preserve from results\n          opts.link = {};\n          compacted[graph] = _removePreserve(ctx, compacted[graph], opts);\n          callback(null, compacted);\n        });\n      });\n    });\n  }\n};\n\n/**\n * **Experimental**\n *\n * Links a JSON-LD document's nodes in memory.\n *\n * @param input the JSON-LD document to link.\n * @param ctx the JSON-LD context to apply.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, linked) called once the operation completes.\n */\njsonld.link = function(input, ctx, options, callback) {\n  // API matches running frame with a wildcard frame and embed: '@link'\n  // get arguments\n  var frame = {};\n  if(ctx) {\n    frame['@context'] = ctx;\n  }\n  frame['@embed'] = '@link';\n  jsonld.frame(input, frame, options, callback);\n};\n\n/**\n * **Deprecated**\n *\n * Performs JSON-LD objectification.\n *\n * @param input the JSON-LD document to objectify.\n * @param ctx the JSON-LD context to apply.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, linked) called once the operation completes.\n */\njsonld.objectify = function(input, ctx, options, callback) {\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // expand input\n  jsonld.expand(input, options, function(err, _input) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before linking.',\n        'jsonld.LinkError', {cause: err}));\n    }\n\n    var flattened;\n    try {\n      // flatten the graph\n      flattened = new Processor().flatten(_input);\n    } catch(ex) {\n      return callback(ex);\n    }\n\n    // compact result (force @graph option to true, skip expansion)\n    options.graph = true;\n    options.skipExpansion = true;\n    jsonld.compact(flattened, ctx, options, function(err, compacted, ctx) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not compact flattened output before linking.',\n          'jsonld.LinkError', {cause: err}));\n      }\n      // get graph alias\n      var graph = _compactIri(ctx, '@graph');\n      var top = compacted[graph][0];\n\n      var recurse = function(subject) {\n        // can't replace just a string\n        if(!_isObject(subject) && !_isArray(subject)) {\n          return;\n        }\n\n        // bottom out recursion on re-visit\n        if(_isObject(subject)) {\n          if(recurse.visited[subject['@id']]) {\n            return;\n          }\n          recurse.visited[subject['@id']] = true;\n        }\n\n        // each array element *or* object key\n        for(var k in subject) {\n          var obj = subject[k];\n          var isid = (jsonld.getContextValue(ctx, k, '@type') === '@id');\n\n          // can't replace a non-object or non-array unless it's an @id\n          if(!_isArray(obj) && !_isObject(obj) && !isid) {\n            continue;\n          }\n\n          if(_isString(obj) && isid) {\n            subject[k] = obj = top[obj];\n            recurse(obj);\n          } else if(_isArray(obj)) {\n            for(var i = 0; i < obj.length; ++i) {\n              if(_isString(obj[i]) && isid) {\n                obj[i] = top[obj[i]];\n              } else if(_isObject(obj[i]) && '@id' in obj[i]) {\n                obj[i] = top[obj[i]['@id']];\n              }\n              recurse(obj[i]);\n            }\n          } else if(_isObject(obj)) {\n            var sid = obj['@id'];\n            subject[k] = obj = top[sid];\n            recurse(obj);\n          }\n        }\n      };\n      recurse.visited = {};\n      recurse(top);\n\n      compacted.of_type = {};\n      for(var s in top) {\n        if(!('@type' in top[s])) {\n          continue;\n        }\n        var types = top[s]['@type'];\n        if(!_isArray(types)) {\n          types = [types];\n        }\n        for(var t = 0; t < types.length; ++t) {\n          if(!(types[t] in compacted.of_type)) {\n            compacted.of_type[types[t]] = [];\n          }\n          compacted.of_type[types[t]].push(top[s]);\n        }\n      }\n      callback(null, compacted);\n    });\n  });\n};\n\n/**\n * Performs RDF dataset normalization on the given input. The input is JSON-LD\n * unless the 'inputFormat' option is used. The output is an RDF dataset\n * unless the 'format' option is used.\n *\n * @param input the input to normalize as JSON-LD or as a format specified by\n *          the 'inputFormat' option.\n * @param [options] the options to use:\n *          [algorithm] the normalization algorithm to use, `URDNA2015` or\n *            `URGNA2012` (default: `URGNA2012`).\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [inputFormat] the format if input is not JSON-LD:\n *            'application/nquads' for N-Quads.\n *          [format] the format if output is a string:\n *            'application/nquads' for N-Quads.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, normalized) called once the operation completes.\n */\njsonld.normalize = function(input, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not normalize, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('algorithm' in options)) {\n    options.algorithm = 'URGNA2012';\n  }\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  if('inputFormat' in options) {\n    if(options.inputFormat !== 'application/nquads') {\n      return callback(new JsonLdError(\n        'Unknown normalization input format.',\n        'jsonld.NormalizeError'));\n    }\n    var parsedInput = _parseNQuads(input);\n    // do normalization\n    new Processor().normalize(parsedInput, options, callback);\n  } else {\n    // convert to RDF dataset then do normalization\n    var opts = _clone(options);\n    delete opts.format;\n    opts.produceGeneralizedRdf = false;\n    jsonld.toRDF(input, opts, function(err, dataset) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not convert input to RDF dataset before normalization.',\n          'jsonld.NormalizeError', {cause: err}));\n      }\n      // do normalization\n      new Processor().normalize(dataset, options, callback);\n    });\n  }\n};\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset a serialized string of RDF in a format specified by the\n *          format option or an RDF dataset to convert.\n * @param [options] the options to use:\n *          [format] the format if dataset param must first be parsed:\n *            'application/nquads' for N-Quads (default).\n *          [rdfParser] a custom RDF-parser to use to parse the dataset.\n *          [useRdfType] true to use rdf:type, false to use @type\n *            (default: false).\n *          [useNativeTypes] true to convert XSD types into native types\n *            (boolean, integer, double), false not to (default: false).\n * @param callback(err, output) called once the operation completes.\n */\njsonld.fromRDF = function(dataset, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not convert from RDF, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('useRdfType' in options)) {\n    options.useRdfType = false;\n  }\n  if(!('useNativeTypes' in options)) {\n    options.useNativeTypes = false;\n  }\n\n  if(!('format' in options) && _isString(dataset)) {\n    // set default format to nquads\n    if(!('format' in options)) {\n      options.format = 'application/nquads';\n    }\n  }\n\n  jsonld.nextTick(function() {\n    // handle special format\n    var rdfParser;\n    if(options.format) {\n      // check supported formats\n      rdfParser = options.rdfParser || _rdfParsers[options.format];\n      if(!rdfParser) {\n        return callback(new JsonLdError(\n          'Unknown input format.',\n          'jsonld.UnknownFormat', {format: options.format}));\n      }\n    } else {\n      // no-op parser, assume dataset already parsed\n      rdfParser = function() {\n        return dataset;\n      };\n    }\n\n    var callbackCalled = false;\n    try {\n      // rdf parser may be async or sync, always pass callback\n      dataset = rdfParser(dataset, function(err, dataset) {\n        callbackCalled = true;\n        if(err) {\n          return callback(err);\n        }\n        fromRDF(dataset, options, callback);\n      });\n    } catch(e) {\n      if(!callbackCalled) {\n        return callback(e);\n      }\n      throw e;\n    }\n    // handle synchronous or promise-based parser\n    if(dataset) {\n      // if dataset is actually a promise\n      if('then' in dataset) {\n        return dataset.then(function(dataset) {\n          fromRDF(dataset, options, callback);\n        }, callback);\n      }\n      // parser is synchronous\n      fromRDF(dataset, options, callback);\n    }\n\n    function fromRDF(dataset, options, callback) {\n      // convert from RDF\n      new Processor().fromRDF(dataset, options, callback);\n    }\n  });\n};\n\n/**\n * Outputs the RDF dataset found in the given JSON-LD object.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [format] the format to use to output a string:\n *            'application/nquads' for N-Quads.\n *          [produceGeneralizedRdf] true to output generalized RDF, false\n *            to produce only standard RDF (default: false).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, dataset) called once the operation completes.\n */\njsonld.toRDF = function(input, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not convert to RDF, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // expand input\n  jsonld.expand(input, options, function(err, expanded) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before serialization to RDF.',\n        'jsonld.RdfError', {cause: err}));\n    }\n\n    var dataset;\n    try {\n      // output RDF dataset\n      dataset = Processor.prototype.toRDF(expanded, options);\n      if(options.format) {\n        if(options.format === 'application/nquads') {\n          return callback(null, _toNQuads(dataset));\n        }\n        throw new JsonLdError(\n          'Unknown output format.',\n          'jsonld.UnknownFormat', {format: options.format});\n      }\n    } catch(ex) {\n      return callback(ex);\n    }\n    callback(null, dataset);\n  });\n};\n\n/**\n * **Experimental**\n *\n * Recursively flattens the nodes in the given JSON-LD input into a map of\n * node ID => node.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [namer] (deprecated)\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, nodeMap) called once the operation completes.\n */\njsonld.createNodeMap = function(input, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not create node map, too few arguments.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  }\n  options = options || {};\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = (typeof input === 'string') ? input : '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // expand input\n  jsonld.expand(input, options, function(err, _input) {\n    if(err) {\n      return callback(new JsonLdError(\n        'Could not expand input before creating node map.',\n        'jsonld.CreateNodeMapError', {cause: err}));\n    }\n\n    var nodeMap;\n    try {\n      nodeMap = new Processor().createNodeMap(_input, options);\n    } catch(ex) {\n      return callback(ex);\n    }\n\n    callback(null, nodeMap);\n  });\n};\n\n/**\n * **Experimental**\n *\n * Merges two or more JSON-LD documents into a single flattened document.\n *\n * @param docs the JSON-LD documents to merge together.\n * @param ctx the context to use to compact the merged result, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [namer] (deprecated).\n *          [mergeNodes] true to merge properties for nodes with the same ID,\n *            false to ignore new properties for nodes with the same ID once\n *            the ID has been defined; note that this may not prevent merging\n *            new properties where a node is in the `object` position\n *            (default: true).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, merged) called once the operation completes.\n */\njsonld.merge = function(docs, ctx, options, callback) {\n  if(arguments.length < 1) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not merge, too few arguments.'));\n    });\n  }\n  if(!_isArray(docs)) {\n    return jsonld.nextTick(function() {\n      callback(new TypeError('Could not merge, \"docs\" must be an array.'));\n    });\n  }\n\n  // get arguments\n  if(typeof options === 'function') {\n    callback = options;\n    options = {};\n  } else if(typeof ctx === 'function') {\n    callback = ctx;\n    ctx = null;\n    options = {};\n  }\n  options = options || {};\n\n  // expand all documents\n  var expanded = [];\n  var error = null;\n  var count = docs.length;\n  for(var i = 0; i < docs.length; ++i) {\n    var opts = {};\n    for(var key in options) {\n      opts[key] = options[key];\n    }\n    jsonld.expand(docs[i], opts, expandComplete);\n  }\n\n  function expandComplete(err, _input) {\n    if(error) {\n      return;\n    }\n    if(err) {\n      error = err;\n      return callback(new JsonLdError(\n        'Could not expand input before flattening.',\n        'jsonld.FlattenError', {cause: err}));\n    }\n    expanded.push(_input);\n    if(--count === 0) {\n      merge(expanded);\n    }\n  }\n\n  function merge(expanded) {\n    var mergeNodes = true;\n    if('mergeNodes' in options) {\n      mergeNodes = options.mergeNodes;\n    }\n\n    var issuer = options.namer || options.issuer || new IdentifierIssuer('_:b');\n    var graphs = {'@default': {}};\n\n    var defaultGraph;\n    try {\n      for(var i = 0; i < expanded.length; ++i) {\n        // uniquely relabel blank nodes\n        var doc = expanded[i];\n        doc = jsonld.relabelBlankNodes(doc, {\n          issuer: new IdentifierIssuer('_:b' + i + '-')\n        });\n\n        // add nodes to the shared node map graphs if merging nodes, to a\n        // separate graph set if not\n        var _graphs = (mergeNodes || i === 0) ? graphs : {'@default': {}};\n        _createNodeMap(doc, _graphs, '@default', issuer);\n\n        if(_graphs !== graphs) {\n          // merge document graphs but don't merge existing nodes\n          for(var graphName in _graphs) {\n            var _nodeMap = _graphs[graphName];\n            if(!(graphName in graphs)) {\n              graphs[graphName] = _nodeMap;\n              continue;\n            }\n            var nodeMap = graphs[graphName];\n            for(var key in _nodeMap) {\n              if(!(key in nodeMap)) {\n                nodeMap[key] = _nodeMap[key];\n              }\n            }\n          }\n        }\n      }\n\n      // add all non-default graphs to default graph\n      defaultGraph = _mergeNodeMaps(graphs);\n    } catch(ex) {\n      return callback(ex);\n    }\n\n    // produce flattened output\n    var flattened = [];\n    var keys = Object.keys(defaultGraph).sort();\n    for(var ki = 0; ki < keys.length; ++ki) {\n      var node = defaultGraph[keys[ki]];\n      // only add full subjects to top-level\n      if(!_isSubjectReference(node)) {\n        flattened.push(node);\n      }\n    }\n\n    if(ctx === null) {\n      return callback(null, flattened);\n    }\n\n    // compact result (force @graph option to true, skip expansion)\n    options.graph = true;\n    options.skipExpansion = true;\n    jsonld.compact(flattened, ctx, options, function(err, compacted) {\n      if(err) {\n        return callback(new JsonLdError(\n          'Could not compact merged output.',\n          'jsonld.MergeError', {cause: err}));\n      }\n      callback(null, compacted);\n    });\n  }\n};\n\n/**\n * Relabels all blank nodes in the given JSON-LD input.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [namer] (deprecated).\n */\njsonld.relabelBlankNodes = function(input, options) {\n  options = options || {};\n  var issuer = options.namer || options.issuer || new IdentifierIssuer('_:b');\n  return _labelBlankNodes(issuer, input);\n};\n\n/**\n * Prepends a base IRI to the given relative IRI.\n *\n * @param base the base IRI.\n * @param iri the relative IRI.\n *\n * @return the absolute IRI.\n */\njsonld.prependBase = function(base, iri) {\n  return _prependBase(base, iri);\n};\n\n/**\n * The default document loader for external documents. If the environment\n * is node.js, a callback-continuation-style document loader is used; otherwise,\n * a promises-style document loader is used.\n *\n * @param url the URL to load.\n * @param callback(err, remoteDoc) called once the operation completes,\n *          if using a non-promises API.\n *\n * @return a promise, if using a promises API.\n */\njsonld.documentLoader = function(url, callback) {\n  var err = new JsonLdError(\n    'Could not retrieve a JSON-LD document from the URL. URL ' +\n    'dereferencing not implemented.', 'jsonld.LoadDocumentError',\n    {code: 'loading document failed'});\n  if(_nodejs) {\n    return callback(err, {contextUrl: null, documentUrl: url, document: null});\n  }\n  return jsonld.promisify(function(callback) {\n    callback(err);\n  });\n};\n\n/**\n * Deprecated default document loader. Use or override jsonld.documentLoader\n * instead.\n */\njsonld.loadDocument = function(url, callback) {\n  var promise = jsonld.documentLoader(url, callback);\n  if(promise && 'then' in promise) {\n    promise.then(callback.bind(null, null), callback);\n  }\n};\n\n/* Promises API */\n\n/**\n * Creates a new promises API object.\n *\n * @param [options] the options to use:\n *          [api] an object to attach the API to.\n *          [version] 'json-ld-1.0' to output a standard JSON-LD 1.0 promises\n *            API, 'jsonld.js' to output the same with augmented proprietary\n *            methods (default: 'jsonld.js')\n *\n * @return the promises API object.\n */\njsonld.promises = function(options) {\n  options = options || {};\n  var slice = Array.prototype.slice;\n  var promisify = jsonld.promisify;\n\n  // handle 'api' option as version, set defaults\n  var api = options.api || {};\n  var version = options.version || 'jsonld.js';\n  if(typeof options.api === 'string') {\n    if(!options.version) {\n      version = options.api;\n    }\n    api = {};\n  }\n\n  // The Web IDL test harness will check the number of parameters defined in\n  // the functions below. The number of parameters must exactly match the\n  // required (non-optional) parameters of the JsonLdProcessor interface as\n  // defined here:\n  // https://www.w3.org/TR/json-ld-api/#the-jsonldprocessor-interface\n\n  api.expand = function(input) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not expand, too few arguments.');\n    }\n    return promisify.apply(null, [jsonld.expand].concat(slice.call(arguments)));\n  };\n  api.compact = function(input, ctx) {\n    if(arguments.length < 2) {\n      throw new TypeError('Could not compact, too few arguments.');\n    }\n    var compact = function(input, ctx, options, callback) {\n      if(typeof options === 'function') {\n        callback = options;\n        options = {};\n      }\n      options = options || {};\n      // ensure only one value is returned in callback\n      jsonld.compact(input, ctx, options, function(err, compacted) {\n        callback(err, compacted);\n      });\n    };\n    return promisify.apply(null, [compact].concat(slice.call(arguments)));\n  };\n  api.flatten = function(input) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not flatten, too few arguments.');\n    }\n    return promisify.apply(\n      null, [jsonld.flatten].concat(slice.call(arguments)));\n  };\n  api.frame = function(input, frame) {\n    if(arguments.length < 2) {\n      throw new TypeError('Could not frame, too few arguments.');\n    }\n    return promisify.apply(null, [jsonld.frame].concat(slice.call(arguments)));\n  };\n  api.fromRDF = function(dataset) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not convert from RDF, too few arguments.');\n    }\n    return promisify.apply(\n      null, [jsonld.fromRDF].concat(slice.call(arguments)));\n  };\n  api.toRDF = function(input) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not convert to RDF, too few arguments.');\n    }\n    return promisify.apply(null, [jsonld.toRDF].concat(slice.call(arguments)));\n  };\n  api.normalize = function(input) {\n    if(arguments.length < 1) {\n      throw new TypeError('Could not normalize, too few arguments.');\n    }\n    return promisify.apply(\n      null, [jsonld.normalize].concat(slice.call(arguments)));\n  };\n\n  if(version === 'jsonld.js') {\n    api.link = function(input, ctx) {\n      if(arguments.length < 2) {\n        throw new TypeError('Could not link, too few arguments.');\n      }\n      return promisify.apply(\n        null, [jsonld.link].concat(slice.call(arguments)));\n    };\n    api.objectify = function(input) {\n      return promisify.apply(\n        null, [jsonld.objectify].concat(slice.call(arguments)));\n    };\n    api.createNodeMap = function(input) {\n      return promisify.apply(\n        null, [jsonld.createNodeMap].concat(slice.call(arguments)));\n    };\n    api.merge = function(input) {\n      return promisify.apply(\n        null, [jsonld.merge].concat(slice.call(arguments)));\n    };\n  }\n\n  try {\n    jsonld.Promise = global.Promise || require('es6-promise').Promise;\n  } catch(e) {\n    var f = function() {\n      throw new Error('Unable to find a Promise implementation.');\n    };\n    for(var method in api) {\n      api[method] = f;\n    }\n  }\n\n  return api;\n};\n\n/**\n * Converts a node.js async op into a promise w/boxed resolved value(s).\n *\n * @param op the operation to convert.\n *\n * @return the promise.\n */\njsonld.promisify = function(op) {\n  if(!jsonld.Promise) {\n    try {\n      jsonld.Promise = global.Promise || require('es6-promise').Promise;\n    } catch(e) {\n      throw new Error('Unable to find a Promise implementation.');\n    }\n  }\n  var args = Array.prototype.slice.call(arguments, 1);\n  return new jsonld.Promise(function(resolve, reject) {\n    op.apply(null, args.concat(function(err, value) {\n      if(!err) {\n        resolve(value);\n      } else {\n        reject(err);\n      }\n    }));\n  });\n};\n\n// extend jsonld.promises w/jsonld.js methods\njsonld.promises({api: jsonld.promises});\n\n/* WebIDL API */\n\nfunction JsonLdProcessor() {}\nJsonLdProcessor.prototype = jsonld.promises({version: 'json-ld-1.0'});\nJsonLdProcessor.prototype.toString = function() {\n  if(this instanceof JsonLdProcessor) {\n    return '[object JsonLdProcessor]';\n  }\n  return '[object JsonLdProcessorPrototype]';\n};\njsonld.JsonLdProcessor = JsonLdProcessor;\n\n// IE8 has Object.defineProperty but it only\n// works on DOM nodes -- so feature detection\n// requires try/catch :-(\nvar canDefineProperty = !!Object.defineProperty;\nif(canDefineProperty) {\n  try {\n    Object.defineProperty({}, 'x', {});\n  } catch(e) {\n    canDefineProperty = false;\n  }\n}\n\nif(canDefineProperty) {\n  Object.defineProperty(JsonLdProcessor, 'prototype', {\n    writable: false,\n    enumerable: false\n  });\n  Object.defineProperty(JsonLdProcessor.prototype, 'constructor', {\n    writable: true,\n    enumerable: false,\n    configurable: true,\n    value: JsonLdProcessor\n  });\n}\n\n// setup browser global JsonLdProcessor\nif(_browser && typeof global.JsonLdProcessor === 'undefined') {\n  if(canDefineProperty) {\n    Object.defineProperty(global, 'JsonLdProcessor', {\n      writable: true,\n      enumerable: false,\n      configurable: true,\n      value: JsonLdProcessor\n    });\n  } else {\n    global.JsonLdProcessor = JsonLdProcessor;\n  }\n}\n\n/* Utility API */\n\n// define setImmediate and nextTick\n//// nextTick implementation with browser-compatible fallback ////\n// from https://github.com/caolan/async/blob/master/lib/async.js\n\n// capture the global reference to guard against fakeTimer mocks\nvar _setImmediate = typeof setImmediate === 'function' && setImmediate;\n\nvar _delay = _setImmediate ? function(fn) {\n  // not a direct alias (for IE10 compatibility)\n  _setImmediate(fn);\n} : function(fn) {\n  setTimeout(fn, 0);\n};\n\nif(typeof process === 'object' && typeof process.nextTick === 'function') {\n  jsonld.nextTick = process.nextTick;\n} else {\n  jsonld.nextTick = _delay;\n}\njsonld.setImmediate = _setImmediate ? _delay : jsonld.nextTick;\n\n/**\n * Parses a link header. The results will be key'd by the value of \"rel\".\n *\n * Link: <http://json-ld.org/contexts/person.jsonld>; rel=\"http://www.w3.org/ns/json-ld#context\"; type=\"application/ld+json\"\n *\n * Parses as: {\n *   'http://www.w3.org/ns/json-ld#context': {\n *     target: http://json-ld.org/contexts/person.jsonld,\n *     type: 'application/ld+json'\n *   }\n * }\n *\n * If there is more than one \"rel\" with the same IRI, then entries in the\n * resulting map for that \"rel\" will be arrays.\n *\n * @param header the link header to parse.\n */\njsonld.parseLinkHeader = function(header) {\n  var rval = {};\n  // split on unbracketed/unquoted commas\n  var entries = header.match(/(?:<[^>]*?>|\"[^\"]*?\"|[^,])+/g);\n  var rLinkHeader = /\\s*<([^>]*?)>\\s*(?:;\\s*(.*))?/;\n  for(var i = 0; i < entries.length; ++i) {\n    var match = entries[i].match(rLinkHeader);\n    if(!match) {\n      continue;\n    }\n    var result = {target: match[1]};\n    var params = match[2];\n    var rParams = /(.*?)=(?:(?:\"([^\"]*?)\")|([^\"]*?))\\s*(?:(?:;\\s*)|$)/g;\n    while(match = rParams.exec(params)) {\n      result[match[1]] = (match[2] === undefined) ? match[3] : match[2];\n    }\n    var rel = result['rel'] || '';\n    if(_isArray(rval[rel])) {\n      rval[rel].push(result);\n    } else if(rel in rval) {\n      rval[rel] = [rval[rel], result];\n    } else {\n      rval[rel] = result;\n    }\n  }\n  return rval;\n};\n\n/**\n * Creates a simple queue for requesting documents.\n */\njsonld.RequestQueue = function() {\n  this._requests = {};\n};\njsonld.RequestQueue.prototype.wrapLoader = function(loader) {\n  this._loader = loader;\n  this._usePromise = (loader.length === 1);\n  return this.add.bind(this);\n};\njsonld.RequestQueue.prototype.add = function(url, callback) {\n  var self = this;\n\n  // callback must be given if not using promises\n  if(!callback && !self._usePromise) {\n    throw new Error('callback must be specified.');\n  }\n\n  // Promise-based API\n  if(self._usePromise) {\n    return new jsonld.Promise(function(resolve, reject) {\n      var load = self._requests[url];\n      if(!load) {\n        // load URL then remove from queue\n        load = self._requests[url] = self._loader(url)\n          .then(function(remoteDoc) {\n            delete self._requests[url];\n            return remoteDoc;\n          }).catch(function(err) {\n            delete self._requests[url];\n            throw err;\n          });\n      }\n      // resolve/reject promise once URL has been loaded\n      load.then(function(remoteDoc) {\n        resolve(remoteDoc);\n      }).catch(function(err) {\n        reject(err);\n      });\n    });\n  }\n\n  // callback-based API\n  if(url in self._requests) {\n    self._requests[url].push(callback);\n  } else {\n    self._requests[url] = [callback];\n    self._loader(url, function(err, remoteDoc) {\n      var callbacks = self._requests[url];\n      delete self._requests[url];\n      for(var i = 0; i < callbacks.length; ++i) {\n        callbacks[i](err, remoteDoc);\n      }\n    });\n  }\n};\n\n/**\n * Creates a simple document cache that retains documents for a short\n * period of time.\n *\n * FIXME: Implement simple HTTP caching instead.\n *\n * @param size the maximum size of the cache.\n */\njsonld.DocumentCache = function(size) {\n  this.order = [];\n  this.cache = {};\n  this.size = size || 50;\n  this.expires = 30 * 1000;\n};\njsonld.DocumentCache.prototype.get = function(url) {\n  if(url in this.cache) {\n    var entry = this.cache[url];\n    if(entry.expires >= +new Date()) {\n      return entry.ctx;\n    }\n    delete this.cache[url];\n    this.order.splice(this.order.indexOf(url), 1);\n  }\n  return null;\n};\njsonld.DocumentCache.prototype.set = function(url, ctx) {\n  if(this.order.length === this.size) {\n    delete this.cache[this.order.shift()];\n  }\n  this.order.push(url);\n  this.cache[url] = {ctx: ctx, expires: (+new Date() + this.expires)};\n};\n\n/**\n * Creates an active context cache.\n *\n * @param size the maximum size of the cache.\n */\njsonld.ActiveContextCache = function(size) {\n  this.order = [];\n  this.cache = {};\n  this.size = size || 100;\n};\njsonld.ActiveContextCache.prototype.get = function(activeCtx, localCtx) {\n  var key1 = JSON.stringify(activeCtx);\n  var key2 = JSON.stringify(localCtx);\n  var level1 = this.cache[key1];\n  if(level1 && key2 in level1) {\n    return level1[key2];\n  }\n  return null;\n};\njsonld.ActiveContextCache.prototype.set = function(\n  activeCtx, localCtx, result) {\n  if(this.order.length === this.size) {\n    var entry = this.order.shift();\n    delete this.cache[entry.activeCtx][entry.localCtx];\n  }\n  var key1 = JSON.stringify(activeCtx);\n  var key2 = JSON.stringify(localCtx);\n  this.order.push({activeCtx: key1, localCtx: key2});\n  if(!(key1 in this.cache)) {\n    this.cache[key1] = {};\n  }\n  this.cache[key1][key2] = _clone(result);\n};\n\n/**\n * Default JSON-LD cache.\n */\njsonld.cache = {\n  activeCtx: new jsonld.ActiveContextCache()\n};\n\n/**\n * Document loaders.\n */\njsonld.documentLoaders = {};\n\n/**\n * Creates a built-in jquery document loader.\n *\n * @param $ the jquery instance to use.\n * @param options the options to use:\n *          secure: require all URLs to use HTTPS.\n *          usePromise: true to use a promises API, false for a\n *            callback-continuation-style API; defaults to true if Promise\n *            is globally defined, false if not.\n *\n * @return the jquery document loader.\n */\njsonld.documentLoaders.jquery = function($, options) {\n  options = options || {};\n  var queue = new jsonld.RequestQueue();\n\n  // use option or, by default, use Promise when its defined\n  var usePromise = ('usePromise' in options ?\n    options.usePromise : (typeof Promise !== 'undefined'));\n  if(usePromise) {\n    return queue.wrapLoader(function(url) {\n      return jsonld.promisify(loader, url);\n    });\n  }\n  return queue.wrapLoader(loader);\n\n  function loader(url, callback) {\n    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; only \"http\" and \"https\" URLs are ' +\n        'supported.',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    if(options.secure && url.indexOf('https') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; secure mode is enabled and ' +\n        'the URL\\'s scheme is not \"https\".',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    $.ajax({\n      url: url,\n      accepts: {\n        json: 'application/ld+json, application/json'\n      },\n      // ensure Accept header is very specific for JSON-LD/JSON\n      headers: {\n        'Accept': 'application/ld+json, application/json'\n      },\n      dataType: 'json',\n      crossDomain: true,\n      success: function(data, textStatus, jqXHR) {\n        var doc = {contextUrl: null, documentUrl: url, document: data};\n\n        // handle Link Header\n        var contentType = jqXHR.getResponseHeader('Content-Type');\n        var linkHeader = jqXHR.getResponseHeader('Link');\n        if(linkHeader && contentType !== 'application/ld+json') {\n          // only 1 related link header permitted\n          linkHeader = jsonld.parseLinkHeader(linkHeader)[LINK_HEADER_REL];\n          if(_isArray(linkHeader)) {\n            return callback(new JsonLdError(\n              'URL could not be dereferenced, it has more than one ' +\n              'associated HTTP Link Header.',\n              'jsonld.InvalidUrl',\n              {code: 'multiple context link headers', url: url}), doc);\n          }\n          if(linkHeader) {\n            doc.contextUrl = linkHeader.target;\n          }\n        }\n\n        callback(null, doc);\n      },\n      error: function(jqXHR, textStatus, err) {\n        callback(new JsonLdError(\n          'URL could not be dereferenced, an error occurred.',\n          'jsonld.LoadDocumentError',\n          {code: 'loading document failed', url: url, cause: err}),\n          {contextUrl: null, documentUrl: url, document: null});\n      }\n    });\n  }\n};\n\n/**\n * Creates a built-in node document loader.\n *\n * @param options the options to use:\n *          secure: require all URLs to use HTTPS.\n *          strictSSL: true to require SSL certificates to be valid,\n *            false not to (default: true).\n *          maxRedirects: the maximum number of redirects to permit, none by\n *            default.\n *          request: the object which will make the request, default is\n *            provided by `https://www.npmjs.com/package/request`.\n *          headers: an array of headers which will be passed as request\n *            headers for the requested document. Accept is not allowed.\n *          usePromise: true to use a promises API, false for a\n *            callback-continuation-style API; false by default.\n *\n * @return the node document loader.\n */\njsonld.documentLoaders.node = function(options) {\n  options = options || {};\n  var strictSSL = ('strictSSL' in options) ? options.strictSSL : true;\n  var maxRedirects = ('maxRedirects' in options) ? options.maxRedirects : -1;\n  var request = ('request' in options) ? options.request : require('request');\n  var acceptHeader = 'application/ld+json, application/json';\n  var http = require('http');\n  // TODO: disable cache until HTTP caching implemented\n  //var cache = new jsonld.DocumentCache();\n\n  var queue = new jsonld.RequestQueue();\n  if(options.usePromise) {\n    return queue.wrapLoader(function(url) {\n      return jsonld.promisify(loadDocument, url, []);\n    });\n  }\n  var headers = options.headers || {};\n  if('Accept' in headers || 'accept' in headers) {\n    throw new RangeError(\n      'Accept header may not be specified as an option; only \"' +\n      acceptHeader + '\" is supported.');\n  }\n  return queue.wrapLoader(function(url, callback) {\n    loadDocument(url, [], callback);\n  });\n\n  function loadDocument(url, redirects, callback) {\n    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; only \"http\" and \"https\" URLs are ' +\n        'supported.',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    if(options.secure && url.indexOf('https') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; secure mode is enabled and ' +\n        'the URL\\'s scheme is not \"https\".',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    // TODO: disable cache until HTTP caching implemented\n    var doc = null;//cache.get(url);\n    if(doc !== null) {\n      return callback(null, doc);\n    }\n    var headers = {'Accept': acceptHeader};\n    for(var k in options.headers) { headers[k] = options.headers[k]; }\n    request({\n      url: url,\n      headers: headers,\n      strictSSL: strictSSL,\n      followRedirect: false\n    }, handleResponse);\n\n    function handleResponse(err, res, body) {\n      doc = {contextUrl: null, documentUrl: url, document: body || null};\n\n      // handle error\n      if(err) {\n        return callback(new JsonLdError(\n          'URL could not be dereferenced, an error occurred.',\n          'jsonld.LoadDocumentError',\n          {code: 'loading document failed', url: url, cause: err}), doc);\n      }\n      var statusText = http.STATUS_CODES[res.statusCode];\n      if(res.statusCode >= 400) {\n        return callback(new JsonLdError(\n          'URL could not be dereferenced: ' + statusText,\n          'jsonld.InvalidUrl', {\n            code: 'loading document failed',\n            url: url,\n            httpStatusCode: res.statusCode\n          }), doc);\n      }\n\n      // handle Link Header\n      if(res.headers.link &&\n        res.headers['content-type'] !== 'application/ld+json') {\n        // only 1 related link header permitted\n        var linkHeader = jsonld.parseLinkHeader(\n          res.headers.link)[LINK_HEADER_REL];\n        if(_isArray(linkHeader)) {\n          return callback(new JsonLdError(\n            'URL could not be dereferenced, it has more than one associated ' +\n            'HTTP Link Header.',\n            'jsonld.InvalidUrl',\n            {code: 'multiple context link headers', url: url}), doc);\n        }\n        if(linkHeader) {\n          doc.contextUrl = linkHeader.target;\n        }\n      }\n\n      // handle redirect\n      if(res.statusCode >= 300 && res.statusCode < 400 &&\n        res.headers.location) {\n        if(redirects.length === maxRedirects) {\n          return callback(new JsonLdError(\n            'URL could not be dereferenced; there were too many redirects.',\n            'jsonld.TooManyRedirects', {\n              code: 'loading document failed',\n              url: url,\n              httpStatusCode: res.statusCode,\n              redirects: redirects\n            }), doc);\n        }\n        if(redirects.indexOf(url) !== -1) {\n          return callback(new JsonLdError(\n            'URL could not be dereferenced; infinite redirection was detected.',\n            'jsonld.InfiniteRedirectDetected', {\n              code: 'recursive context inclusion',\n              url: url,\n              httpStatusCode: res.statusCode,\n              redirects: redirects\n            }), doc);\n        }\n        redirects.push(url);\n        return loadDocument(res.headers.location, redirects, callback);\n      }\n      // cache for each redirected URL\n      redirects.push(url);\n      // TODO: disable cache until HTTP caching implemented\n      /*for(var i = 0; i < redirects.length; ++i) {\n        cache.set(\n          redirects[i],\n          {contextUrl: null, documentUrl: redirects[i], document: body});\n      }*/\n      callback(err, doc);\n    }\n  }\n};\n\n/**\n * Creates a built-in XMLHttpRequest document loader.\n *\n * @param options the options to use:\n *          secure: require all URLs to use HTTPS.\n *          usePromise: true to use a promises API, false for a\n *            callback-continuation-style API; defaults to true if Promise\n *            is globally defined, false if not.\n *          [xhr]: the XMLHttpRequest API to use.\n *\n * @return the XMLHttpRequest document loader.\n */\njsonld.documentLoaders.xhr = function(options) {\n  options = options || {};\n  var rlink = /(^|(\\r\\n))link:/i;\n  var queue = new jsonld.RequestQueue();\n\n  // use option or, by default, use Promise when its defined\n  var usePromise = ('usePromise' in options ?\n    options.usePromise : (typeof Promise !== 'undefined'));\n  if(usePromise) {\n    return queue.wrapLoader(function(url) {\n      return jsonld.promisify(loader, url);\n    });\n  }\n  return queue.wrapLoader(loader);\n\n  function loader(url, callback) {\n    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; only \"http\" and \"https\" URLs are ' +\n        'supported.',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    if(options.secure && url.indexOf('https') !== 0) {\n      return callback(new JsonLdError(\n        'URL could not be dereferenced; secure mode is enabled and ' +\n        'the URL\\'s scheme is not \"https\".',\n        'jsonld.InvalidUrl', {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    }\n    var xhr = options.xhr || XMLHttpRequest;\n    var req = new xhr();\n    req.onload = function() {\n      if(req.status >= 400) {\n        return callback(new JsonLdError(\n          'URL could not be dereferenced: ' + req.statusText,\n          'jsonld.LoadDocumentError', {\n            code: 'loading document failed',\n            url: url,\n            httpStatusCode: req.status\n          }), {contextUrl: null, documentUrl: url, document: null});\n      }\n\n      var doc = {contextUrl: null, documentUrl: url, document: req.response};\n\n      // handle Link Header (avoid unsafe header warning by existence testing)\n      var contentType = req.getResponseHeader('Content-Type');\n      var linkHeader;\n      if(rlink.test(req.getAllResponseHeaders())) {\n        linkHeader = req.getResponseHeader('Link');\n      }\n      if(linkHeader && contentType !== 'application/ld+json') {\n        // only 1 related link header permitted\n        linkHeader = jsonld.parseLinkHeader(linkHeader)[LINK_HEADER_REL];\n        if(_isArray(linkHeader)) {\n          return callback(new JsonLdError(\n            'URL could not be dereferenced, it has more than one ' +\n            'associated HTTP Link Header.',\n            'jsonld.InvalidUrl',\n            {code: 'multiple context link headers', url: url}), doc);\n        }\n        if(linkHeader) {\n          doc.contextUrl = linkHeader.target;\n        }\n      }\n\n      callback(null, doc);\n    };\n    req.onerror = function() {\n      callback(new JsonLdError(\n        'URL could not be dereferenced, an error occurred.',\n        'jsonld.LoadDocumentError',\n        {code: 'loading document failed', url: url}),\n        {contextUrl: null, documentUrl: url, document: null});\n    };\n    req.open('GET', url, true);\n    req.setRequestHeader('Accept', 'application/ld+json, application/json');\n    req.send();\n  }\n};\n\n/**\n * Assigns the default document loader for external document URLs to a built-in\n * default. Supported types currently include: 'jquery' and 'node'.\n *\n * To use the jquery document loader, the first parameter must be a reference\n * to the main jquery object.\n *\n * @param type the type to set.\n * @param [params] the parameters required to use the document loader.\n */\njsonld.useDocumentLoader = function(type) {\n  if(!(type in jsonld.documentLoaders)) {\n    throw new JsonLdError(\n      'Unknown document loader type: \"' + type + '\"',\n      'jsonld.UnknownDocumentLoader',\n      {type: type});\n  }\n\n  // set document loader\n  jsonld.documentLoader = jsonld.documentLoaders[type].apply(\n    jsonld, Array.prototype.slice.call(arguments, 1));\n};\n\n/**\n * Processes a local context, resolving any URLs as necessary, and returns a\n * new active context in its callback.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param [options] the options to use:\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param callback(err, ctx) called once the operation completes.\n */\njsonld.processContext = function(activeCtx, localCtx) {\n  // get arguments\n  var options = {};\n  var callbackArg = 2;\n  if(arguments.length > 3) {\n    options = arguments[2] || {};\n    callbackArg += 1;\n  }\n  var callback = arguments[callbackArg];\n\n  // set default options\n  if(!('base' in options)) {\n    options.base = '';\n  }\n  if(!('documentLoader' in options)) {\n    options.documentLoader = jsonld.loadDocument;\n  }\n\n  // return initial context early for null context\n  if(localCtx === null) {\n    return callback(null, _getInitialContext(options));\n  }\n\n  // retrieve URLs in localCtx\n  localCtx = _clone(localCtx);\n  if(!(_isObject(localCtx) && '@context' in localCtx)) {\n    localCtx = {'@context': localCtx};\n  }\n  _retrieveContextUrls(localCtx, options, function(err, ctx) {\n    if(err) {\n      return callback(err);\n    }\n    try {\n      // process context\n      ctx = new Processor().processContext(activeCtx, ctx, options);\n    } catch(ex) {\n      return callback(ex);\n    }\n    callback(null, ctx);\n  });\n};\n\n/**\n * Returns true if the given subject has the given property.\n *\n * @param subject the subject to check.\n * @param property the property to look for.\n *\n * @return true if the subject has the given property, false if not.\n */\njsonld.hasProperty = function(subject, property) {\n  var rval = false;\n  if(property in subject) {\n    var value = subject[property];\n    rval = (!_isArray(value) || value.length > 0);\n  }\n  return rval;\n};\n\n/**\n * Determines if the given value is a property of the given subject.\n *\n * @param subject the subject to check.\n * @param property the property to check.\n * @param value the value to check.\n *\n * @return true if the value exists, false if not.\n */\njsonld.hasValue = function(subject, property, value) {\n  var rval = false;\n  if(jsonld.hasProperty(subject, property)) {\n    var val = subject[property];\n    var isList = _isList(val);\n    if(_isArray(val) || isList) {\n      if(isList) {\n        val = val['@list'];\n      }\n      for(var i = 0; i < val.length; ++i) {\n        if(jsonld.compareValues(value, val[i])) {\n          rval = true;\n          break;\n        }\n      }\n    } else if(!_isArray(value)) {\n      // avoid matching the set of values with an array value parameter\n      rval = jsonld.compareValues(value, val);\n    }\n  }\n  return rval;\n};\n\n/**\n * Adds a value to a subject. If the value is an array, all values in the\n * array will be added.\n *\n * @param subject the subject to add the value to.\n * @param property the property that relates the value to the subject.\n * @param value the value to add.\n * @param [options] the options to use:\n *        [propertyIsArray] true if the property is always an array, false\n *          if not (default: false).\n *        [allowDuplicate] true to allow duplicates, false not to (uses a\n *          simple shallow comparison of subject ID or value) (default: true).\n */\njsonld.addValue = function(subject, property, value, options) {\n  options = options || {};\n  if(!('propertyIsArray' in options)) {\n    options.propertyIsArray = false;\n  }\n  if(!('allowDuplicate' in options)) {\n    options.allowDuplicate = true;\n  }\n\n  if(_isArray(value)) {\n    if(value.length === 0 && options.propertyIsArray &&\n      !(property in subject)) {\n      subject[property] = [];\n    }\n    for(var i = 0; i < value.length; ++i) {\n      jsonld.addValue(subject, property, value[i], options);\n    }\n  } else if(property in subject) {\n    // check if subject already has value if duplicates not allowed\n    var hasValue = (!options.allowDuplicate &&\n      jsonld.hasValue(subject, property, value));\n\n    // make property an array if value not present or always an array\n    if(!_isArray(subject[property]) &&\n      (!hasValue || options.propertyIsArray)) {\n      subject[property] = [subject[property]];\n    }\n\n    // add new value\n    if(!hasValue) {\n      subject[property].push(value);\n    }\n  } else {\n    // add new value as set or single value\n    subject[property] = options.propertyIsArray ? [value] : value;\n  }\n};\n\n/**\n * Gets all of the values for a subject's property as an array.\n *\n * @param subject the subject.\n * @param property the property.\n *\n * @return all of the values for a subject's property as an array.\n */\njsonld.getValues = function(subject, property) {\n  var rval = subject[property] || [];\n  if(!_isArray(rval)) {\n    rval = [rval];\n  }\n  return rval;\n};\n\n/**\n * Removes a property from a subject.\n *\n * @param subject the subject.\n * @param property the property.\n */\njsonld.removeProperty = function(subject, property) {\n  delete subject[property];\n};\n\n/**\n * Removes a value from a subject.\n *\n * @param subject the subject.\n * @param property the property that relates the value to the subject.\n * @param value the value to remove.\n * @param [options] the options to use:\n *          [propertyIsArray] true if the property is always an array, false\n *            if not (default: false).\n */\njsonld.removeValue = function(subject, property, value, options) {\n  options = options || {};\n  if(!('propertyIsArray' in options)) {\n    options.propertyIsArray = false;\n  }\n\n  // filter out value\n  var values = jsonld.getValues(subject, property).filter(function(e) {\n    return !jsonld.compareValues(e, value);\n  });\n\n  if(values.length === 0) {\n    jsonld.removeProperty(subject, property);\n  } else if(values.length === 1 && !options.propertyIsArray) {\n    subject[property] = values[0];\n  } else {\n    subject[property] = values;\n  }\n};\n\n/**\n * Compares two JSON-LD values for equality. Two JSON-LD values will be\n * considered equal if:\n *\n * 1. They are both primitives of the same type and value.\n * 2. They are both @values with the same @value, @type, @language,\n *   and @index, OR\n * 3. They both have @ids they are the same.\n *\n * @param v1 the first value.\n * @param v2 the second value.\n *\n * @return true if v1 and v2 are considered equal, false if not.\n */\njsonld.compareValues = function(v1, v2) {\n  // 1. equal primitives\n  if(v1 === v2) {\n    return true;\n  }\n\n  // 2. equal @values\n  if(_isValue(v1) && _isValue(v2) &&\n    v1['@value'] === v2['@value'] &&\n    v1['@type'] === v2['@type'] &&\n    v1['@language'] === v2['@language'] &&\n    v1['@index'] === v2['@index']) {\n    return true;\n  }\n\n  // 3. equal @ids\n  if(_isObject(v1) && ('@id' in v1) && _isObject(v2) && ('@id' in v2)) {\n    return v1['@id'] === v2['@id'];\n  }\n\n  return false;\n};\n\n/**\n * Gets the value for the given active context key and type, null if none is\n * set.\n *\n * @param ctx the active context.\n * @param key the context key.\n * @param [type] the type of value to get (eg: '@id', '@type'), if not\n *          specified gets the entire entry for a key, null if not found.\n *\n * @return the value.\n */\njsonld.getContextValue = function(ctx, key, type) {\n  var rval = null;\n\n  // return null for invalid key\n  if(key === null) {\n    return rval;\n  }\n\n  // get default language\n  if(type === '@language' && (type in ctx)) {\n    rval = ctx[type];\n  }\n\n  // get specific entry information\n  if(ctx.mappings[key]) {\n    var entry = ctx.mappings[key];\n\n    if(_isUndefined(type)) {\n      // return whole entry\n      rval = entry;\n    } else if(type in entry) {\n      // return entry value for type\n      rval = entry[type];\n    }\n  }\n\n  return rval;\n};\n\n/** Registered RDF dataset parsers hashed by content-type. */\nvar _rdfParsers = {};\n\n/**\n * Registers an RDF dataset parser by content-type, for use with\n * jsonld.fromRDF. An RDF dataset parser will always be given two parameters,\n * a string of input and a callback. An RDF dataset parser can be synchronous\n * or asynchronous.\n *\n * If the parser function returns undefined or null then it will be assumed to\n * be asynchronous w/a continuation-passing style and the callback parameter\n * given to the parser MUST be invoked.\n *\n * If it returns a Promise, then it will be assumed to be asynchronous, but the\n * callback parameter MUST NOT be invoked. It should instead be ignored.\n *\n * If it returns an RDF dataset, it will be assumed to be synchronous and the\n * callback parameter MUST NOT be invoked. It should instead be ignored.\n *\n * @param contentType the content-type for the parser.\n * @param parser(input, callback(err, dataset)) the parser function (takes a\n *          string as a parameter and either returns null/undefined and uses\n *          the given callback, returns a Promise, or returns an RDF dataset).\n */\njsonld.registerRDFParser = function(contentType, parser) {\n  _rdfParsers[contentType] = parser;\n};\n\n/**\n * Unregisters an RDF dataset parser by content-type.\n *\n * @param contentType the content-type for the parser.\n */\njsonld.unregisterRDFParser = function(contentType) {\n  delete _rdfParsers[contentType];\n};\n\nif(_nodejs) {\n  // needed for serialization of XML literals\n  if(typeof XMLSerializer === 'undefined') {\n    var XMLSerializer = null;\n  }\n  if(typeof Node === 'undefined') {\n    var Node = {\n      ELEMENT_NODE: 1,\n      ATTRIBUTE_NODE: 2,\n      TEXT_NODE: 3,\n      CDATA_SECTION_NODE: 4,\n      ENTITY_REFERENCE_NODE: 5,\n      ENTITY_NODE: 6,\n      PROCESSING_INSTRUCTION_NODE: 7,\n      COMMENT_NODE: 8,\n      DOCUMENT_NODE: 9,\n      DOCUMENT_TYPE_NODE: 10,\n      DOCUMENT_FRAGMENT_NODE: 11,\n      NOTATION_NODE:12\n    };\n  }\n}\n\n// constants\nvar XSD_BOOLEAN = 'http://www.w3.org/2001/XMLSchema#boolean';\nvar XSD_DOUBLE = 'http://www.w3.org/2001/XMLSchema#double';\nvar XSD_INTEGER = 'http://www.w3.org/2001/XMLSchema#integer';\nvar XSD_STRING = 'http://www.w3.org/2001/XMLSchema#string';\n\nvar RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';\nvar RDF_LIST = RDF + 'List';\nvar RDF_FIRST = RDF + 'first';\nvar RDF_REST = RDF + 'rest';\nvar RDF_NIL = RDF + 'nil';\nvar RDF_TYPE = RDF + 'type';\nvar RDF_PLAIN_LITERAL = RDF + 'PlainLiteral';\nvar RDF_XML_LITERAL = RDF + 'XMLLiteral';\nvar RDF_OBJECT = RDF + 'object';\nvar RDF_LANGSTRING = RDF + 'langString';\n\nvar LINK_HEADER_REL = 'http://www.w3.org/ns/json-ld#context';\nvar MAX_CONTEXT_URLS = 10;\n\n/**\n * A JSON-LD Error.\n *\n * @param msg the error message.\n * @param type the error type.\n * @param details the error details.\n */\nvar JsonLdError = function(msg, type, details) {\n  if(_nodejs) {\n    Error.call(this);\n    Error.captureStackTrace(this, this.constructor);\n  } else if(typeof Error !== 'undefined') {\n    this.stack = (new Error()).stack;\n  }\n  this.name = type || 'jsonld.Error';\n  this.message = msg || 'An unspecified JSON-LD error occurred.';\n  this.details = details || {};\n};\nif(_nodejs) {\n  require('util').inherits(JsonLdError, Error);\n} else if(typeof Error !== 'undefined') {\n  JsonLdError.prototype = new Error();\n}\n\n/**\n * Constructs a new JSON-LD Processor.\n */\nvar Processor = function() {};\n\n/**\n * Recursively compacts an element using the given active context. All values\n * must be in expanded form before this method is called.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the compacted property associated with the element\n *          to compact, null for none.\n * @param element the element to compact.\n * @param options the compaction options.\n *\n * @return the compacted value.\n */\nProcessor.prototype.compact = function(\n  activeCtx, activeProperty, element, options) {\n  // recursively compact array\n  if(_isArray(element)) {\n    var rval = [];\n    for(var i = 0; i < element.length; ++i) {\n      // compact, dropping any null values\n      var compacted = this.compact(\n        activeCtx, activeProperty, element[i], options);\n      if(compacted !== null) {\n        rval.push(compacted);\n      }\n    }\n    if(options.compactArrays && rval.length === 1) {\n      // use single element if no container is specified\n      var container = jsonld.getContextValue(\n        activeCtx, activeProperty, '@container');\n      if(container === null) {\n        rval = rval[0];\n      }\n    }\n    return rval;\n  }\n\n  // recursively compact object\n  if(_isObject(element)) {\n    if(options.link && '@id' in element && element['@id'] in options.link) {\n      // check for a linked element to reuse\n      var linked = options.link[element['@id']];\n      for(var i = 0; i < linked.length; ++i) {\n        if(linked[i].expanded === element) {\n          return linked[i].compacted;\n        }\n      }\n    }\n\n    // do value compaction on @values and subject references\n    if(_isValue(element) || _isSubjectReference(element)) {\n      var rval = _compactValue(activeCtx, activeProperty, element);\n      if(options.link && _isSubjectReference(element)) {\n        // store linked element\n        if(!(element['@id'] in options.link)) {\n          options.link[element['@id']] = [];\n        }\n        options.link[element['@id']].push({expanded: element, compacted: rval});\n      }\n      return rval;\n    }\n\n    // FIXME: avoid misuse of active property as an expanded property?\n    var insideReverse = (activeProperty === '@reverse');\n\n    var rval = {};\n\n    if(options.link && '@id' in element) {\n      // store linked element\n      if(!(element['@id'] in options.link)) {\n        options.link[element['@id']] = [];\n      }\n      options.link[element['@id']].push({expanded: element, compacted: rval});\n    }\n\n    // process element keys in order\n    var keys = Object.keys(element).sort();\n    for(var ki = 0; ki < keys.length; ++ki) {\n      var expandedProperty = keys[ki];\n      var expandedValue = element[expandedProperty];\n\n      // compact @id and @type(s)\n      if(expandedProperty === '@id' || expandedProperty === '@type') {\n        var compactedValue;\n\n        // compact single @id\n        if(_isString(expandedValue)) {\n          compactedValue = _compactIri(\n            activeCtx, expandedValue, null,\n            {vocab: (expandedProperty === '@type')});\n        } else {\n          // expanded value must be a @type array\n          compactedValue = [];\n          for(var vi = 0; vi < expandedValue.length; ++vi) {\n            compactedValue.push(_compactIri(\n              activeCtx, expandedValue[vi], null, {vocab: true}));\n          }\n        }\n\n        // use keyword alias and add value\n        var alias = _compactIri(activeCtx, expandedProperty);\n        var isArray = (_isArray(compactedValue) && expandedValue.length === 0);\n        jsonld.addValue(\n          rval, alias, compactedValue, {propertyIsArray: isArray});\n        continue;\n      }\n\n      // handle @reverse\n      if(expandedProperty === '@reverse') {\n        // recursively compact expanded value\n        var compactedValue = this.compact(\n          activeCtx, '@reverse', expandedValue, options);\n\n        // handle double-reversed properties\n        for(var compactedProperty in compactedValue) {\n          if(activeCtx.mappings[compactedProperty] &&\n            activeCtx.mappings[compactedProperty].reverse) {\n            var value = compactedValue[compactedProperty];\n            var container = jsonld.getContextValue(\n              activeCtx, compactedProperty, '@container');\n            var useArray = (container === '@set' || !options.compactArrays);\n            jsonld.addValue(\n              rval, compactedProperty, value, {propertyIsArray: useArray});\n            delete compactedValue[compactedProperty];\n          }\n        }\n\n        if(Object.keys(compactedValue).length > 0) {\n          // use keyword alias and add value\n          var alias = _compactIri(activeCtx, expandedProperty);\n          jsonld.addValue(rval, alias, compactedValue);\n        }\n\n        continue;\n      }\n\n      // handle @index property\n      if(expandedProperty === '@index') {\n        // drop @index if inside an @index container\n        var container = jsonld.getContextValue(\n          activeCtx, activeProperty, '@container');\n        if(container === '@index') {\n          continue;\n        }\n\n        // use keyword alias and add value\n        var alias = _compactIri(activeCtx, expandedProperty);\n        jsonld.addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // skip array processing for keywords that aren't @graph or @list\n      if(expandedProperty !== '@graph' && expandedProperty !== '@list' &&\n        _isKeyword(expandedProperty)) {\n        // use keyword alias and add value as is\n        var alias = _compactIri(activeCtx, expandedProperty);\n        jsonld.addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // Note: expanded value must be an array due to expansion algorithm.\n\n      // preserve empty arrays\n      if(expandedValue.length === 0) {\n        var itemActiveProperty = _compactIri(\n          activeCtx, expandedProperty, expandedValue, {vocab: true},\n          insideReverse);\n        jsonld.addValue(\n          rval, itemActiveProperty, expandedValue, {propertyIsArray: true});\n      }\n\n      // recusively process array values\n      for(var vi = 0; vi < expandedValue.length; ++vi) {\n        var expandedItem = expandedValue[vi];\n\n        // compact property and get container type\n        var itemActiveProperty = _compactIri(\n          activeCtx, expandedProperty, expandedItem, {vocab: true},\n          insideReverse);\n        var container = jsonld.getContextValue(\n          activeCtx, itemActiveProperty, '@container');\n\n        // get @list value if appropriate\n        var isList = _isList(expandedItem);\n        var list = null;\n        if(isList) {\n          list = expandedItem['@list'];\n        }\n\n        // recursively compact expanded item\n        var compactedItem = this.compact(\n          activeCtx, itemActiveProperty, isList ? list : expandedItem, options);\n\n        // handle @list\n        if(isList) {\n          // ensure @list value is an array\n          if(!_isArray(compactedItem)) {\n            compactedItem = [compactedItem];\n          }\n\n          if(container !== '@list') {\n            // wrap using @list alias\n            var wrapper = {};\n            wrapper[_compactIri(activeCtx, '@list')] = compactedItem;\n            compactedItem = wrapper;\n\n            // include @index from expanded @list, if any\n            if('@index' in expandedItem) {\n              compactedItem[_compactIri(activeCtx, '@index')] =\n                expandedItem['@index'];\n            }\n          } else if(itemActiveProperty in rval) {\n            // can't use @list container for more than 1 list\n            throw new JsonLdError(\n              'JSON-LD compact error; property has a \"@list\" @container ' +\n              'rule but there is more than a single @list that matches ' +\n              'the compacted term in the document. Compaction might mix ' +\n              'unwanted items into the list.',\n              'jsonld.SyntaxError', {code: 'compaction to list of lists'});\n          }\n        }\n\n        // handle language and index maps\n        if(container === '@language' || container === '@index') {\n          // get or create the map object\n          var mapObject;\n          if(itemActiveProperty in rval) {\n            mapObject = rval[itemActiveProperty];\n          } else {\n            rval[itemActiveProperty] = mapObject = {};\n          }\n\n          // if container is a language map, simplify compacted value to\n          // a simple string\n          if(container === '@language' && _isValue(compactedItem)) {\n            compactedItem = compactedItem['@value'];\n          }\n\n          // add compact value to map object using key from expanded value\n          // based on the container type\n          jsonld.addValue(mapObject, expandedItem[container], compactedItem);\n        } else {\n          // use an array if: compactArrays flag is false,\n          // @container is @set or @list , value is an empty\n          // array, or key is @graph\n          var isArray = (!options.compactArrays || container === '@set' ||\n            container === '@list' ||\n            (_isArray(compactedItem) && compactedItem.length === 0) ||\n            expandedProperty === '@list' || expandedProperty === '@graph');\n\n          // add compact value\n          jsonld.addValue(\n            rval, itemActiveProperty, compactedItem,\n            {propertyIsArray: isArray});\n        }\n      }\n    }\n\n    return rval;\n  }\n\n  // only primitives remain which are already compact\n  return element;\n};\n\n/**\n * Recursively expands an element using the given context. Any context in\n * the element will be removed. All context URLs must have been retrieved\n * before calling this method.\n *\n * @param activeCtx the context to use.\n * @param activeProperty the property for the element, null for none.\n * @param element the element to expand.\n * @param options the expansion options.\n * @param insideList true if the element is a list, false if not.\n *\n * @return the expanded value.\n */\nProcessor.prototype.expand = function(\n  activeCtx, activeProperty, element, options, insideList) {\n  var self = this;\n\n  // nothing to expand\n  if(element === null || element === undefined) {\n    return null;\n  }\n\n  if(!_isArray(element) && !_isObject(element)) {\n    // drop free-floating scalars that are not in lists\n    if(!insideList && (activeProperty === null ||\n      _expandIri(activeCtx, activeProperty, {vocab: true}) === '@graph')) {\n      return null;\n    }\n\n    // expand element according to value expansion rules\n    return _expandValue(activeCtx, activeProperty, element);\n  }\n\n  // recursively expand array\n  if(_isArray(element)) {\n    var rval = [];\n    var container = jsonld.getContextValue(\n      activeCtx, activeProperty, '@container');\n    insideList = insideList || container === '@list';\n    for(var i = 0; i < element.length; ++i) {\n      // expand element\n      var e = self.expand(activeCtx, activeProperty, element[i], options);\n      if(insideList && (_isArray(e) || _isList(e))) {\n        // lists of lists are illegal\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; lists of lists are not permitted.',\n          'jsonld.SyntaxError', {code: 'list of lists'});\n      }\n      // drop null values\n      if(e !== null) {\n        if(_isArray(e)) {\n          rval = rval.concat(e);\n        } else {\n          rval.push(e);\n        }\n      }\n    }\n    return rval;\n  }\n\n  // recursively expand object:\n\n  // if element has a context, process it\n  if('@context' in element) {\n    activeCtx = self.processContext(activeCtx, element['@context'], options);\n  }\n\n  // expand the active property\n  var expandedActiveProperty = _expandIri(\n    activeCtx, activeProperty, {vocab: true});\n\n  var rval = {};\n  var keys = Object.keys(element).sort();\n  for(var ki = 0; ki < keys.length; ++ki) {\n    var key = keys[ki];\n    var value = element[key];\n    var expandedValue;\n\n    // skip @context\n    if(key === '@context') {\n      continue;\n    }\n\n    // expand property\n    var expandedProperty = _expandIri(activeCtx, key, {vocab: true});\n\n    // drop non-absolute IRI keys that aren't keywords\n    if(expandedProperty === null ||\n      !(_isAbsoluteIri(expandedProperty) || _isKeyword(expandedProperty))) {\n      continue;\n    }\n\n    if(_isKeyword(expandedProperty)) {\n      if(expandedActiveProperty === '@reverse') {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a keyword cannot be used as a @reverse ' +\n          'property.', 'jsonld.SyntaxError',\n          {code: 'invalid reverse property map', value: value});\n      }\n      if(expandedProperty in rval) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; colliding keywords detected.',\n          'jsonld.SyntaxError',\n          {code: 'colliding keywords', keyword: expandedProperty});\n      }\n    }\n\n    // syntax error if @id is not a string\n    if(expandedProperty === '@id' && !_isString(value)) {\n      if(!options.isFrame) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@id\" value must a string.',\n          'jsonld.SyntaxError', {code: 'invalid @id value', value: value});\n      }\n      if(!_isObject(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@id\" value must be a string or an ' +\n          'object.', 'jsonld.SyntaxError',\n          {code: 'invalid @id value', value: value});\n      }\n    }\n\n    if(expandedProperty === '@type') {\n      _validateTypeValue(value);\n    }\n\n    // @graph must be an array or an object\n    if(expandedProperty === '@graph' &&\n      !(_isObject(value) || _isArray(value))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; \"@graph\" value must not be an ' +\n        'object or an array.',\n        'jsonld.SyntaxError', {code: 'invalid @graph value', value: value});\n    }\n\n    // @value must not be an object or an array\n    if(expandedProperty === '@value' &&\n      (_isObject(value) || _isArray(value))) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; \"@value\" value must not be an ' +\n        'object or an array.',\n        'jsonld.SyntaxError',\n        {code: 'invalid value object value', value: value});\n    }\n\n    // @language must be a string\n    if(expandedProperty === '@language') {\n      if(value === null) {\n        // drop null @language values, they expand as if they didn't exist\n        continue;\n      }\n      if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@language\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid language-tagged string', value: value});\n      }\n      // ensure language value is lowercase\n      value = value.toLowerCase();\n    }\n\n    // @index must be a string\n    if(expandedProperty === '@index') {\n      if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@index\" value must be a string.',\n          'jsonld.SyntaxError',\n          {code: 'invalid @index value', value: value});\n      }\n    }\n\n    // @reverse must be an object\n    if(expandedProperty === '@reverse') {\n      if(!_isObject(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; \"@reverse\" value must be an object.',\n          'jsonld.SyntaxError', {code: 'invalid @reverse value', value: value});\n      }\n\n      expandedValue = self.expand(activeCtx, '@reverse', value, options);\n\n      // properties double-reversed\n      if('@reverse' in expandedValue) {\n        for(var property in expandedValue['@reverse']) {\n          jsonld.addValue(\n            rval, property, expandedValue['@reverse'][property],\n            {propertyIsArray: true});\n        }\n      }\n\n      // FIXME: can this be merged with code below to simplify?\n      // merge in all reversed properties\n      var reverseMap = rval['@reverse'] || null;\n      for(var property in expandedValue) {\n        if(property === '@reverse') {\n          continue;\n        }\n        if(reverseMap === null) {\n          reverseMap = rval['@reverse'] = {};\n        }\n        jsonld.addValue(reverseMap, property, [], {propertyIsArray: true});\n        var items = expandedValue[property];\n        for(var ii = 0; ii < items.length; ++ii) {\n          var item = items[ii];\n          if(_isValue(item) || _isList(item)) {\n            throw new JsonLdError(\n              'Invalid JSON-LD syntax; \"@reverse\" value must not be a ' +\n              '@value or an @list.', 'jsonld.SyntaxError',\n              {code: 'invalid reverse property value', value: expandedValue});\n          }\n          jsonld.addValue(\n            reverseMap, property, item, {propertyIsArray: true});\n        }\n      }\n\n      continue;\n    }\n\n    var container = jsonld.getContextValue(activeCtx, key, '@container');\n\n    if(container === '@language' && _isObject(value)) {\n      // handle language map container (skip if value is not an object)\n      expandedValue = _expandLanguageMap(value);\n    } else if(container === '@index' && _isObject(value)) {\n      // handle index container (skip if value is not an object)\n      expandedValue = (function _expandIndexMap(activeProperty) {\n        var rval = [];\n        var keys = Object.keys(value).sort();\n        for(var ki = 0; ki < keys.length; ++ki) {\n          var key = keys[ki];\n          var val = value[key];\n          if(!_isArray(val)) {\n            val = [val];\n          }\n          val = self.expand(activeCtx, activeProperty, val, options, false);\n          for(var vi = 0; vi < val.length; ++vi) {\n            var item = val[vi];\n            if(!('@index' in item)) {\n              item['@index'] = key;\n            }\n            rval.push(item);\n          }\n        }\n        return rval;\n      })(key);\n    } else {\n      // recurse into @list or @set\n      var isList = (expandedProperty === '@list');\n      if(isList || expandedProperty === '@set') {\n        var nextActiveProperty = activeProperty;\n        if(isList && expandedActiveProperty === '@graph') {\n          nextActiveProperty = null;\n        }\n        expandedValue = self.expand(\n          activeCtx, nextActiveProperty, value, options, isList);\n        if(isList && _isList(expandedValue)) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; lists of lists are not permitted.',\n            'jsonld.SyntaxError', {code: 'list of lists'});\n        }\n      } else {\n        // recursively expand value with key as new active property\n        expandedValue = self.expand(activeCtx, key, value, options, false);\n      }\n    }\n\n    // drop null values if property is not @value\n    if(expandedValue === null && expandedProperty !== '@value') {\n      continue;\n    }\n\n    // convert expanded value to @list if container specifies it\n    if(expandedProperty !== '@list' && !_isList(expandedValue) &&\n      container === '@list') {\n      // ensure expanded value is an array\n      expandedValue = (_isArray(expandedValue) ?\n        expandedValue : [expandedValue]);\n      expandedValue = {'@list': expandedValue};\n    }\n\n    // FIXME: can this be merged with code above to simplify?\n    // merge in reverse properties\n    if(activeCtx.mappings[key] && activeCtx.mappings[key].reverse) {\n      var reverseMap = rval['@reverse'] = rval['@reverse'] || {};\n      if(!_isArray(expandedValue)) {\n        expandedValue = [expandedValue];\n      }\n      for(var ii = 0; ii < expandedValue.length; ++ii) {\n        var item = expandedValue[ii];\n        if(_isValue(item) || _isList(item)) {\n          throw new JsonLdError(\n            'Invalid JSON-LD syntax; \"@reverse\" value must not be a ' +\n            '@value or an @list.', 'jsonld.SyntaxError',\n            {code: 'invalid reverse property value', value: expandedValue});\n        }\n        jsonld.addValue(\n          reverseMap, expandedProperty, item, {propertyIsArray: true});\n      }\n      continue;\n    }\n\n    // add value for property\n    // use an array except for certain keywords\n    var useArray =\n      ['@index', '@id', '@type', '@value', '@language'].indexOf(\n        expandedProperty) === -1;\n    jsonld.addValue(\n      rval, expandedProperty, expandedValue, {propertyIsArray: useArray});\n  }\n\n  // get property count on expanded output\n  keys = Object.keys(rval);\n  var count = keys.length;\n\n  if('@value' in rval) {\n    // @value must only have @language or @type\n    if('@type' in rval && '@language' in rval) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" may not ' +\n        'contain both \"@type\" and \"@language\".',\n        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});\n    }\n    var validCount = count - 1;\n    if('@type' in rval) {\n      validCount -= 1;\n    }\n    if('@index' in rval) {\n      validCount -= 1;\n    }\n    if('@language' in rval) {\n      validCount -= 1;\n    }\n    if(validCount !== 0) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" may only ' +\n        'have an \"@index\" property and at most one other property ' +\n        'which can be \"@type\" or \"@language\".',\n        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});\n    }\n    // drop null @values\n    if(rval['@value'] === null) {\n      rval = null;\n    } else if('@language' in rval && !_isString(rval['@value'])) {\n      // if @language is present, @value must be a string\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; only strings may be language-tagged.',\n        'jsonld.SyntaxError',\n        {code: 'invalid language-tagged value', element: rval});\n    } else if('@type' in rval && (!_isAbsoluteIri(rval['@type']) ||\n      rval['@type'].indexOf('_:') === 0)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an element containing \"@value\" and \"@type\" ' +\n        'must have an absolute IRI for the value of \"@type\".',\n        'jsonld.SyntaxError', {code: 'invalid typed value', element: rval});\n    }\n  } else if('@type' in rval && !_isArray(rval['@type'])) {\n    // convert @type to an array\n    rval['@type'] = [rval['@type']];\n  } else if('@set' in rval || '@list' in rval) {\n    // handle @set and @list\n    if(count > 1 && !(count === 2 && '@index' in rval)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; if an element has the property \"@set\" ' +\n        'or \"@list\", then it can have at most one other property that is ' +\n        '\"@index\".', 'jsonld.SyntaxError',\n        {code: 'invalid set or list object', element: rval});\n    }\n    // optimize away @set\n    if('@set' in rval) {\n      rval = rval['@set'];\n      keys = Object.keys(rval);\n      count = keys.length;\n    }\n  } else if(count === 1 && '@language' in rval) {\n    // drop objects with only @language\n    rval = null;\n  }\n\n  // drop certain top-level objects that do not occur in lists\n  if(_isObject(rval) &&\n    !options.keepFreeFloatingNodes && !insideList &&\n    (activeProperty === null || expandedActiveProperty === '@graph')) {\n    // drop empty object, top-level @value/@list, or object with only @id\n    if(count === 0 || '@value' in rval || '@list' in rval ||\n      (count === 1 && '@id' in rval)) {\n      rval = null;\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Creates a JSON-LD node map (node ID => node).\n *\n * @param input the expanded JSON-LD to create a node map of.\n * @param [options] the options to use:\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [namer] (deprecated).\n *\n * @return the node map.\n */\nProcessor.prototype.createNodeMap = function(input, options) {\n  options = options || {};\n\n  // produce a map of all subjects and name each bnode\n  var issuer = options.namer || options.issuer || new IdentifierIssuer('_:b');\n  var graphs = {'@default': {}};\n  _createNodeMap(input, graphs, '@default', issuer);\n\n  // add all non-default graphs to default graph\n  return _mergeNodeMaps(graphs);\n};\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the expanded JSON-LD to flatten.\n *\n * @return the flattened output.\n */\nProcessor.prototype.flatten = function(input) {\n  var defaultGraph = this.createNodeMap(input);\n\n  // produce flattened output\n  var flattened = [];\n  var keys = Object.keys(defaultGraph).sort();\n  for(var ki = 0; ki < keys.length; ++ki) {\n    var node = defaultGraph[keys[ki]];\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      flattened.push(node);\n    }\n  }\n  return flattened;\n};\n\n/**\n * Performs JSON-LD framing.\n *\n * @param input the expanded JSON-LD to frame.\n * @param frame the expanded JSON-LD frame to use.\n * @param options the framing options.\n *\n * @return the framed output.\n */\nProcessor.prototype.frame = function(input, frame, options) {\n  // create framing state\n  var state = {\n    options: options,\n    graphs: {'@default': {}, '@merged': {}},\n    subjectStack: [],\n    link: {}\n  };\n\n  // produce a map of all graphs and name each bnode\n  // FIXME: currently uses subjects from @merged graph only\n  var issuer = new IdentifierIssuer('_:b');\n  _createNodeMap(input, state.graphs, '@merged', issuer);\n  state.subjects = state.graphs['@merged'];\n\n  // frame the subjects\n  var framed = [];\n  _frame(state, Object.keys(state.subjects).sort(), frame, framed, null);\n  return framed;\n};\n\n/**\n * Performs normalization on the given RDF dataset.\n *\n * @param dataset the RDF dataset to normalize.\n * @param options the normalization options.\n * @param callback(err, normalized) called once the operation completes.\n */\nProcessor.prototype.normalize = function(dataset, options, callback) {\n  if(options.algorithm === 'URDNA2015') {\n    return new URDNA2015(options).main(dataset, callback);\n  }\n  if(options.algorithm === 'URGNA2012') {\n    return new URGNA2012(options).main(dataset, callback);\n  }\n  callback(new Error(\n    'Invalid RDF Dataset Normalization algorithm: ' + options.algorithm));\n};\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset the RDF dataset.\n * @param options the RDF serialization options.\n * @param callback(err, output) called once the operation completes.\n */\nProcessor.prototype.fromRDF = function(dataset, options, callback) {\n  var defaultGraph = {};\n  var graphMap = {'@default': defaultGraph};\n  var referencedOnce = {};\n\n  for(var name in dataset) {\n    var graph = dataset[name];\n    if(!(name in graphMap)) {\n      graphMap[name] = {};\n    }\n    if(name !== '@default' && !(name in defaultGraph)) {\n      defaultGraph[name] = {'@id': name};\n    }\n    var nodeMap = graphMap[name];\n    for(var ti = 0; ti < graph.length; ++ti) {\n      var triple = graph[ti];\n\n      // get subject, predicate, object\n      var s = triple.subject.value;\n      var p = triple.predicate.value;\n      var o = triple.object;\n\n      if(!(s in nodeMap)) {\n        nodeMap[s] = {'@id': s};\n      }\n      var node = nodeMap[s];\n\n      var objectIsId = (o.type === 'IRI' || o.type === 'blank node');\n      if(objectIsId && !(o.value in nodeMap)) {\n        nodeMap[o.value] = {'@id': o.value};\n      }\n\n      if(p === RDF_TYPE && !options.useRdfType && objectIsId) {\n        jsonld.addValue(node, '@type', o.value, {propertyIsArray: true});\n        continue;\n      }\n\n      var value = _RDFToObject(o, options.useNativeTypes);\n      jsonld.addValue(node, p, value, {propertyIsArray: true});\n\n      // object may be an RDF list/partial list node but we can't know easily\n      // until all triples are read\n      if(objectIsId) {\n        if(o.value === RDF_NIL) {\n          // track rdf:nil uniquely per graph\n          var object = nodeMap[o.value];\n          if(!('usages' in object)) {\n            object.usages = [];\n          }\n          object.usages.push({\n            node: node,\n            property: p,\n            value: value\n          });\n        } else if(o.value in referencedOnce) {\n          // object referenced more than once\n          referencedOnce[o.value] = false;\n        } else {\n          // keep track of single reference\n          referencedOnce[o.value] = {\n            node: node,\n            property: p,\n            value: value\n          };\n        }\n      }\n    }\n  }\n\n  // convert linked lists to @list arrays\n  for(var name in graphMap) {\n    var graphObject = graphMap[name];\n\n    // no @lists to be converted, continue\n    if(!(RDF_NIL in graphObject)) {\n      continue;\n    }\n\n    // iterate backwards through each RDF list\n    var nil = graphObject[RDF_NIL];\n    for(var i = 0; i < nil.usages.length; ++i) {\n      var usage = nil.usages[i];\n      var node = usage.node;\n      var property = usage.property;\n      var head = usage.value;\n      var list = [];\n      var listNodes = [];\n\n      // ensure node is a well-formed list node; it must:\n      // 1. Be referenced only once.\n      // 2. Have an array for rdf:first that has 1 item.\n      // 3. Have an array for rdf:rest that has 1 item.\n      // 4. Have no keys other than: @id, rdf:first, rdf:rest, and,\n      //   optionally, @type where the value is rdf:List.\n      var nodeKeyCount = Object.keys(node).length;\n      while(property === RDF_REST &&\n        _isObject(referencedOnce[node['@id']]) &&\n        _isArray(node[RDF_FIRST]) && node[RDF_FIRST].length === 1 &&\n        _isArray(node[RDF_REST]) && node[RDF_REST].length === 1 &&\n        (nodeKeyCount === 3 || (nodeKeyCount === 4 && _isArray(node['@type']) &&\n          node['@type'].length === 1 && node['@type'][0] === RDF_LIST))) {\n        list.push(node[RDF_FIRST][0]);\n        listNodes.push(node['@id']);\n\n        // get next node, moving backwards through list\n        usage = referencedOnce[node['@id']];\n        node = usage.node;\n        property = usage.property;\n        head = usage.value;\n        nodeKeyCount = Object.keys(node).length;\n\n        // if node is not a blank node, then list head found\n        if(node['@id'].indexOf('_:') !== 0) {\n          break;\n        }\n      }\n\n      // the list is nested in another list\n      if(property === RDF_FIRST) {\n        // empty list\n        if(node['@id'] === RDF_NIL) {\n          // can't convert rdf:nil to a @list object because it would\n          // result in a list of lists which isn't supported\n          continue;\n        }\n\n        // preserve list head\n        head = graphObject[head['@id']][RDF_REST][0];\n        list.pop();\n        listNodes.pop();\n      }\n\n      // transform list into @list object\n      delete head['@id'];\n      head['@list'] = list.reverse();\n      for(var j = 0; j < listNodes.length; ++j) {\n        delete graphObject[listNodes[j]];\n      }\n    }\n\n    delete nil.usages;\n  }\n\n  var result = [];\n  var subjects = Object.keys(defaultGraph).sort();\n  for(var i = 0; i < subjects.length; ++i) {\n    var subject = subjects[i];\n    var node = defaultGraph[subject];\n    if(subject in graphMap) {\n      var graph = node['@graph'] = [];\n      var graphObject = graphMap[subject];\n      var subjects_ = Object.keys(graphObject).sort();\n      for(var si = 0; si < subjects_.length; ++si) {\n        var node_ = graphObject[subjects_[si]];\n        // only add full subjects to top-level\n        if(!_isSubjectReference(node_)) {\n          graph.push(node_);\n        }\n      }\n    }\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      result.push(node);\n    }\n  }\n\n  callback(null, result);\n};\n\n/**\n * Outputs an RDF dataset for the expanded JSON-LD input.\n *\n * @param input the expanded JSON-LD input.\n * @param options the RDF serialization options.\n *\n * @return the RDF dataset.\n */\nProcessor.prototype.toRDF = function(input, options) {\n  // create node map for default graph (and any named graphs)\n  var issuer = new IdentifierIssuer('_:b');\n  var nodeMap = {'@default': {}};\n  _createNodeMap(input, nodeMap, '@default', issuer);\n\n  var dataset = {};\n  var graphNames = Object.keys(nodeMap).sort();\n  for(var i = 0; i < graphNames.length; ++i) {\n    var graphName = graphNames[i];\n    // skip relative IRIs\n    if(graphName === '@default' || _isAbsoluteIri(graphName)) {\n      dataset[graphName] = _graphToRDF(nodeMap[graphName], issuer, options);\n    }\n  }\n  return dataset;\n};\n\n/**\n * Processes a local context and returns a new active context.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param options the context processing options.\n *\n * @return the new active context.\n */\nProcessor.prototype.processContext = function(activeCtx, localCtx, options) {\n  // normalize local context to an array of @context objects\n  if(_isObject(localCtx) && '@context' in localCtx &&\n    _isArray(localCtx['@context'])) {\n    localCtx = localCtx['@context'];\n  }\n  var ctxs = _isArray(localCtx) ? localCtx : [localCtx];\n\n  // no contexts in array, clone existing context\n  if(ctxs.length === 0) {\n    return activeCtx.clone();\n  }\n\n  // process each context in order, update active context\n  // on each iteration to ensure proper caching\n  var rval = activeCtx;\n  for(var i = 0; i < ctxs.length; ++i) {\n    var ctx = ctxs[i];\n\n    // reset to initial context\n    if(ctx === null) {\n      rval = activeCtx = _getInitialContext(options);\n      continue;\n    }\n\n    // dereference @context key if present\n    if(_isObject(ctx) && '@context' in ctx) {\n      ctx = ctx['@context'];\n    }\n\n    // context must be an object by now, all URLs retrieved before this call\n    if(!_isObject(ctx)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context must be an object.',\n        'jsonld.SyntaxError', {code: 'invalid local context', context: ctx});\n    }\n\n    // get context from cache if available\n    if(jsonld.cache.activeCtx) {\n      var cached = jsonld.cache.activeCtx.get(activeCtx, ctx);\n      if(cached) {\n        rval = activeCtx = cached;\n        continue;\n      }\n    }\n\n    // update active context and clone new one before updating\n    activeCtx = rval;\n    rval = rval.clone();\n\n    // define context mappings for keys in local context\n    var defined = {};\n\n    // handle @base\n    if('@base' in ctx) {\n      var base = ctx['@base'];\n\n      // clear base\n      if(base === null) {\n        base = null;\n      } else if(!_isString(base)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@base\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});\n      } else if(base !== '' && !_isAbsoluteIri(base)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@base\" in a ' +\n          '@context must be an absolute IRI or the empty string.',\n          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});\n      }\n\n      if(base !== null) {\n        base = jsonld.url.parse(base || '');\n      }\n      rval['@base'] = base;\n      defined['@base'] = true;\n    }\n\n    // handle @vocab\n    if('@vocab' in ctx) {\n      var value = ctx['@vocab'];\n      if(value === null) {\n        delete rval['@vocab'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else if(!_isAbsoluteIri(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@vocab\" in a ' +\n          '@context must be an absolute IRI.',\n          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});\n      } else {\n        rval['@vocab'] = value;\n      }\n      defined['@vocab'] = true;\n    }\n\n    // handle @language\n    if('@language' in ctx) {\n      var value = ctx['@language'];\n      if(value === null) {\n        delete rval['@language'];\n      } else if(!_isString(value)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; the value of \"@language\" in a ' +\n          '@context must be a string or null.',\n          'jsonld.SyntaxError',\n          {code: 'invalid default language', context: ctx});\n      } else {\n        rval['@language'] = value.toLowerCase();\n      }\n      defined['@language'] = true;\n    }\n\n    // process all other keys\n    for(var key in ctx) {\n      _createTermDefinition(rval, ctx, key, defined);\n    }\n\n    // cache result\n    if(jsonld.cache.activeCtx) {\n      jsonld.cache.activeCtx.set(activeCtx, ctx, rval);\n    }\n  }\n\n  return rval;\n};\n\n/**\n * Expands a language map.\n *\n * @param languageMap the language map to expand.\n *\n * @return the expanded language map.\n */\nfunction _expandLanguageMap(languageMap) {\n  var rval = [];\n  var keys = Object.keys(languageMap).sort();\n  for(var ki = 0; ki < keys.length; ++ki) {\n    var key = keys[ki];\n    var val = languageMap[key];\n    if(!_isArray(val)) {\n      val = [val];\n    }\n    for(var vi = 0; vi < val.length; ++vi) {\n      var item = val[vi];\n      if(item === null) {\n          // null values are allowed (8.5) but ignored (3.1)\n          continue;\n      }\n      if(!_isString(item)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; language map values must be strings.',\n          'jsonld.SyntaxError',\n          {code: 'invalid language map value', languageMap: languageMap});\n      }\n      rval.push({\n        '@value': item,\n        '@language': key.toLowerCase()\n      });\n    }\n  }\n  return rval;\n}\n\n/**\n * Labels the blank nodes in the given value using the given IdentifierIssuer.\n *\n * @param issuer the IdentifierIssuer to use.\n * @param element the element with blank nodes to rename.\n *\n * @return the element.\n */\nfunction _labelBlankNodes(issuer, element) {\n  if(_isArray(element)) {\n    for(var i = 0; i < element.length; ++i) {\n      element[i] = _labelBlankNodes(issuer, element[i]);\n    }\n  } else if(_isList(element)) {\n    element['@list'] = _labelBlankNodes(issuer, element['@list']);\n  } else if(_isObject(element)) {\n    // relabel blank node\n    if(_isBlankNode(element)) {\n      element['@id'] = issuer.getId(element['@id']);\n    }\n\n    // recursively apply to all keys\n    var keys = Object.keys(element).sort();\n    for(var ki = 0; ki < keys.length; ++ki) {\n      var key = keys[ki];\n      if(key !== '@id') {\n        element[key] = _labelBlankNodes(issuer, element[key]);\n      }\n    }\n  }\n\n  return element;\n}\n\n/**\n * Expands the given value by using the coercion and keyword rules in the\n * given context.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the active property the value is associated with.\n * @param value the value to expand.\n *\n * @return the expanded value.\n */\nfunction _expandValue(activeCtx, activeProperty, value) {\n  // nothing to expand\n  if(value === null || value === undefined) {\n    return null;\n  }\n\n  // special-case expand @id and @type (skips '@id' expansion)\n  var expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true});\n  if(expandedProperty === '@id') {\n    return _expandIri(activeCtx, value, {base: true});\n  } else if(expandedProperty === '@type') {\n    return _expandIri(activeCtx, value, {vocab: true, base: true});\n  }\n\n  // get type definition from context\n  var type = jsonld.getContextValue(activeCtx, activeProperty, '@type');\n\n  // do @id expansion (automatic for @graph)\n  if(type === '@id' || (expandedProperty === '@graph' && _isString(value))) {\n    return {'@id': _expandIri(activeCtx, value, {base: true})};\n  }\n  // do @id expansion w/vocab\n  if(type === '@vocab') {\n    return {'@id': _expandIri(activeCtx, value, {vocab: true, base: true})};\n  }\n\n  // do not expand keyword values\n  if(_isKeyword(expandedProperty)) {\n    return value;\n  }\n\n  var rval = {};\n\n  if(type !== null) {\n    // other type\n    rval['@type'] = type;\n  } else if(_isString(value)) {\n    // check for language tagging for strings\n    var language = jsonld.getContextValue(\n      activeCtx, activeProperty, '@language');\n    if(language !== null) {\n      rval['@language'] = language;\n    }\n  }\n  // do conversion of values that aren't basic JSON types to strings\n  if(['boolean', 'number', 'string'].indexOf(typeof value) === -1) {\n    value = value.toString();\n  }\n  rval['@value'] = value;\n\n  return rval;\n}\n\n/**\n * Creates an array of RDF triples for the given graph.\n *\n * @param graph the graph to create RDF triples for.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param options the RDF serialization options.\n *\n * @return the array of RDF triples for the given graph.\n */\nfunction _graphToRDF(graph, issuer, options) {\n  var rval = [];\n\n  var ids = Object.keys(graph).sort();\n  for(var i = 0; i < ids.length; ++i) {\n    var id = ids[i];\n    var node = graph[id];\n    var properties = Object.keys(node).sort();\n    for(var pi = 0; pi < properties.length; ++pi) {\n      var property = properties[pi];\n      var items = node[property];\n      if(property === '@type') {\n        property = RDF_TYPE;\n      } else if(_isKeyword(property)) {\n        continue;\n      }\n\n      for(var ii = 0; ii < items.length; ++ii) {\n        var item = items[ii];\n\n        // RDF subject\n        var subject = {};\n        subject.type = (id.indexOf('_:') === 0) ? 'blank node' : 'IRI';\n        subject.value = id;\n\n        // skip relative IRI subjects\n        if(!_isAbsoluteIri(id)) {\n          continue;\n        }\n\n        // RDF predicate\n        var predicate = {};\n        predicate.type = (property.indexOf('_:') === 0) ? 'blank node' : 'IRI';\n        predicate.value = property;\n\n        // skip relative IRI predicates\n        if(!_isAbsoluteIri(property)) {\n          continue;\n        }\n\n        // skip blank node predicates unless producing generalized RDF\n        if(predicate.type === 'blank node' && !options.produceGeneralizedRdf) {\n          continue;\n        }\n\n        // convert @list to triples\n        if(_isList(item)) {\n          _listToRDF(item['@list'], issuer, subject, predicate, rval);\n        } else {\n          // convert value or node object to triple\n          var object = _objectToRDF(item);\n          // skip null objects (they are relative IRIs)\n          if(object) {\n            rval.push({subject: subject, predicate: predicate, object: object});\n          }\n        }\n      }\n    }\n  }\n\n  return rval;\n}\n\n/**\n * Converts a @list value into linked list of blank node RDF triples\n * (an RDF collection).\n *\n * @param list the @list value.\n * @param issuer a IdentifierIssuer for assigning blank node names.\n * @param subject the subject for the head of the list.\n * @param predicate the predicate for the head of the list.\n * @param triples the array of triples to append to.\n */\nfunction _listToRDF(list, issuer, subject, predicate, triples) {\n  var first = {type: 'IRI', value: RDF_FIRST};\n  var rest = {type: 'IRI', value: RDF_REST};\n  var nil = {type: 'IRI', value: RDF_NIL};\n\n  for(var i = 0; i < list.length; ++i) {\n    var item = list[i];\n\n    var blankNode = {type: 'blank node', value: issuer.getId()};\n    triples.push({subject: subject, predicate: predicate, object: blankNode});\n\n    subject = blankNode;\n    predicate = first;\n    var object = _objectToRDF(item);\n\n    // skip null objects (they are relative IRIs)\n    if(object) {\n      triples.push({subject: subject, predicate: predicate, object: object});\n    }\n\n    predicate = rest;\n  }\n\n  triples.push({subject: subject, predicate: predicate, object: nil});\n}\n\n/**\n * Converts a JSON-LD value object to an RDF literal or a JSON-LD string or\n * node object to an RDF resource.\n *\n * @param item the JSON-LD value or node object.\n *\n * @return the RDF literal or RDF resource.\n */\nfunction _objectToRDF(item) {\n  var object = {};\n\n  // convert value object to RDF\n  if(_isValue(item)) {\n    object.type = 'literal';\n    var value = item['@value'];\n    var datatype = item['@type'] || null;\n\n    // convert to XSD datatypes as appropriate\n    if(_isBoolean(value)) {\n      object.value = value.toString();\n      object.datatype = datatype || XSD_BOOLEAN;\n    } else if(_isDouble(value) || datatype === XSD_DOUBLE) {\n      if(!_isDouble(value)) {\n        value = parseFloat(value);\n      }\n      // canonical double representation\n      object.value = value.toExponential(15).replace(/(\\d)0*e\\+?/, '$1E');\n      object.datatype = datatype || XSD_DOUBLE;\n    } else if(_isNumber(value)) {\n      object.value = value.toFixed(0);\n      object.datatype = datatype || XSD_INTEGER;\n    } else if('@language' in item) {\n      object.value = value;\n      object.datatype = datatype || RDF_LANGSTRING;\n      object.language = item['@language'];\n    } else {\n      object.value = value;\n      object.datatype = datatype || XSD_STRING;\n    }\n  } else {\n    // convert string/node object to RDF\n    var id = _isObject(item) ? item['@id'] : item;\n    object.type = (id.indexOf('_:') === 0) ? 'blank node' : 'IRI';\n    object.value = id;\n  }\n\n  // skip relative IRIs\n  if(object.type === 'IRI' && !_isAbsoluteIri(object.value)) {\n    return null;\n  }\n\n  return object;\n}\n\n/**\n * Converts an RDF triple object to a JSON-LD object.\n *\n * @param o the RDF triple object to convert.\n * @param useNativeTypes true to output native types, false not to.\n *\n * @return the JSON-LD object.\n */\nfunction _RDFToObject(o, useNativeTypes) {\n  // convert IRI/blank node object to JSON-LD\n  if(o.type === 'IRI' || o.type === 'blank node') {\n    return {'@id': o.value};\n  }\n\n  // convert literal to JSON-LD\n  var rval = {'@value': o.value};\n\n  // add language\n  if(o.language) {\n    rval['@language'] = o.language;\n  } else {\n    var type = o.datatype;\n    if(!type) {\n      type = XSD_STRING;\n    }\n    // use native types for certain xsd types\n    if(useNativeTypes) {\n      if(type === XSD_BOOLEAN) {\n        if(rval['@value'] === 'true') {\n          rval['@value'] = true;\n        } else if(rval['@value'] === 'false') {\n          rval['@value'] = false;\n        }\n      } else if(_isNumeric(rval['@value'])) {\n        if(type === XSD_INTEGER) {\n          var i = parseInt(rval['@value'], 10);\n          if(i.toFixed(0) === rval['@value']) {\n            rval['@value'] = i;\n          }\n        } else if(type === XSD_DOUBLE) {\n          rval['@value'] = parseFloat(rval['@value']);\n        }\n      }\n      // do not add native type\n      if([XSD_BOOLEAN, XSD_INTEGER, XSD_DOUBLE, XSD_STRING]\n        .indexOf(type) === -1) {\n        rval['@type'] = type;\n      }\n    } else if(type !== XSD_STRING) {\n      rval['@type'] = type;\n    }\n  }\n\n  return rval;\n}\n\n/**\n * Compares two RDF triples for equality.\n *\n * @param t1 the first triple.\n * @param t2 the second triple.\n *\n * @return true if the triples are the same, false if not.\n */\nfunction _compareRDFTriples(t1, t2) {\n  var attrs = ['subject', 'predicate', 'object'];\n  for(var i = 0; i < attrs.length; ++i) {\n    var attr = attrs[i];\n    if(t1[attr].type !== t2[attr].type || t1[attr].value !== t2[attr].value) {\n      return false;\n    }\n  }\n  if(t1.object.language !== t2.object.language) {\n    return false;\n  }\n  if(t1.object.datatype !== t2.object.datatype) {\n    return false;\n  }\n  return true;\n}\n\n/////////////////////////////// DEFINE URDNA2015 //////////////////////////////\n\nvar URDNA2015 = (function() {\n\nvar POSITIONS = {'subject': 's', 'object': 'o', 'name': 'g'};\n\nvar Normalize = function(options) {\n  options = options || {};\n  this.name = 'URDNA2015';\n  this.options = options;\n  this.blankNodeInfo = {};\n  this.hashToBlankNodes = {};\n  this.canonicalIssuer = new IdentifierIssuer('_:c14n');\n  this.quads = [];\n  this.schedule = {};\n  if('maxCallStackDepth' in options) {\n    this.schedule.MAX_DEPTH = options.maxCallStackDepth;\n  } else {\n    this.schedule.MAX_DEPTH = 500;\n  }\n  if('maxTotalCallStackDepth' in options) {\n    this.schedule.MAX_TOTAL_DEPTH = options.maxCallStackDepth;\n  } else {\n    this.schedule.MAX_TOTAL_DEPTH = 0xFFFFFFFF;\n  }\n  this.schedule.depth = 0;\n  this.schedule.totalDepth = 0;\n  if('timeSlice' in options) {\n    this.schedule.timeSlice = options.timeSlice;\n  } else {\n    // milliseconds\n    this.schedule.timeSlice = 10;\n  }\n};\n\n// do some work in a time slice, but in serial\nNormalize.prototype.doWork = function(fn, callback) {\n  var schedule = this.schedule;\n\n  if(schedule.totalDepth >= schedule.MAX_TOTAL_DEPTH) {\n    return callback(new Error(\n      'Maximum total call stack depth exceeded; normalization aborting.'));\n  }\n\n  (function work() {\n    if(schedule.depth === schedule.MAX_DEPTH) {\n      // stack too deep, run on next tick\n      schedule.depth = 0;\n      schedule.running = false;\n      return jsonld.nextTick(work);\n    }\n\n    // if not yet running, force run\n    var now = new Date().getTime();\n    if(!schedule.running) {\n      schedule.start = new Date().getTime();\n      schedule.deadline = schedule.start + schedule.timeSlice;\n    }\n\n    // TODO: should also include an estimate of expectedWorkTime\n    if(now < schedule.deadline) {\n      schedule.running = true;\n      schedule.depth++;\n      schedule.totalDepth++;\n      return fn(function(err, result) {\n        schedule.depth--;\n        schedule.totalDepth--;\n        callback(err, result);\n      });\n    }\n\n    // not enough time left in this slice, run after letting browser\n    // do some other things\n    schedule.depth = 0;\n    schedule.running = false;\n    jsonld.setImmediate(work);\n  })();\n};\n\n// asynchronously loop\nNormalize.prototype.forEach = function(iterable, fn, callback) {\n  var self = this;\n  var iterator;\n  var idx = 0;\n  var length;\n  if(_isArray(iterable)) {\n    length = iterable.length;\n    iterator = function() {\n      if(idx === length) {\n        return false;\n      }\n      iterator.value = iterable[idx++];\n      iterator.key = idx;\n      return true;\n    };\n  } else {\n    var keys = Object.keys(iterable);\n    length = keys.length;\n    iterator = function() {\n      if(idx === length) {\n        return false;\n      }\n      iterator.key = keys[idx++];\n      iterator.value = iterable[iterator.key];\n      return true;\n    };\n  }\n\n  (function iterate(err, result) {\n    if(err) {\n      return callback(err);\n    }\n    if(iterator()) {\n      return self.doWork(function() {\n        fn(iterator.value, iterator.key, iterate);\n      });\n    }\n    callback();\n  })();\n};\n\n// asynchronous waterfall\nNormalize.prototype.waterfall = function(fns, callback) {\n  var self = this;\n  self.forEach(fns, function(fn, idx, callback) {\n    self.doWork(fn, callback);\n  }, callback);\n};\n\n// asynchronous while\nNormalize.prototype.whilst = function(condition, fn, callback) {\n  var self = this;\n  (function loop(err) {\n    if(err) {\n      return callback(err);\n    }\n    if(!condition()) {\n      return callback();\n    }\n    self.doWork(fn, loop);\n  })();\n};\n\n// 4.4) Normalization Algorithm\nNormalize.prototype.main = function(dataset, callback) {\n  var self = this;\n  self.schedule.start = new Date().getTime();\n  var result;\n\n  // handle invalid output format\n  if(self.options.format) {\n    if(self.options.format !== 'application/nquads') {\n      return callback(new JsonLdError(\n        'Unknown output format.',\n        'jsonld.UnknownFormat', {format: self.options.format}));\n    }\n  }\n\n  // 1) Create the normalization state.\n\n  // Note: Optimize by generating non-normalized blank node map concurrently.\n  var nonNormalized = {};\n\n  self.waterfall([\n    function(callback) {\n      // 2) For every quad in input dataset:\n      self.forEach(dataset, function(triples, graphName, callback) {\n        if(graphName === '@default') {\n          graphName = null;\n        }\n        self.forEach(triples, function(quad, idx, callback) {\n          if(graphName !== null) {\n            if(graphName.indexOf('_:') === 0) {\n              quad.name = {type: 'blank node', value: graphName};\n            } else {\n              quad.name = {type: 'IRI', value: graphName};\n            }\n          }\n          self.quads.push(quad);\n\n          // 2.1) For each blank node that occurs in the quad, add a reference\n          // to the quad using the blank node identifier in the blank node to\n          // quads map, creating a new entry if necessary.\n          self.forEachComponent(quad, function(component) {\n            if(component.type !== 'blank node') {\n              return;\n            }\n            var id = component.value;\n            if(id in self.blankNodeInfo) {\n              self.blankNodeInfo[id].quads.push(quad);\n            } else {\n              nonNormalized[id] = true;\n              self.blankNodeInfo[id] = {quads: [quad]};\n            }\n          });\n          callback();\n        }, callback);\n      }, callback);\n    },\n    function(callback) {\n      // 3) Create a list of non-normalized blank node identifiers\n      // non-normalized identifiers and populate it using the keys from the\n      // blank node to quads map.\n      // Note: We use a map here and it was generated during step 2.\n\n      // 4) Initialize simple, a boolean flag, to true.\n      var simple = true;\n\n      // 5) While simple is true, issue canonical identifiers for blank nodes:\n      self.whilst(function() { return simple; }, function(callback) {\n        // 5.1) Set simple to false.\n        simple = false;\n\n        // 5.2) Clear hash to blank nodes map.\n        self.hashToBlankNodes = {};\n\n        self.waterfall([\n          function(callback) {\n            // 5.3) For each blank node identifier identifier in non-normalized\n            // identifiers:\n            self.forEach(nonNormalized, function(value, id, callback) {\n              // 5.3.1) Create a hash, hash, according to the Hash First Degree\n              // Quads algorithm.\n              self.hashFirstDegreeQuads(id, function(err, hash) {\n                if(err) {\n                  return callback(err);\n                }\n                // 5.3.2) Add hash and identifier to hash to blank nodes map,\n                // creating a new entry if necessary.\n                if(hash in self.hashToBlankNodes) {\n                  self.hashToBlankNodes[hash].push(id);\n                } else {\n                  self.hashToBlankNodes[hash] = [id];\n                }\n                callback();\n              });\n            }, callback);\n          },\n          function(callback) {\n            // 5.4) For each hash to identifier list mapping in hash to blank\n            // nodes map, lexicographically-sorted by hash:\n            var hashes = Object.keys(self.hashToBlankNodes).sort();\n            self.forEach(hashes, function(hash, i, callback) {\n              // 5.4.1) If the length of identifier list is greater than 1,\n              // continue to the next mapping.\n              var idList = self.hashToBlankNodes[hash];\n              if(idList.length > 1) {\n                return callback();\n              }\n\n              // 5.4.2) Use the Issue Identifier algorithm, passing canonical\n              // issuer and the single blank node identifier in identifier\n              // list, identifier, to issue a canonical replacement identifier\n              // for identifier.\n              // TODO: consider changing `getId` to `issue`\n              var id = idList[0];\n              self.canonicalIssuer.getId(id);\n\n              // 5.4.3) Remove identifier from non-normalized identifiers.\n              delete nonNormalized[id];\n\n              // 5.4.4) Remove hash from the hash to blank nodes map.\n              delete self.hashToBlankNodes[hash];\n\n              // 5.4.5) Set simple to true.\n              simple = true;\n              callback();\n            }, callback);\n          }\n        ], callback);\n      }, callback);\n    },\n    function(callback) {\n      // 6) For each hash to identifier list mapping in hash to blank nodes map,\n      // lexicographically-sorted by hash:\n      var hashes = Object.keys(self.hashToBlankNodes).sort();\n      self.forEach(hashes, function(hash, idx, callback) {\n        // 6.1) Create hash path list where each item will be a result of\n        // running the Hash N-Degree Quads algorithm.\n        var hashPathList = [];\n\n        // 6.2) For each blank node identifier identifier in identifier list:\n        var idList = self.hashToBlankNodes[hash];\n        self.waterfall([\n          function(callback) {\n            self.forEach(idList, function(id, idx, callback) {\n              // 6.2.1) If a canonical identifier has already been issued for\n              // identifier, continue to the next identifier.\n              if(self.canonicalIssuer.hasId(id)) {\n                return callback();\n              }\n\n              // 6.2.2) Create temporary issuer, an identifier issuer\n              // initialized with the prefix _:b.\n              var issuer = new IdentifierIssuer('_:b');\n\n              // 6.2.3) Use the Issue Identifier algorithm, passing temporary\n              // issuer and identifier, to issue a new temporary blank node\n              // identifier for identifier.\n              issuer.getId(id);\n\n              // 6.2.4) Run the Hash N-Degree Quads algorithm, passing\n              // temporary issuer, and append the result to the hash path list.\n              self.hashNDegreeQuads(id, issuer, function(err, result) {\n                if(err) {\n                  return callback(err);\n                }\n                hashPathList.push(result);\n                callback();\n              });\n            }, callback);\n          },\n          function(callback) {\n            // 6.3) For each result in the hash path list,\n            // lexicographically-sorted by the hash in result:\n            hashPathList.sort(function(a, b) {\n              return (a.hash < b.hash) ? -1 : ((a.hash > b.hash) ? 1 : 0);\n            });\n            self.forEach(hashPathList, function(result, idx, callback) {\n              // 6.3.1) For each blank node identifier, existing identifier,\n              // that was issued a temporary identifier by identifier issuer\n              // in result, issue a canonical identifier, in the same order,\n              // using the Issue Identifier algorithm, passing canonical\n              // issuer and existing identifier.\n              for(var existing in result.issuer.existing) {\n                self.canonicalIssuer.getId(existing);\n              }\n              callback();\n            }, callback);\n          }\n        ], callback);\n      }, callback);\n    }, function(callback) {\n      /* Note: At this point all blank nodes in the set of RDF quads have been\n      assigned canonical identifiers, which have been stored in the canonical\n      issuer. Here each quad is updated by assigning each of its blank nodes\n      its new identifier. */\n\n      // 7) For each quad, quad, in input dataset:\n      var normalized = [];\n      self.waterfall([\n        function(callback) {\n          self.forEach(self.quads, function(quad, idx, callback) {\n            // 7.1) Create a copy, quad copy, of quad and replace any existing\n            // blank node identifiers using the canonical identifiers\n            // previously issued by canonical issuer.\n            // Note: We optimize away the copy here.\n            self.forEachComponent(quad, function(component) {\n              if(component.type === 'blank node' &&\n                component.value.indexOf(self.canonicalIssuer.prefix) !== 0) {\n                component.value = self.canonicalIssuer.getId(component.value);\n              }\n            });\n            // 7.2) Add quad copy to the normalized dataset.\n            normalized.push(_toNQuad(quad));\n            callback();\n          }, callback);\n        },\n        function(callback) {\n          // sort normalized output\n          normalized.sort();\n\n          // 8) Return the normalized dataset.\n          if(self.options.format === 'application/nquads') {\n            result = normalized.join('');\n            return callback();\n          }\n\n          result = _parseNQuads(normalized.join(''));\n          callback();\n        }\n      ], callback);\n    }\n  ], function(err) {\n    callback(err, result);\n  });\n};\n\n// 4.6) Hash First Degree Quads\nNormalize.prototype.hashFirstDegreeQuads = function(id, callback) {\n  var self = this;\n\n  // return cached hash\n  var info = self.blankNodeInfo[id];\n  if('hash' in info) {\n    return callback(null, info.hash);\n  }\n\n  // 1) Initialize nquads to an empty list. It will be used to store quads in\n  // N-Quads format.\n  var nquads = [];\n\n  // 2) Get the list of quads quads associated with the reference blank node\n  // identifier in the blank node to quads map.\n  var quads = info.quads;\n\n  // 3) For each quad quad in quads:\n  self.forEach(quads, function(quad, idx, callback) {\n    // 3.1) Serialize the quad in N-Quads format with the following special\n    // rule:\n\n    // 3.1.1) If any component in quad is an blank node, then serialize it\n    // using a special identifier as follows:\n    var copy = {predicate: quad.predicate};\n    self.forEachComponent(quad, function(component, key) {\n      // 3.1.2) If the blank node's existing blank node identifier matches the\n      // reference blank node identifier then use the blank node identifier _:a,\n      // otherwise, use the blank node identifier _:z.\n      copy[key] = self.modifyFirstDegreeComponent(id, component, key);\n    });\n    nquads.push(_toNQuad(copy));\n    callback();\n  }, function(err) {\n    if(err) {\n      return callback(err);\n    }\n    // 4) Sort nquads in lexicographical order.\n    nquads.sort();\n\n    // 5) Return the hash that results from passing the sorted, joined nquads\n    // through the hash algorithm.\n    info.hash = NormalizeHash.hashNQuads(self.name, nquads);\n    callback(null, info.hash);\n  });\n};\n\n// helper for modifying component during Hash First Degree Quads\nNormalize.prototype.modifyFirstDegreeComponent = function(id, component) {\n  if(component.type !== 'blank node') {\n    return component;\n  }\n  component = _clone(component);\n  component.value = (component.value === id ? '_:a' : '_:z');\n  return component;\n};\n\n// 4.7) Hash Related Blank Node\nNormalize.prototype.hashRelatedBlankNode = function(\n  related, quad, issuer, position, callback) {\n  var self = this;\n\n  // 1) Set the identifier to use for related, preferring first the canonical\n  // identifier for related if issued, second the identifier issued by issuer\n  // if issued, and last, if necessary, the result of the Hash First Degree\n  // Quads algorithm, passing related.\n  var id;\n  self.waterfall([\n    function(callback) {\n      if(self.canonicalIssuer.hasId(related)) {\n        id = self.canonicalIssuer.getId(related);\n        return callback();\n      }\n      if(issuer.hasId(related)) {\n        id = issuer.getId(related);\n        return callback();\n      }\n      self.hashFirstDegreeQuads(related, function(err, hash) {\n        if(err) {\n          return callback(err);\n        }\n        id = hash;\n        callback();\n      });\n    }\n  ], function(err) {\n    if(err) {\n      return callback(err);\n    }\n\n    // 2) Initialize a string input to the value of position.\n    // Note: We use a hash object instead.\n    var md = new NormalizeHash(self.name);\n    md.update(position);\n\n    // 3) If position is not g, append <, the value of the predicate in quad,\n    // and > to input.\n    if(position !== 'g') {\n      md.update(self.getRelatedPredicate(quad));\n    }\n\n    // 4) Append identifier to input.\n    md.update(id);\n\n    // 5) Return the hash that results from passing input through the hash\n    // algorithm.\n    return callback(null, md.digest());\n  });\n};\n\n// helper for getting a related predicate\nNormalize.prototype.getRelatedPredicate = function(quad) {\n  return '<' + quad.predicate.value + '>';\n};\n\n// 4.8) Hash N-Degree Quads\nNormalize.prototype.hashNDegreeQuads = function(id, issuer, callback) {\n  var self = this;\n\n  // 1) Create a hash to related blank nodes map for storing hashes that\n  // identify related blank nodes.\n  // Note: 2) and 3) handled within `createHashToRelated`\n  var hashToRelated;\n  var md = new NormalizeHash(self.name);\n  self.waterfall([\n    function(callback) {\n      self.createHashToRelated(id, issuer, function(err, result) {\n        if(err) {\n          return callback(err);\n        }\n        hashToRelated = result;\n        callback();\n      });\n    },\n    function(callback) {\n      // 4) Create an empty string, data to hash.\n      // Note: We created a hash object `md` above instead.\n\n      // 5) For each related hash to blank node list mapping in hash to related\n      // blank nodes map, sorted lexicographically by related hash:\n      var hashes = Object.keys(hashToRelated).sort();\n      self.forEach(hashes, function(hash, idx, callback) {\n        // 5.1) Append the related hash to the data to hash.\n        md.update(hash);\n\n        // 5.2) Create a string chosen path.\n        var chosenPath = '';\n\n        // 5.3) Create an unset chosen issuer variable.\n        var chosenIssuer;\n\n        // 5.4) For each permutation of blank node list:\n        var permutator = new Permutator(hashToRelated[hash]);\n        self.whilst(\n          function() { return permutator.hasNext(); },\n          function(nextPermutation) {\n          var permutation = permutator.next();\n\n          // 5.4.1) Create a copy of issuer, issuer copy.\n          var issuerCopy = issuer.clone();\n\n          // 5.4.2) Create a string path.\n          var path = '';\n\n          // 5.4.3) Create a recursion list, to store blank node identifiers\n          // that must be recursively processed by this algorithm.\n          var recursionList = [];\n\n          self.waterfall([\n            function(callback) {\n              // 5.4.4) For each related in permutation:\n              self.forEach(permutation, function(related, idx, callback) {\n                // 5.4.4.1) If a canonical identifier has been issued for\n                // related, append it to path.\n                if(self.canonicalIssuer.hasId(related)) {\n                  path += self.canonicalIssuer.getId(related);\n                } else {\n                  // 5.4.4.2) Otherwise:\n                  // 5.4.4.2.1) If issuer copy has not issued an identifier for\n                  // related, append related to recursion list.\n                  if(!issuerCopy.hasId(related)) {\n                    recursionList.push(related);\n                  }\n                  // 5.4.4.2.2) Use the Issue Identifier algorithm, passing\n                  // issuer copy and related and append the result to path.\n                  path += issuerCopy.getId(related);\n                }\n\n                // 5.4.4.3) If chosen path is not empty and the length of path\n                // is greater than or equal to the length of chosen path and\n                // path is lexicographically greater than chosen path, then\n                // skip to the next permutation.\n                if(chosenPath.length !== 0 &&\n                  path.length >= chosenPath.length && path > chosenPath) {\n                  // FIXME: may cause inaccurate total depth calculation\n                  return nextPermutation();\n                }\n                callback();\n              }, callback);\n            },\n            function(callback) {\n              // 5.4.5) For each related in recursion list:\n              self.forEach(recursionList, function(related, idx, callback) {\n                // 5.4.5.1) Set result to the result of recursively executing\n                // the Hash N-Degree Quads algorithm, passing related for\n                // identifier and issuer copy for path identifier issuer.\n                self.hashNDegreeQuads(\n                  related, issuerCopy, function(err, result) {\n                  if(err) {\n                    return callback(err);\n                  }\n\n                  // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer\n                  // copy and related and append the result to path.\n                  path += issuerCopy.getId(related);\n\n                  // 5.4.5.3) Append <, the hash in result, and > to path.\n                  path += '<' + result.hash + '>';\n\n                  // 5.4.5.4) Set issuer copy to the identifier issuer in\n                  // result.\n                  issuerCopy = result.issuer;\n\n                  // 5.4.5.5) If chosen path is not empty and the length of path\n                  // is greater than or equal to the length of chosen path and\n                  // path is lexicographically greater than chosen path, then\n                  // skip to the next permutation.\n                  if(chosenPath.length !== 0 &&\n                    path.length >= chosenPath.length && path > chosenPath) {\n                    // FIXME: may cause inaccurate total depth calculation\n                    return nextPermutation();\n                  }\n                  callback();\n                });\n              }, callback);\n            },\n            function(callback) {\n              // 5.4.6) If chosen path is empty or path is lexicographically\n              // less than chosen path, set chosen path to path and chosen\n              // issuer to issuer copy.\n              if(chosenPath.length === 0 || path < chosenPath) {\n                chosenPath = path;\n                chosenIssuer = issuerCopy;\n              }\n              callback();\n            }\n          ], nextPermutation);\n        }, function(err) {\n          if(err) {\n            return callback(err);\n          }\n\n          // 5.5) Append chosen path to data to hash.\n          md.update(chosenPath);\n\n          // 5.6) Replace issuer, by reference, with chosen issuer.\n          issuer = chosenIssuer;\n          callback();\n        });\n      }, callback);\n    }\n  ], function(err) {\n    // 6) Return issuer and the hash that results from passing data to hash\n    // through the hash algorithm.\n    callback(err, {hash: md.digest(), issuer: issuer});\n  });\n};\n\n// helper for creating hash to related blank nodes map\nNormalize.prototype.createHashToRelated = function(id, issuer, callback) {\n  var self = this;\n\n  // 1) Create a hash to related blank nodes map for storing hashes that\n  // identify related blank nodes.\n  var hashToRelated = {};\n\n  // 2) Get a reference, quads, to the list of quads in the blank node to\n  // quads map for the key identifier.\n  var quads = self.blankNodeInfo[id].quads;\n\n  // 3) For each quad in quads:\n  self.forEach(quads, function(quad, idx, callback) {\n    // 3.1) For each component in quad, if component is the subject, object,\n    // and graph name and it is a blank node that is not identified by\n    // identifier:\n    self.forEach(quad, function(component, key, callback) {\n      if(key === 'predicate' ||\n        !(component.type === 'blank node' && component.value !== id)) {\n        return callback();\n      }\n      // 3.1.1) Set hash to the result of the Hash Related Blank Node\n      // algorithm, passing the blank node identifier for component as\n      // related, quad, path identifier issuer as issuer, and position as\n      // either s, o, or g based on whether component is a subject, object,\n      // graph name, respectively.\n      var related = component.value;\n      var position = POSITIONS[key];\n      self.hashRelatedBlankNode(\n        related, quad, issuer, position, function(err, hash) {\n        if(err) {\n          return callback(err);\n        }\n        // 3.1.2) Add a mapping of hash to the blank node identifier for\n        // component to hash to related blank nodes map, adding an entry as\n        // necessary.\n        if(hash in hashToRelated) {\n          hashToRelated[hash].push(related);\n        } else {\n          hashToRelated[hash] = [related];\n        }\n        callback();\n      });\n    }, callback);\n  }, function(err) {\n    callback(err, hashToRelated);\n  });\n};\n\n// helper that iterates over quad components (skips predicate)\nNormalize.prototype.forEachComponent = function(quad, op) {\n  for(var key in quad) {\n    // skip `predicate`\n    if(key === 'predicate') {\n      continue;\n    }\n    op(quad[key], key, quad);\n  }\n};\n\nreturn Normalize;\n\n})(); // end of define URDNA2015\n\n/////////////////////////////// DEFINE URGNA2012 //////////////////////////////\n\nvar URGNA2012 = (function() {\n\nvar Normalize = function(options) {\n  URDNA2015.call(this, options);\n  this.name = 'URGNA2012';\n};\nNormalize.prototype = new URDNA2015();\n\n// helper for modifying component during Hash First Degree Quads\nNormalize.prototype.modifyFirstDegreeComponent = function(id, component, key) {\n  if(component.type !== 'blank node') {\n    return component;\n  }\n  component = _clone(component);\n  if(key === 'name') {\n    component.value = '_:g';\n  } else {\n    component.value = (component.value === id ? '_:a' : '_:z');\n  }\n  return component;\n};\n\n// helper for getting a related predicate\nNormalize.prototype.getRelatedPredicate = function(quad) {\n  return quad.predicate.value;\n};\n\n// helper for creating hash to related blank nodes map\nNormalize.prototype.createHashToRelated = function(id, issuer, callback) {\n  var self = this;\n\n  // 1) Create a hash to related blank nodes map for storing hashes that\n  // identify related blank nodes.\n  var hashToRelated = {};\n\n  // 2) Get a reference, quads, to the list of quads in the blank node to\n  // quads map for the key identifier.\n  var quads = self.blankNodeInfo[id].quads;\n\n  // 3) For each quad in quads:\n  self.forEach(quads, function(quad, idx, callback) {\n    // 3.1) If the quad's subject is a blank node that does not match\n    // identifier, set hash to the result of the Hash Related Blank Node\n    // algorithm, passing the blank node identifier for subject as related,\n    // quad, path identifier issuer as issuer, and p as position.\n    var position;\n    var related;\n    if(quad.subject.type === 'blank node' && quad.subject.value !== id) {\n      related = quad.subject.value;\n      position = 'p';\n    } else if(quad.object.type === 'blank node' && quad.object.value !== id) {\n      // 3.2) Otherwise, if quad's object is a blank node that does not match\n      // identifier, to the result of the Hash Related Blank Node algorithm,\n      // passing the blank node identifier for object as related, quad, path\n      // identifier issuer as issuer, and r as position.\n      related = quad.object.value;\n      position = 'r';\n    } else {\n      // 3.3) Otherwise, continue to the next quad.\n      return callback();\n    }\n    // 3.4) Add a mapping of hash to the blank node identifier for the\n    // component that matched (subject or object) to hash to related blank\n    // nodes map, adding an entry as necessary.\n    self.hashRelatedBlankNode(\n      related, quad, issuer, position, function(err, hash) {\n      if(hash in hashToRelated) {\n        hashToRelated[hash].push(related);\n      } else {\n        hashToRelated[hash] = [related];\n      }\n      callback();\n    });\n  }, function(err) {\n    callback(err, hashToRelated);\n  });\n};\n\nreturn Normalize;\n\n})(); // end of define URGNA2012\n\n/**\n * Recursively flattens the subjects in the given JSON-LD expanded input\n * into a node map.\n *\n * @param input the JSON-LD expanded input.\n * @param graphs a map of graph name to subject map.\n * @param graph the name of the current graph.\n * @param issuer the blank node identifier issuer.\n * @param name the name assigned to the current input if it is a bnode.\n * @param list the list to append to, null for none.\n */\nfunction _createNodeMap(input, graphs, graph, issuer, name, list) {\n  // recurse through array\n  if(_isArray(input)) {\n    for(var i = 0; i < input.length; ++i) {\n      _createNodeMap(input[i], graphs, graph, issuer, undefined, list);\n    }\n    return;\n  }\n\n  // add non-object to list\n  if(!_isObject(input)) {\n    if(list) {\n      list.push(input);\n    }\n    return;\n  }\n\n  // add values to list\n  if(_isValue(input)) {\n    if('@type' in input) {\n      var type = input['@type'];\n      // rename @type blank node\n      if(type.indexOf('_:') === 0) {\n        input['@type'] = type = issuer.getId(type);\n      }\n    }\n    if(list) {\n      list.push(input);\n    }\n    return;\n  }\n\n  // Note: At this point, input must be a subject.\n\n  // spec requires @type to be named first, so assign names early\n  if('@type' in input) {\n    var types = input['@type'];\n    for(var i = 0; i < types.length; ++i) {\n      var type = types[i];\n      if(type.indexOf('_:') === 0) {\n        issuer.getId(type);\n      }\n    }\n  }\n\n  // get name for subject\n  if(_isUndefined(name)) {\n    name = _isBlankNode(input) ? issuer.getId(input['@id']) : input['@id'];\n  }\n\n  // add subject reference to list\n  if(list) {\n    list.push({'@id': name});\n  }\n\n  // create new subject or merge into existing one\n  var subjects = graphs[graph];\n  var subject = subjects[name] = subjects[name] || {};\n  subject['@id'] = name;\n  var properties = Object.keys(input).sort();\n  for(var pi = 0; pi < properties.length; ++pi) {\n    var property = properties[pi];\n\n    // skip @id\n    if(property === '@id') {\n      continue;\n    }\n\n    // handle reverse properties\n    if(property === '@reverse') {\n      var referencedNode = {'@id': name};\n      var reverseMap = input['@reverse'];\n      for(var reverseProperty in reverseMap) {\n        var items = reverseMap[reverseProperty];\n        for(var ii = 0; ii < items.length; ++ii) {\n          var item = items[ii];\n          var itemName = item['@id'];\n          if(_isBlankNode(item)) {\n            itemName = issuer.getId(itemName);\n          }\n          _createNodeMap(item, graphs, graph, issuer, itemName);\n          jsonld.addValue(\n            subjects[itemName], reverseProperty, referencedNode,\n            {propertyIsArray: true, allowDuplicate: false});\n        }\n      }\n      continue;\n    }\n\n    // recurse into graph\n    if(property === '@graph') {\n      // add graph subjects map entry\n      if(!(name in graphs)) {\n        graphs[name] = {};\n      }\n      var g = (graph === '@merged') ? graph : name;\n      _createNodeMap(input[property], graphs, g, issuer);\n      continue;\n    }\n\n    // copy non-@type keywords\n    if(property !== '@type' && _isKeyword(property)) {\n      if(property === '@index' && property in subject &&\n        (input[property] !== subject[property] ||\n        input[property]['@id'] !== subject[property]['@id'])) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; conflicting @index property detected.',\n          'jsonld.SyntaxError',\n          {code: 'conflicting indexes', subject: subject});\n      }\n      subject[property] = input[property];\n      continue;\n    }\n\n    // iterate over objects\n    var objects = input[property];\n\n    // if property is a bnode, assign it a new id\n    if(property.indexOf('_:') === 0) {\n      property = issuer.getId(property);\n    }\n\n    // ensure property is added for empty arrays\n    if(objects.length === 0) {\n      jsonld.addValue(subject, property, [], {propertyIsArray: true});\n      continue;\n    }\n    for(var oi = 0; oi < objects.length; ++oi) {\n      var o = objects[oi];\n\n      if(property === '@type') {\n        // rename @type blank nodes\n        o = (o.indexOf('_:') === 0) ? issuer.getId(o) : o;\n      }\n\n      // handle embedded subject or subject reference\n      if(_isSubject(o) || _isSubjectReference(o)) {\n        // relabel blank node @id\n        var id = _isBlankNode(o) ? issuer.getId(o['@id']) : o['@id'];\n\n        // add reference and recurse\n        jsonld.addValue(\n          subject, property, {'@id': id},\n          {propertyIsArray: true, allowDuplicate: false});\n        _createNodeMap(o, graphs, graph, issuer, id);\n      } else if(_isList(o)) {\n        // handle @list\n        var _list = [];\n        _createNodeMap(o['@list'], graphs, graph, issuer, name, _list);\n        o = {'@list': _list};\n        jsonld.addValue(\n          subject, property, o,\n          {propertyIsArray: true, allowDuplicate: false});\n      } else {\n        // handle @value\n        _createNodeMap(o, graphs, graph, issuer, name);\n        jsonld.addValue(\n          subject, property, o, {propertyIsArray: true, allowDuplicate: false});\n      }\n    }\n  }\n}\n\nfunction _mergeNodeMaps(graphs) {\n  // add all non-default graphs to default graph\n  var defaultGraph = graphs['@default'];\n  var graphNames = Object.keys(graphs).sort();\n  for(var i = 0; i < graphNames.length; ++i) {\n    var graphName = graphNames[i];\n    if(graphName === '@default') {\n      continue;\n    }\n    var nodeMap = graphs[graphName];\n    var subject = defaultGraph[graphName];\n    if(!subject) {\n      defaultGraph[graphName] = subject = {\n        '@id': graphName,\n        '@graph': []\n      };\n    } else if(!('@graph' in subject)) {\n      subject['@graph'] = [];\n    }\n    var graph = subject['@graph'];\n    var ids = Object.keys(nodeMap).sort();\n    for(var ii = 0; ii < ids.length; ++ii) {\n      var node = nodeMap[ids[ii]];\n      // only add full subjects\n      if(!_isSubjectReference(node)) {\n        graph.push(node);\n      }\n    }\n  }\n  return defaultGraph;\n}\n\n/**\n * Frames subjects according to the given frame.\n *\n * @param state the current framing state.\n * @param subjects the subjects to filter.\n * @param frame the frame.\n * @param parent the parent subject or top-level array.\n * @param property the parent property, initialized to null.\n */\nfunction _frame(state, subjects, frame, parent, property) {\n  // validate the frame\n  _validateFrame(frame);\n  frame = frame[0];\n\n  // get flags for current frame\n  var options = state.options;\n  var flags = {\n    embed: _getFrameFlag(frame, options, 'embed'),\n    explicit: _getFrameFlag(frame, options, 'explicit'),\n    requireAll: _getFrameFlag(frame, options, 'requireAll')\n  };\n\n  // filter out subjects that match the frame\n  var matches = _filterSubjects(state, subjects, frame, flags);\n\n  // add matches to output\n  var ids = Object.keys(matches).sort();\n  for(var idx = 0; idx < ids.length; ++idx) {\n    var id = ids[idx];\n    var subject = matches[id];\n\n    if(flags.embed === '@link' && id in state.link) {\n      // TODO: may want to also match an existing linked subject against\n      // the current frame ... so different frames could produce different\n      // subjects that are only shared in-memory when the frames are the same\n\n      // add existing linked subject\n      _addFrameOutput(parent, property, state.link[id]);\n      continue;\n    }\n\n    /* Note: In order to treat each top-level match as a compartmentalized\n    result, clear the unique embedded subjects map when the property is null,\n    which only occurs at the top-level. */\n    if(property === null) {\n      state.uniqueEmbeds = {};\n    }\n\n    // start output for subject\n    var output = {};\n    output['@id'] = id;\n    state.link[id] = output;\n\n    // if embed is @never or if a circular reference would be created by an\n    // embed, the subject cannot be embedded, just add the reference;\n    // note that a circular reference won't occur when the embed flag is\n    // `@link` as the above check will short-circuit before reaching this point\n    if(flags.embed === '@never' ||\n      _createsCircularReference(subject, state.subjectStack)) {\n      _addFrameOutput(parent, property, output);\n      continue;\n    }\n\n    // if only the last match should be embedded\n    if(flags.embed === '@last') {\n      // remove any existing embed\n      if(id in state.uniqueEmbeds) {\n        _removeEmbed(state, id);\n      }\n      state.uniqueEmbeds[id] = {parent: parent, property: property};\n    }\n\n    // push matching subject onto stack to enable circular embed checks\n    state.subjectStack.push(subject);\n\n    // iterate over subject properties\n    var props = Object.keys(subject).sort();\n    for(var i = 0; i < props.length; i++) {\n      var prop = props[i];\n\n      // copy keywords to output\n      if(_isKeyword(prop)) {\n        output[prop] = _clone(subject[prop]);\n        continue;\n      }\n\n      // explicit is on and property isn't in the frame, skip processing\n      if(flags.explicit && !(prop in frame)) {\n        continue;\n      }\n\n      // add objects\n      var objects = subject[prop];\n      for(var oi = 0; oi < objects.length; ++oi) {\n        var o = objects[oi];\n\n        // recurse into list\n        if(_isList(o)) {\n          // add empty list\n          var list = {'@list': []};\n          _addFrameOutput(output, prop, list);\n\n          // add list objects\n          var src = o['@list'];\n          for(var n in src) {\n            o = src[n];\n            if(_isSubjectReference(o)) {\n              var subframe = (prop in frame ?\n                frame[prop][0]['@list'] : _createImplicitFrame(flags));\n              // recurse into subject reference\n              _frame(state, [o['@id']], subframe, list, '@list');\n            } else {\n              // include other values automatically\n              _addFrameOutput(list, '@list', _clone(o));\n            }\n          }\n          continue;\n        }\n\n        if(_isSubjectReference(o)) {\n          // recurse into subject reference\n          var subframe = (prop in frame ?\n            frame[prop] : _createImplicitFrame(flags));\n          _frame(state, [o['@id']], subframe, output, prop);\n        } else {\n          // include other values automatically\n          _addFrameOutput(output, prop, _clone(o));\n        }\n      }\n    }\n\n    // handle defaults\n    var props = Object.keys(frame).sort();\n    for(var i = 0; i < props.length; ++i) {\n      var prop = props[i];\n\n      // skip keywords\n      if(_isKeyword(prop)) {\n        continue;\n      }\n\n      // if omit default is off, then include default values for properties\n      // that appear in the next frame but are not in the matching subject\n      var next = frame[prop][0];\n      var omitDefaultOn = _getFrameFlag(next, options, 'omitDefault');\n      if(!omitDefaultOn && !(prop in output)) {\n        var preserve = '@null';\n        if('@default' in next) {\n          preserve = _clone(next['@default']);\n        }\n        if(!_isArray(preserve)) {\n          preserve = [preserve];\n        }\n        output[prop] = [{'@preserve': preserve}];\n      }\n    }\n\n    // add output to parent\n    _addFrameOutput(parent, property, output);\n\n    // pop matching subject from circular ref-checking stack\n    state.subjectStack.pop();\n  }\n}\n\n/**\n * Creates an implicit frame when recursing through subject matches. If\n * a frame doesn't have an explicit frame for a particular property, then\n * a wildcard child frame will be created that uses the same flags that the\n * parent frame used.\n *\n * @param flags the current framing flags.\n *\n * @return the implicit frame.\n */\nfunction _createImplicitFrame(flags) {\n  var frame = {};\n  for(var key in flags) {\n    if(flags[key] !== undefined) {\n      frame['@' + key] = [flags[key]];\n    }\n  }\n  return [frame];\n}\n\n/**\n * Checks the current subject stack to see if embedding the given subject\n * would cause a circular reference.\n *\n * @param subjectToEmbed the subject to embed.\n * @param subjectStack the current stack of subjects.\n *\n * @return true if a circular reference would be created, false if not.\n */\nfunction _createsCircularReference(subjectToEmbed, subjectStack) {\n  for(var i = subjectStack.length - 1; i >= 0; --i) {\n    if(subjectStack[i]['@id'] === subjectToEmbed['@id']) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Gets the frame flag value for the given flag name.\n *\n * @param frame the frame.\n * @param options the framing options.\n * @param name the flag name.\n *\n * @return the flag value.\n */\nfunction _getFrameFlag(frame, options, name) {\n  var flag = '@' + name;\n  var rval = (flag in frame ? frame[flag][0] : options[name]);\n  if(name === 'embed') {\n    // default is \"@last\"\n    // backwards-compatibility support for \"embed\" maps:\n    // true => \"@last\"\n    // false => \"@never\"\n    if(rval === true) {\n      rval = '@last';\n    } else if(rval === false) {\n      rval = '@never';\n    } else if(rval !== '@always' && rval !== '@never' && rval !== '@link') {\n      rval = '@last';\n    }\n  }\n  return rval;\n}\n\n/**\n * Validates a JSON-LD frame, throwing an exception if the frame is invalid.\n *\n * @param frame the frame to validate.\n */\nfunction _validateFrame(frame) {\n  if(!_isArray(frame) || frame.length !== 1 || !_isObject(frame[0])) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a JSON-LD frame must be a single object.',\n      'jsonld.SyntaxError', {frame: frame});\n  }\n}\n\n/**\n * Returns a map of all of the subjects that match a parsed frame.\n *\n * @param state the current framing state.\n * @param subjects the set of subjects to filter.\n * @param frame the parsed frame.\n * @param flags the frame flags.\n *\n * @return all of the matched subjects.\n */\nfunction _filterSubjects(state, subjects, frame, flags) {\n  // filter subjects in @id order\n  var rval = {};\n  for(var i = 0; i < subjects.length; ++i) {\n    var id = subjects[i];\n    var subject = state.subjects[id];\n    if(_filterSubject(subject, frame, flags)) {\n      rval[id] = subject;\n    }\n  }\n  return rval;\n}\n\n/**\n * Returns true if the given subject matches the given frame.\n *\n * @param subject the subject to check.\n * @param frame the frame to check.\n * @param flags the frame flags.\n *\n * @return true if the subject matches, false if not.\n */\nfunction _filterSubject(subject, frame, flags) {\n  // check @type (object value means 'any' type, fall through to ducktyping)\n  if('@type' in frame &&\n    !(frame['@type'].length === 1 && _isObject(frame['@type'][0]))) {\n    var types = frame['@type'];\n    for(var i = 0; i < types.length; ++i) {\n      // any matching @type is a match\n      if(jsonld.hasValue(subject, '@type', types[i])) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  // check ducktype\n  var wildcard = true;\n  var matchesSome = false;\n  for(var key in frame) {\n    if(_isKeyword(key)) {\n      // skip non-@id and non-@type\n      if(key !== '@id' && key !== '@type') {\n        continue;\n      }\n      wildcard = false;\n\n      // check @id for a specific @id value\n      if(key === '@id' && _isString(frame[key])) {\n        if(subject[key] !== frame[key]) {\n          return false;\n        }\n        matchesSome = true;\n        continue;\n      }\n    }\n\n    wildcard = false;\n\n    if(key in subject) {\n      // frame[key] === [] means do not match if property is present\n      if(_isArray(frame[key]) && frame[key].length === 0 &&\n        subject[key] !== undefined) {\n        return false;\n      }\n      matchesSome = true;\n      continue;\n    }\n\n    // all properties must match to be a duck unless a @default is specified\n    var hasDefault = (_isArray(frame[key]) && _isObject(frame[key][0]) &&\n      '@default' in frame[key][0]);\n    if(flags.requireAll && !hasDefault) {\n      return false;\n    }\n  }\n\n  // return true if wildcard or subject matches some properties\n  return wildcard || matchesSome;\n}\n\n/**\n * Removes an existing embed.\n *\n * @param state the current framing state.\n * @param id the @id of the embed to remove.\n */\nfunction _removeEmbed(state, id) {\n  // get existing embed\n  var embeds = state.uniqueEmbeds;\n  var embed = embeds[id];\n  var parent = embed.parent;\n  var property = embed.property;\n\n  // create reference to replace embed\n  var subject = {'@id': id};\n\n  // remove existing embed\n  if(_isArray(parent)) {\n    // replace subject with reference\n    for(var i = 0; i < parent.length; ++i) {\n      if(jsonld.compareValues(parent[i], subject)) {\n        parent[i] = subject;\n        break;\n      }\n    }\n  } else {\n    // replace subject with reference\n    var useArray = _isArray(parent[property]);\n    jsonld.removeValue(parent, property, subject, {propertyIsArray: useArray});\n    jsonld.addValue(parent, property, subject, {propertyIsArray: useArray});\n  }\n\n  // recursively remove dependent dangling embeds\n  var removeDependents = function(id) {\n    // get embed keys as a separate array to enable deleting keys in map\n    var ids = Object.keys(embeds);\n    for(var i = 0; i < ids.length; ++i) {\n      var next = ids[i];\n      if(next in embeds && _isObject(embeds[next].parent) &&\n        embeds[next].parent['@id'] === id) {\n        delete embeds[next];\n        removeDependents(next);\n      }\n    }\n  };\n  removeDependents(id);\n}\n\n/**\n * Adds framing output to the given parent.\n *\n * @param parent the parent to add to.\n * @param property the parent property.\n * @param output the output to add.\n */\nfunction _addFrameOutput(parent, property, output) {\n  if(_isObject(parent)) {\n    jsonld.addValue(parent, property, output, {propertyIsArray: true});\n  } else {\n    parent.push(output);\n  }\n}\n\n/**\n * Removes the @preserve keywords as the last step of the framing algorithm.\n *\n * @param ctx the active context used to compact the input.\n * @param input the framed, compacted output.\n * @param options the compaction options used.\n *\n * @return the resulting output.\n */\nfunction _removePreserve(ctx, input, options) {\n  // recurse through arrays\n  if(_isArray(input)) {\n    var output = [];\n    for(var i = 0; i < input.length; ++i) {\n      var result = _removePreserve(ctx, input[i], options);\n      // drop nulls from arrays\n      if(result !== null) {\n        output.push(result);\n      }\n    }\n    input = output;\n  } else if(_isObject(input)) {\n    // remove @preserve\n    if('@preserve' in input) {\n      if(input['@preserve'] === '@null') {\n        return null;\n      }\n      return input['@preserve'];\n    }\n\n    // skip @values\n    if(_isValue(input)) {\n      return input;\n    }\n\n    // recurse through @lists\n    if(_isList(input)) {\n      input['@list'] = _removePreserve(ctx, input['@list'], options);\n      return input;\n    }\n\n    // handle in-memory linked nodes\n    var idAlias = _compactIri(ctx, '@id');\n    if(idAlias in input) {\n      var id = input[idAlias];\n      if(id in options.link) {\n        var idx = options.link[id].indexOf(input);\n        if(idx === -1) {\n          // prevent circular visitation\n          options.link[id].push(input);\n        } else {\n          // already visited\n          return options.link[id][idx];\n        }\n      } else {\n        // prevent circular visitation\n        options.link[id] = [input];\n      }\n    }\n\n    // recurse through properties\n    for(var prop in input) {\n      var result = _removePreserve(ctx, input[prop], options);\n      var container = jsonld.getContextValue(ctx, prop, '@container');\n      if(options.compactArrays && _isArray(result) && result.length === 1 &&\n        container === null) {\n        result = result[0];\n      }\n      input[prop] = result;\n    }\n  }\n  return input;\n}\n\n/**\n * Compares two strings first based on length and then lexicographically.\n *\n * @param a the first string.\n * @param b the second string.\n *\n * @return -1 if a < b, 1 if a > b, 0 if a == b.\n */\nfunction _compareShortestLeast(a, b) {\n  if(a.length < b.length) {\n    return -1;\n  }\n  if(b.length < a.length) {\n    return 1;\n  }\n  if(a === b) {\n    return 0;\n  }\n  return (a < b) ? -1 : 1;\n}\n\n/**\n * Picks the preferred compaction term from the given inverse context entry.\n *\n * @param activeCtx the active context.\n * @param iri the IRI to pick the term for.\n * @param value the value to pick the term for.\n * @param containers the preferred containers.\n * @param typeOrLanguage either '@type' or '@language'.\n * @param typeOrLanguageValue the preferred value for '@type' or '@language'.\n *\n * @return the preferred term.\n */\nfunction _selectTerm(\n  activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue) {\n  if(typeOrLanguageValue === null) {\n    typeOrLanguageValue = '@null';\n  }\n\n  // preferences for the value of @type or @language\n  var prefs = [];\n\n  // determine prefs for @id based on whether or not value compacts to a term\n  if((typeOrLanguageValue === '@id' || typeOrLanguageValue === '@reverse') &&\n    _isSubjectReference(value)) {\n    // prefer @reverse first\n    if(typeOrLanguageValue === '@reverse') {\n      prefs.push('@reverse');\n    }\n    // try to compact value to a term\n    var term = _compactIri(activeCtx, value['@id'], null, {vocab: true});\n    if(term in activeCtx.mappings &&\n      activeCtx.mappings[term] &&\n      activeCtx.mappings[term]['@id'] === value['@id']) {\n      // prefer @vocab\n      prefs.push.apply(prefs, ['@vocab', '@id']);\n    } else {\n      // prefer @id\n      prefs.push.apply(prefs, ['@id', '@vocab']);\n    }\n  } else {\n    prefs.push(typeOrLanguageValue);\n  }\n  prefs.push('@none');\n\n  var containerMap = activeCtx.inverse[iri];\n  for(var ci = 0; ci < containers.length; ++ci) {\n    // if container not available in the map, continue\n    var container = containers[ci];\n    if(!(container in containerMap)) {\n      continue;\n    }\n\n    var typeOrLanguageValueMap = containerMap[container][typeOrLanguage];\n    for(var pi = 0; pi < prefs.length; ++pi) {\n      // if type/language option not available in the map, continue\n      var pref = prefs[pi];\n      if(!(pref in typeOrLanguageValueMap)) {\n        continue;\n      }\n\n      // select term\n      return typeOrLanguageValueMap[pref];\n    }\n  }\n\n  return null;\n}\n\n/**\n * Compacts an IRI or keyword into a term or prefix if it can be. If the\n * IRI has an associated value it may be passed.\n *\n * @param activeCtx the active context to use.\n * @param iri the IRI to compact.\n * @param value the value to check or null.\n * @param relativeTo options for how to compact IRIs:\n *          vocab: true to split after @vocab, false not to.\n * @param reverse true if a reverse property is being compacted, false if not.\n *\n * @return the compacted term, prefix, keyword alias, or the original IRI.\n */\nfunction _compactIri(activeCtx, iri, value, relativeTo, reverse) {\n  // can't compact null\n  if(iri === null) {\n    return iri;\n  }\n\n  // default value and parent to null\n  if(_isUndefined(value)) {\n    value = null;\n  }\n  // default reverse to false\n  if(_isUndefined(reverse)) {\n    reverse = false;\n  }\n  relativeTo = relativeTo || {};\n\n  var inverseCtx = activeCtx.getInverse();\n\n  // if term is a keyword, it can only be compacted to a simple alias\n  if(_isKeyword(iri)) {\n    if(iri in inverseCtx) {\n      return inverseCtx[iri]['@none']['@type']['@none'];\n    }\n    return iri;\n  }\n\n  // use inverse context to pick a term if iri is relative to vocab\n  if(relativeTo.vocab && iri in inverseCtx) {\n    var defaultLanguage = activeCtx['@language'] || '@none';\n\n    // prefer @index if available in value\n    var containers = [];\n    if(_isObject(value) && '@index' in value) {\n      containers.push('@index');\n    }\n\n    // defaults for term selection based on type/language\n    var typeOrLanguage = '@language';\n    var typeOrLanguageValue = '@null';\n\n    if(reverse) {\n      typeOrLanguage = '@type';\n      typeOrLanguageValue = '@reverse';\n      containers.push('@set');\n    } else if(_isList(value)) {\n      // choose the most specific term that works for all elements in @list\n      // only select @list containers if @index is NOT in value\n      if(!('@index' in value)) {\n        containers.push('@list');\n      }\n      var list = value['@list'];\n      var commonLanguage = (list.length === 0) ? defaultLanguage : null;\n      var commonType = null;\n      for(var i = 0; i < list.length; ++i) {\n        var item = list[i];\n        var itemLanguage = '@none';\n        var itemType = '@none';\n        if(_isValue(item)) {\n          if('@language' in item) {\n            itemLanguage = item['@language'];\n          } else if('@type' in item) {\n            itemType = item['@type'];\n          } else {\n            // plain literal\n            itemLanguage = '@null';\n          }\n        } else {\n          itemType = '@id';\n        }\n        if(commonLanguage === null) {\n          commonLanguage = itemLanguage;\n        } else if(itemLanguage !== commonLanguage && _isValue(item)) {\n          commonLanguage = '@none';\n        }\n        if(commonType === null) {\n          commonType = itemType;\n        } else if(itemType !== commonType) {\n          commonType = '@none';\n        }\n        // there are different languages and types in the list, so choose\n        // the most generic term, no need to keep iterating the list\n        if(commonLanguage === '@none' && commonType === '@none') {\n          break;\n        }\n      }\n      commonLanguage = commonLanguage || '@none';\n      commonType = commonType || '@none';\n      if(commonType !== '@none') {\n        typeOrLanguage = '@type';\n        typeOrLanguageValue = commonType;\n      } else {\n        typeOrLanguageValue = commonLanguage;\n      }\n    } else {\n      if(_isValue(value)) {\n        if('@language' in value && !('@index' in value)) {\n          containers.push('@language');\n          typeOrLanguageValue = value['@language'];\n        } else if('@type' in value) {\n          typeOrLanguage = '@type';\n          typeOrLanguageValue = value['@type'];\n        }\n      } else {\n        typeOrLanguage = '@type';\n        typeOrLanguageValue = '@id';\n      }\n      containers.push('@set');\n    }\n\n    // do term selection\n    containers.push('@none');\n    var term = _selectTerm(\n      activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue);\n    if(term !== null) {\n      return term;\n    }\n  }\n\n  // no term match, use @vocab if available\n  if(relativeTo.vocab) {\n    if('@vocab' in activeCtx) {\n      // determine if vocab is a prefix of the iri\n      var vocab = activeCtx['@vocab'];\n      if(iri.indexOf(vocab) === 0 && iri !== vocab) {\n        // use suffix as relative iri if it is not a term in the active context\n        var suffix = iri.substr(vocab.length);\n        if(!(suffix in activeCtx.mappings)) {\n          return suffix;\n        }\n      }\n    }\n  }\n\n  // no term or @vocab match, check for possible CURIEs\n  var choice = null;\n  var idx = 0;\n  var partialMatches = [];\n  var iriMap = activeCtx.fastCurieMap;\n  // check for partial matches of against `iri`, which means look until\n  // iri.length - 1, not full length\n  var maxPartialLength = iri.length - 1;\n  for(; idx < maxPartialLength && iri[idx] in iriMap; ++idx) {\n    iriMap = iriMap[iri[idx]];\n    if('' in iriMap) {\n      partialMatches.push(iriMap[''][0]);\n    }\n  }\n  // check partial matches in reverse order to prefer longest ones first\n  for(var i = partialMatches.length - 1; i >= 0; --i) {\n    var entry = partialMatches[i];\n    var terms = entry.terms;\n    for(var ti = 0; ti < terms.length; ++ti) {\n      // a CURIE is usable if:\n      // 1. it has no mapping, OR\n      // 2. value is null, which means we're not compacting an @value, AND\n      //   the mapping matches the IRI\n      var curie = terms[ti] + ':' + iri.substr(entry.iri.length);\n      var isUsableCurie = (!(curie in activeCtx.mappings) ||\n        (value === null && activeCtx.mappings[curie]['@id'] === iri));\n\n      // select curie if it is shorter or the same length but lexicographically\n      // less than the current choice\n      if(isUsableCurie && (choice === null ||\n        _compareShortestLeast(curie, choice) < 0)) {\n        choice = curie;\n      }\n    }\n  }\n\n  // return chosen curie\n  if(choice !== null) {\n    return choice;\n  }\n\n  // compact IRI relative to base\n  if(!relativeTo.vocab) {\n    return _removeBase(activeCtx['@base'], iri);\n  }\n\n  // return IRI as is\n  return iri;\n}\n\n/**\n * Performs value compaction on an object with '@value' or '@id' as the only\n * property.\n *\n * @param activeCtx the active context.\n * @param activeProperty the active property that points to the value.\n * @param value the value to compact.\n *\n * @return the compaction result.\n */\nfunction _compactValue(activeCtx, activeProperty, value) {\n  // value is a @value\n  if(_isValue(value)) {\n    // get context rules\n    var type = jsonld.getContextValue(activeCtx, activeProperty, '@type');\n    var language = jsonld.getContextValue(\n      activeCtx, activeProperty, '@language');\n    var container = jsonld.getContextValue(\n      activeCtx, activeProperty, '@container');\n\n    // whether or not the value has an @index that must be preserved\n    var preserveIndex = (('@index' in value) &&\n      container !== '@index');\n\n    // if there's no @index to preserve ...\n    if(!preserveIndex) {\n      // matching @type or @language specified in context, compact value\n      if(value['@type'] === type || value['@language'] === language) {\n        return value['@value'];\n      }\n    }\n\n    // return just the value of @value if all are true:\n    // 1. @value is the only key or @index isn't being preserved\n    // 2. there is no default language or @value is not a string or\n    //   the key has a mapping with a null @language\n    var keyCount = Object.keys(value).length;\n    var isValueOnlyKey = (keyCount === 1 ||\n      (keyCount === 2 && ('@index' in value) && !preserveIndex));\n    var hasDefaultLanguage = ('@language' in activeCtx);\n    var isValueString = _isString(value['@value']);\n    var hasNullMapping = (activeCtx.mappings[activeProperty] &&\n      activeCtx.mappings[activeProperty]['@language'] === null);\n    if(isValueOnlyKey &&\n      (!hasDefaultLanguage || !isValueString || hasNullMapping)) {\n      return value['@value'];\n    }\n\n    var rval = {};\n\n    // preserve @index\n    if(preserveIndex) {\n      rval[_compactIri(activeCtx, '@index')] = value['@index'];\n    }\n\n    if('@type' in value) {\n      // compact @type IRI\n      rval[_compactIri(activeCtx, '@type')] = _compactIri(\n        activeCtx, value['@type'], null, {vocab: true});\n    } else if('@language' in value) {\n      // alias @language\n      rval[_compactIri(activeCtx, '@language')] = value['@language'];\n    }\n\n    // alias @value\n    rval[_compactIri(activeCtx, '@value')] = value['@value'];\n\n    return rval;\n  }\n\n  // value is a subject reference\n  var expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true});\n  var type = jsonld.getContextValue(activeCtx, activeProperty, '@type');\n  var compacted = _compactIri(\n    activeCtx, value['@id'], null, {vocab: type === '@vocab'});\n\n  // compact to scalar\n  if(type === '@id' || type === '@vocab' || expandedProperty === '@graph') {\n    return compacted;\n  }\n\n  var rval = {};\n  rval[_compactIri(activeCtx, '@id')] = compacted;\n  return rval;\n}\n\n/**\n * Creates a term definition during context processing.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context being processed.\n * @param term the term in the local context to define the mapping for.\n * @param defined a map of defining/defined keys to detect cycles and prevent\n *          double definitions.\n */\nfunction _createTermDefinition(activeCtx, localCtx, term, defined) {\n  if(term in defined) {\n    // term already defined\n    if(defined[term]) {\n      return;\n    }\n    // cycle detected\n    throw new JsonLdError(\n      'Cyclical context definition detected.',\n      'jsonld.CyclicalContext',\n      {code: 'cyclic IRI mapping', context: localCtx, term: term});\n  }\n\n  // now defining term\n  defined[term] = false;\n\n  if(_isKeyword(term)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; keywords cannot be overridden.',\n      'jsonld.SyntaxError',\n      {code: 'keyword redefinition', context: localCtx, term: term});\n  }\n\n  if(term === '') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; a term cannot be an empty string.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // remove old mapping\n  if(activeCtx.mappings[term]) {\n    delete activeCtx.mappings[term];\n  }\n\n  // get context term value\n  var value = localCtx[term];\n\n  // clear context entry\n  if(value === null || (_isObject(value) && value['@id'] === null)) {\n    activeCtx.mappings[term] = null;\n    defined[term] = true;\n    return;\n  }\n\n  // convert short-hand value to object w/@id\n  if(_isString(value)) {\n    value = {'@id': value};\n  }\n\n  if(!_isObject(value)) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context property values must be ' +\n      'strings or objects.',\n      'jsonld.SyntaxError',\n      {code: 'invalid term definition', context: localCtx});\n  }\n\n  // create new mapping\n  var mapping = activeCtx.mappings[term] = {};\n  mapping.reverse = false;\n\n  if('@reverse' in value) {\n    if('@id' in value) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @reverse term definition must not ' +\n        'contain @id.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n    var reverse = value['@reverse'];\n    if(!_isString(reverse)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n\n    // expand and add @id mapping\n    var id = _expandIri(\n      activeCtx, reverse, {vocab: true, base: false}, localCtx, defined);\n    if(!_isAbsoluteIri(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @reverse value must be an ' +\n        'absolute IRI or a blank node identifier.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n    mapping['@id'] = id;\n    mapping.reverse = true;\n  } else if('@id' in value) {\n    var id = value['@id'];\n    if(!_isString(id)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; a @context @id value must be an array ' +\n        'of strings or a string.',\n        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});\n    }\n    if(id !== term) {\n      // expand and add @id mapping\n      id = _expandIri(\n        activeCtx, id, {vocab: true, base: false}, localCtx, defined);\n      if(!_isAbsoluteIri(id) && !_isKeyword(id)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; a @context @id value must be an ' +\n          'absolute IRI, a blank node identifier, or a keyword.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx});\n      }\n      mapping['@id'] = id;\n    }\n  }\n\n  // always compute whether term has a colon as an optimization for\n  // _compactIri\n  var colon = term.indexOf(':');\n  mapping._termHasColon = (colon !== -1);\n\n  if(!('@id' in mapping)) {\n    // see if the term has a prefix\n    if(mapping._termHasColon) {\n      var prefix = term.substr(0, colon);\n      if(prefix in localCtx) {\n        // define parent prefix\n        _createTermDefinition(activeCtx, localCtx, prefix, defined);\n      }\n\n      if(activeCtx.mappings[prefix]) {\n        // set @id based on prefix parent\n        var suffix = term.substr(colon + 1);\n        mapping['@id'] = activeCtx.mappings[prefix]['@id'] + suffix;\n      } else {\n        // term is an absolute IRI\n        mapping['@id'] = term;\n      }\n    } else {\n      // non-IRIs *must* define @ids if @vocab is not available\n      if(!('@vocab' in activeCtx)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; @context terms must define an @id.',\n          'jsonld.SyntaxError',\n          {code: 'invalid IRI mapping', context: localCtx, term: term});\n      }\n      // prepend vocab to term\n      mapping['@id'] = activeCtx['@vocab'] + term;\n    }\n  }\n\n  // IRI mapping now defined\n  defined[term] = true;\n\n  if('@type' in value) {\n    var type = value['@type'];\n    if(!_isString(type)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; an @context @type values must be a string.',\n        'jsonld.SyntaxError',\n        {code: 'invalid type mapping', context: localCtx});\n    }\n\n    if(type !== '@id' && type !== '@vocab') {\n      // expand @type to full IRI\n      type = _expandIri(\n        activeCtx, type, {vocab: true, base: false}, localCtx, defined);\n      if(!_isAbsoluteIri(type)) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type value must be an ' +\n          'absolute IRI.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n      if(type.indexOf('_:') === 0) {\n        throw new JsonLdError(\n          'Invalid JSON-LD syntax; an @context @type values must be an IRI, ' +\n          'not a blank node identifier.',\n          'jsonld.SyntaxError',\n          {code: 'invalid type mapping', context: localCtx});\n      }\n    }\n\n    // add @type to mapping\n    mapping['@type'] = type;\n  }\n\n  if('@container' in value) {\n    var container = value['@container'];\n    if(container !== '@list' && container !== '@set' &&\n      container !== '@index' && container !== '@language') {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value must be ' +\n        'one of the following: @list, @set, @index, or @language.',\n        'jsonld.SyntaxError',\n        {code: 'invalid container mapping', context: localCtx});\n    }\n    if(mapping.reverse && container !== '@index' && container !== '@set' &&\n      container !== null) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @container value for a @reverse ' +\n        'type definition must be @index or @set.', 'jsonld.SyntaxError',\n        {code: 'invalid reverse property', context: localCtx});\n    }\n\n    // add @container to mapping\n    mapping['@container'] = container;\n  }\n\n  if('@language' in value && !('@type' in value)) {\n    var language = value['@language'];\n    if(language !== null && !_isString(language)) {\n      throw new JsonLdError(\n        'Invalid JSON-LD syntax; @context @language value must be ' +\n        'a string or null.', 'jsonld.SyntaxError',\n        {code: 'invalid language mapping', context: localCtx});\n    }\n\n    // add @language to mapping\n    if(language !== null) {\n      language = language.toLowerCase();\n    }\n    mapping['@language'] = language;\n  }\n\n  // disallow aliasing @context and @preserve\n  var id = mapping['@id'];\n  if(id === '@context' || id === '@preserve') {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; @context and @preserve cannot be aliased.',\n      'jsonld.SyntaxError', {code: 'invalid keyword alias', context: localCtx});\n  }\n}\n\n/**\n * Expands a string to a full IRI. The string may be a term, a prefix, a\n * relative IRI, or an absolute IRI. The associated absolute IRI will be\n * returned.\n *\n * @param activeCtx the current active context.\n * @param value the string to expand.\n * @param relativeTo options for how to resolve relative IRIs:\n *          base: true to resolve against the base IRI, false not to.\n *          vocab: true to concatenate after @vocab, false not to.\n * @param localCtx the local context being processed (only given if called\n *          during context processing).\n * @param defined a map for tracking cycles in context definitions (only given\n *          if called during context processing).\n *\n * @return the expanded value.\n */\nfunction _expandIri(activeCtx, value, relativeTo, localCtx, defined) {\n  // already expanded\n  if(value === null || _isKeyword(value)) {\n    return value;\n  }\n\n  // ensure value is interpreted as a string\n  value = String(value);\n\n  // define term dependency if not defined\n  if(localCtx && value in localCtx && defined[value] !== true) {\n    _createTermDefinition(activeCtx, localCtx, value, defined);\n  }\n\n  relativeTo = relativeTo || {};\n  if(relativeTo.vocab) {\n    var mapping = activeCtx.mappings[value];\n\n    // value is explicitly ignored with a null mapping\n    if(mapping === null) {\n      return null;\n    }\n\n    if(mapping) {\n      // value is a term\n      return mapping['@id'];\n    }\n  }\n\n  // split value into prefix:suffix\n  var colon = value.indexOf(':');\n  if(colon !== -1) {\n    var prefix = value.substr(0, colon);\n    var suffix = value.substr(colon + 1);\n\n    // do not expand blank nodes (prefix of '_') or already-absolute\n    // IRIs (suffix of '//')\n    if(prefix === '_' || suffix.indexOf('//') === 0) {\n      return value;\n    }\n\n    // prefix dependency not defined, define it\n    if(localCtx && prefix in localCtx) {\n      _createTermDefinition(activeCtx, localCtx, prefix, defined);\n    }\n\n    // use mapping if prefix is defined\n    var mapping = activeCtx.mappings[prefix];\n    if(mapping) {\n      return mapping['@id'] + suffix;\n    }\n\n    // already absolute IRI\n    return value;\n  }\n\n  // prepend vocab\n  if(relativeTo.vocab && '@vocab' in activeCtx) {\n    return activeCtx['@vocab'] + value;\n  }\n\n  // prepend base\n  var rval = value;\n  if(relativeTo.base) {\n    rval = jsonld.prependBase(activeCtx['@base'], rval);\n  }\n\n  return rval;\n}\n\nfunction _prependBase(base, iri) {\n  // skip IRI processing\n  if(base === null) {\n    return iri;\n  }\n  // already an absolute IRI\n  if(iri.indexOf(':') !== -1) {\n    return iri;\n  }\n\n  // parse base if it is a string\n  if(_isString(base)) {\n    base = jsonld.url.parse(base || '');\n  }\n\n  // parse given IRI\n  var rel = jsonld.url.parse(iri);\n\n  // per RFC3986 5.2.2\n  var transform = {\n    protocol: base.protocol || ''\n  };\n\n  if(rel.authority !== null) {\n    transform.authority = rel.authority;\n    transform.path = rel.path;\n    transform.query = rel.query;\n  } else {\n    transform.authority = base.authority;\n\n    if(rel.path === '') {\n      transform.path = base.path;\n      if(rel.query !== null) {\n        transform.query = rel.query;\n      } else {\n        transform.query = base.query;\n      }\n    } else {\n      if(rel.path.indexOf('/') === 0) {\n        // IRI represents an absolute path\n        transform.path = rel.path;\n      } else {\n        // merge paths\n        var path = base.path;\n\n        // append relative path to the end of the last directory from base\n        if(rel.path !== '') {\n          path = path.substr(0, path.lastIndexOf('/') + 1);\n          if(path.length > 0 && path.substr(-1) !== '/') {\n            path += '/';\n          }\n          path += rel.path;\n        }\n\n        transform.path = path;\n      }\n      transform.query = rel.query;\n    }\n  }\n\n  // remove slashes and dots in path\n  transform.path = _removeDotSegments(transform.path, !!transform.authority);\n\n  // construct URL\n  var rval = transform.protocol;\n  if(transform.authority !== null) {\n    rval += '//' + transform.authority;\n  }\n  rval += transform.path;\n  if(transform.query !== null) {\n    rval += '?' + transform.query;\n  }\n  if(rel.fragment !== null) {\n    rval += '#' + rel.fragment;\n  }\n\n  // handle empty base\n  if(rval === '') {\n    rval = './';\n  }\n\n  return rval;\n}\n\n/**\n * Removes a base IRI from the given absolute IRI.\n *\n * @param base the base IRI.\n * @param iri the absolute IRI.\n *\n * @return the relative IRI if relative to base, otherwise the absolute IRI.\n */\nfunction _removeBase(base, iri) {\n  // skip IRI processing\n  if(base === null) {\n    return iri;\n  }\n\n  if(_isString(base)) {\n    base = jsonld.url.parse(base || '');\n  }\n\n  // establish base root\n  var root = '';\n  if(base.href !== '') {\n    root += (base.protocol || '') + '//' + (base.authority || '');\n  } else if(iri.indexOf('//')) {\n    // support network-path reference with empty base\n    root += '//';\n  }\n\n  // IRI not relative to base\n  if(iri.indexOf(root) !== 0) {\n    return iri;\n  }\n\n  // remove root from IRI and parse remainder\n  var rel = jsonld.url.parse(iri.substr(root.length));\n\n  // remove path segments that match (do not remove last segment unless there\n  // is a hash or query)\n  var baseSegments = base.normalizedPath.split('/');\n  var iriSegments = rel.normalizedPath.split('/');\n  var last = (rel.fragment || rel.query) ? 0 : 1;\n  while(baseSegments.length > 0 && iriSegments.length > last) {\n    if(baseSegments[0] !== iriSegments[0]) {\n      break;\n    }\n    baseSegments.shift();\n    iriSegments.shift();\n  }\n\n  // use '../' for each non-matching base segment\n  var rval = '';\n  if(baseSegments.length > 0) {\n    // don't count the last segment (if it ends with '/' last path doesn't\n    // count and if it doesn't end with '/' it isn't a path)\n    baseSegments.pop();\n    for(var i = 0; i < baseSegments.length; ++i) {\n      rval += '../';\n    }\n  }\n\n  // prepend remaining segments\n  rval += iriSegments.join('/');\n\n  // add query and hash\n  if(rel.query !== null) {\n    rval += '?' + rel.query;\n  }\n  if(rel.fragment !== null) {\n    rval += '#' + rel.fragment;\n  }\n\n  // handle empty base\n  if(rval === '') {\n    rval = './';\n  }\n\n  return rval;\n}\n\n/**\n * Gets the initial context.\n *\n * @param options the options to use:\n *          [base] the document base IRI.\n *\n * @return the initial context.\n */\nfunction _getInitialContext(options) {\n  var base = jsonld.url.parse(options.base || '');\n  return {\n    '@base': base,\n    mappings: {},\n    inverse: null,\n    getInverse: _createInverseContext,\n    clone: _cloneActiveContext\n  };\n\n  /**\n   * Generates an inverse context for use in the compaction algorithm, if\n   * not already generated for the given active context.\n   *\n   * @return the inverse context.\n   */\n  function _createInverseContext() {\n    var activeCtx = this;\n\n    // lazily create inverse\n    if(activeCtx.inverse) {\n      return activeCtx.inverse;\n    }\n    var inverse = activeCtx.inverse = {};\n\n    // variables for building fast CURIE map\n    var fastCurieMap = activeCtx.fastCurieMap = {};\n    var irisToTerms = {};\n\n    // handle default language\n    var defaultLanguage = activeCtx['@language'] || '@none';\n\n    // create term selections for each mapping in the context, ordered by\n    // shortest and then lexicographically least\n    var mappings = activeCtx.mappings;\n    var terms = Object.keys(mappings).sort(_compareShortestLeast);\n    for(var i = 0; i < terms.length; ++i) {\n      var term = terms[i];\n      var mapping = mappings[term];\n      if(mapping === null) {\n        continue;\n      }\n\n      var container = mapping['@container'] || '@none';\n\n      // iterate over every IRI in the mapping\n      var ids = mapping['@id'];\n      if(!_isArray(ids)) {\n        ids = [ids];\n      }\n      for(var ii = 0; ii < ids.length; ++ii) {\n        var iri = ids[ii];\n        var entry = inverse[iri];\n        var isKeyword = _isKeyword(iri);\n\n        if(!entry) {\n          // initialize entry\n          inverse[iri] = entry = {};\n\n          if(!isKeyword && !mapping._termHasColon) {\n            // init IRI to term map and fast CURIE prefixes\n            irisToTerms[iri] = [term];\n            var fastCurieEntry = {iri: iri, terms: irisToTerms[iri]};\n            if(iri[0] in fastCurieMap) {\n              fastCurieMap[iri[0]].push(fastCurieEntry);\n            } else {\n              fastCurieMap[iri[0]] = [fastCurieEntry];\n            }\n          }\n        } else if(!isKeyword && !mapping._termHasColon) {\n          // add IRI to term match\n          irisToTerms[iri].push(term);\n        }\n\n        // add new entry\n        if(!entry[container]) {\n          entry[container] = {\n            '@language': {},\n            '@type': {}\n          };\n        }\n        entry = entry[container];\n\n        if(mapping.reverse) {\n          // term is preferred for values using @reverse\n          _addPreferredTerm(mapping, term, entry['@type'], '@reverse');\n        } else if('@type' in mapping) {\n          // term is preferred for values using specific type\n          _addPreferredTerm(mapping, term, entry['@type'], mapping['@type']);\n        } else if('@language' in mapping) {\n          // term is preferred for values using specific language\n          var language = mapping['@language'] || '@null';\n          _addPreferredTerm(mapping, term, entry['@language'], language);\n        } else {\n          // term is preferred for values w/default language or no type and\n          // no language\n          // add an entry for the default language\n          _addPreferredTerm(mapping, term, entry['@language'], defaultLanguage);\n\n          // add entries for no type and no language\n          _addPreferredTerm(mapping, term, entry['@type'], '@none');\n          _addPreferredTerm(mapping, term, entry['@language'], '@none');\n        }\n      }\n    }\n\n    // build fast CURIE map\n    for(var key in fastCurieMap) {\n      _buildIriMap(fastCurieMap, key, 1);\n    }\n\n    return inverse;\n  }\n\n  /**\n   * Runs a recursive algorithm to build a lookup map for quickly finding\n   * potential CURIEs.\n   *\n   * @param iriMap the map to build.\n   * @param key the current key in the map to work on.\n   * @param idx the index into the IRI to compare.\n   */\n  function _buildIriMap(iriMap, key, idx) {\n    var entries = iriMap[key];\n    var next = iriMap[key] = {};\n\n    var iri;\n    var letter;\n    for(var i = 0; i < entries.length; ++i) {\n      iri = entries[i].iri;\n      if(idx >= iri.length) {\n        letter = '';\n      } else {\n        letter = iri[idx];\n      }\n      if(letter in next) {\n        next[letter].push(entries[i]);\n      } else {\n        next[letter] = [entries[i]];\n      }\n    }\n\n    for(var key in next) {\n      if(key === '') {\n        continue;\n      }\n      _buildIriMap(next, key, idx + 1);\n    }\n  }\n\n  /**\n   * Adds the term for the given entry if not already added.\n   *\n   * @param mapping the term mapping.\n   * @param term the term to add.\n   * @param entry the inverse context typeOrLanguage entry to add to.\n   * @param typeOrLanguageValue the key in the entry to add to.\n   */\n  function _addPreferredTerm(mapping, term, entry, typeOrLanguageValue) {\n    if(!(typeOrLanguageValue in entry)) {\n      entry[typeOrLanguageValue] = term;\n    }\n  }\n\n  /**\n   * Clones an active context, creating a child active context.\n   *\n   * @return a clone (child) of the active context.\n   */\n  function _cloneActiveContext() {\n    var child = {};\n    child['@base'] = this['@base'];\n    child.mappings = _clone(this.mappings);\n    child.clone = this.clone;\n    child.inverse = null;\n    child.getInverse = this.getInverse;\n    if('@language' in this) {\n      child['@language'] = this['@language'];\n    }\n    if('@vocab' in this) {\n      child['@vocab'] = this['@vocab'];\n    }\n    return child;\n  }\n}\n\n/**\n * Returns whether or not the given value is a keyword.\n *\n * @param v the value to check.\n *\n * @return true if the value is a keyword, false if not.\n */\nfunction _isKeyword(v) {\n  if(!_isString(v)) {\n    return false;\n  }\n  switch(v) {\n  case '@base':\n  case '@context':\n  case '@container':\n  case '@default':\n  case '@embed':\n  case '@explicit':\n  case '@graph':\n  case '@id':\n  case '@index':\n  case '@language':\n  case '@list':\n  case '@omitDefault':\n  case '@preserve':\n  case '@requireAll':\n  case '@reverse':\n  case '@set':\n  case '@type':\n  case '@value':\n  case '@vocab':\n    return true;\n  }\n  return false;\n}\n\n/**\n * Returns true if the given value is an Object.\n *\n * @param v the value to check.\n *\n * @return true if the value is an Object, false if not.\n */\nfunction _isObject(v) {\n  return (Object.prototype.toString.call(v) === '[object Object]');\n}\n\n/**\n * Returns true if the given value is an empty Object.\n *\n * @param v the value to check.\n *\n * @return true if the value is an empty Object, false if not.\n */\nfunction _isEmptyObject(v) {\n  return _isObject(v) && Object.keys(v).length === 0;\n}\n\n/**\n * Returns true if the given value is an Array.\n *\n * @param v the value to check.\n *\n * @return true if the value is an Array, false if not.\n */\nfunction _isArray(v) {\n  return Array.isArray(v);\n}\n\n/**\n * Throws an exception if the given value is not a valid @type value.\n *\n * @param v the value to check.\n */\nfunction _validateTypeValue(v) {\n  // can be a string or an empty object\n  if(_isString(v) || _isEmptyObject(v)) {\n    return;\n  }\n\n  // must be an array\n  var isValid = false;\n  if(_isArray(v)) {\n    // must contain only strings\n    isValid = true;\n    for(var i = 0; i < v.length; ++i) {\n      if(!(_isString(v[i]))) {\n        isValid = false;\n        break;\n      }\n    }\n  }\n\n  if(!isValid) {\n    throw new JsonLdError(\n      'Invalid JSON-LD syntax; \"@type\" value must a string, an array of ' +\n      'strings, or an empty object.', 'jsonld.SyntaxError',\n      {code: 'invalid type value', value: v});\n  }\n}\n\n/**\n * Returns true if the given value is a String.\n *\n * @param v the value to check.\n *\n * @return true if the value is a String, false if not.\n */\nfunction _isString(v) {\n  return (typeof v === 'string' ||\n    Object.prototype.toString.call(v) === '[object String]');\n}\n\n/**\n * Returns true if the given value is a Number.\n *\n * @param v the value to check.\n *\n * @return true if the value is a Number, false if not.\n */\nfunction _isNumber(v) {\n  return (typeof v === 'number' ||\n    Object.prototype.toString.call(v) === '[object Number]');\n}\n\n/**\n * Returns true if the given value is a double.\n *\n * @param v the value to check.\n *\n * @return true if the value is a double, false if not.\n */\nfunction _isDouble(v) {\n  return _isNumber(v) && String(v).indexOf('.') !== -1;\n}\n\n/**\n * Returns true if the given value is numeric.\n *\n * @param v the value to check.\n *\n * @return true if the value is numeric, false if not.\n */\nfunction _isNumeric(v) {\n  return !isNaN(parseFloat(v)) && isFinite(v);\n}\n\n/**\n * Returns true if the given value is a Boolean.\n *\n * @param v the value to check.\n *\n * @return true if the value is a Boolean, false if not.\n */\nfunction _isBoolean(v) {\n  return (typeof v === 'boolean' ||\n    Object.prototype.toString.call(v) === '[object Boolean]');\n}\n\n/**\n * Returns true if the given value is undefined.\n *\n * @param v the value to check.\n *\n * @return true if the value is undefined, false if not.\n */\nfunction _isUndefined(v) {\n  return (typeof v === 'undefined');\n}\n\n/**\n * Returns true if the given value is a subject with properties.\n *\n * @param v the value to check.\n *\n * @return true if the value is a subject with properties, false if not.\n */\nfunction _isSubject(v) {\n  // Note: A value is a subject if all of these hold true:\n  // 1. It is an Object.\n  // 2. It is not a @value, @set, or @list.\n  // 3. It has more than 1 key OR any existing key is not @id.\n  var rval = false;\n  if(_isObject(v) &&\n    !(('@value' in v) || ('@set' in v) || ('@list' in v))) {\n    var keyCount = Object.keys(v).length;\n    rval = (keyCount > 1 || !('@id' in v));\n  }\n  return rval;\n}\n\n/**\n * Returns true if the given value is a subject reference.\n *\n * @param v the value to check.\n *\n * @return true if the value is a subject reference, false if not.\n */\nfunction _isSubjectReference(v) {\n  // Note: A value is a subject reference if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has a single key: @id.\n  return (_isObject(v) && Object.keys(v).length === 1 && ('@id' in v));\n}\n\n/**\n * Returns true if the given value is a @value.\n *\n * @param v the value to check.\n *\n * @return true if the value is a @value, false if not.\n */\nfunction _isValue(v) {\n  // Note: A value is a @value if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has the @value property.\n  return _isObject(v) && ('@value' in v);\n}\n\n/**\n * Returns true if the given value is a @list.\n *\n * @param v the value to check.\n *\n * @return true if the value is a @list, false if not.\n */\nfunction _isList(v) {\n  // Note: A value is a @list if all of these hold true:\n  // 1. It is an Object.\n  // 2. It has the @list property.\n  return _isObject(v) && ('@list' in v);\n}\n\n/**\n * Returns true if the given value is a blank node.\n *\n * @param v the value to check.\n *\n * @return true if the value is a blank node, false if not.\n */\nfunction _isBlankNode(v) {\n  // Note: A value is a blank node if all of these hold true:\n  // 1. It is an Object.\n  // 2. If it has an @id key its value begins with '_:'.\n  // 3. It has no keys OR is not a @value, @set, or @list.\n  var rval = false;\n  if(_isObject(v)) {\n    if('@id' in v) {\n      rval = (v['@id'].indexOf('_:') === 0);\n    } else {\n      rval = (Object.keys(v).length === 0 ||\n        !(('@value' in v) || ('@set' in v) || ('@list' in v)));\n    }\n  }\n  return rval;\n}\n\n/**\n * Returns true if the given value is an absolute IRI, false if not.\n *\n * @param v the value to check.\n *\n * @return true if the value is an absolute IRI, false if not.\n */\nfunction _isAbsoluteIri(v) {\n  return _isString(v) && v.indexOf(':') !== -1;\n}\n\n/**\n * Clones an object, array, or string/number. If a typed JavaScript object\n * is given, such as a Date, it will be converted to a string.\n *\n * @param value the value to clone.\n *\n * @return the cloned value.\n */\nfunction _clone(value) {\n  if(value && typeof value === 'object') {\n    var rval;\n    if(_isArray(value)) {\n      rval = [];\n      for(var i = 0; i < value.length; ++i) {\n        rval[i] = _clone(value[i]);\n      }\n    } else if(_isObject(value)) {\n      rval = {};\n      for(var key in value) {\n        rval[key] = _clone(value[key]);\n      }\n    } else {\n      rval = value.toString();\n    }\n    return rval;\n  }\n  return value;\n}\n\n/**\n * Finds all @context URLs in the given JSON-LD input.\n *\n * @param input the JSON-LD input.\n * @param urls a map of URLs (url => false/@contexts).\n * @param replace true to replace the URLs in the given input with the\n *           @contexts from the urls map, false not to.\n * @param base the base IRI to use to resolve relative IRIs.\n *\n * @return true if new URLs to retrieve were found, false if not.\n */\nfunction _findContextUrls(input, urls, replace, base) {\n  var count = Object.keys(urls).length;\n  if(_isArray(input)) {\n    for(var i = 0; i < input.length; ++i) {\n      _findContextUrls(input[i], urls, replace, base);\n    }\n    return (count < Object.keys(urls).length);\n  } else if(_isObject(input)) {\n    for(var key in input) {\n      if(key !== '@context') {\n        _findContextUrls(input[key], urls, replace, base);\n        continue;\n      }\n\n      // get @context\n      var ctx = input[key];\n\n      // array @context\n      if(_isArray(ctx)) {\n        var length = ctx.length;\n        for(var i = 0; i < length; ++i) {\n          var _ctx = ctx[i];\n          if(_isString(_ctx)) {\n            _ctx = jsonld.prependBase(base, _ctx);\n            // replace w/@context if requested\n            if(replace) {\n              _ctx = urls[_ctx];\n              if(_isArray(_ctx)) {\n                // add flattened context\n                Array.prototype.splice.apply(ctx, [i, 1].concat(_ctx));\n                i += _ctx.length - 1;\n                length = ctx.length;\n              } else {\n                ctx[i] = _ctx;\n              }\n            } else if(!(_ctx in urls)) {\n              // @context URL found\n              urls[_ctx] = false;\n            }\n          }\n        }\n      } else if(_isString(ctx)) {\n        // string @context\n        ctx = jsonld.prependBase(base, ctx);\n        // replace w/@context if requested\n        if(replace) {\n          input[key] = urls[ctx];\n        } else if(!(ctx in urls)) {\n          // @context URL found\n          urls[ctx] = false;\n        }\n      }\n    }\n    return (count < Object.keys(urls).length);\n  }\n  return false;\n}\n\n/**\n * Retrieves external @context URLs using the given document loader. Every\n * instance of @context in the input that refers to a URL will be replaced\n * with the JSON @context found at that URL.\n *\n * @param input the JSON-LD input with possible contexts.\n * @param options the options to use:\n *          documentLoader(url, callback(err, remoteDoc)) the document loader.\n * @param callback(err, input) called once the operation completes.\n */\nfunction _retrieveContextUrls(input, options, callback) {\n  // if any error occurs during URL resolution, quit\n  var error = null;\n\n  // recursive document loader\n  var documentLoader = options.documentLoader;\n  var retrieve = function(input, cycles, documentLoader, base, callback) {\n    if(Object.keys(cycles).length > MAX_CONTEXT_URLS) {\n      error = new JsonLdError(\n        'Maximum number of @context URLs exceeded.',\n        'jsonld.ContextUrlError',\n        {code: 'loading remote context failed', max: MAX_CONTEXT_URLS});\n      return callback(error);\n    }\n\n    // for tracking the URLs to retrieve\n    var urls = {};\n\n    // finished will be called once the URL queue is empty\n    var finished = function() {\n      // replace all URLs in the input\n      _findContextUrls(input, urls, true, base);\n      callback(null, input);\n    };\n\n    // find all URLs in the given input\n    if(!_findContextUrls(input, urls, false, base)) {\n      // no new URLs in input\n      return finished();\n    }\n\n    // queue all unretrieved URLs\n    var queue = [];\n    for(var url in urls) {\n      if(urls[url] === false) {\n        queue.push(url);\n      }\n    }\n\n    // retrieve URLs in queue\n    var count = queue.length;\n    for(var i = 0; i < queue.length; ++i) {\n      (function(url) {\n        // check for context URL cycle\n        if(url in cycles) {\n          error = new JsonLdError(\n            'Cyclical @context URLs detected.',\n            'jsonld.ContextUrlError',\n            {code: 'recursive context inclusion', url: url});\n          return callback(error);\n        }\n        var _cycles = _clone(cycles);\n        _cycles[url] = true;\n        var done = function(err, remoteDoc) {\n          // short-circuit if there was an error with another URL\n          if(error) {\n            return;\n          }\n\n          var ctx = remoteDoc ? remoteDoc.document : null;\n\n          // parse string context as JSON\n          if(!err && _isString(ctx)) {\n            try {\n              ctx = JSON.parse(ctx);\n            } catch(ex) {\n              err = ex;\n            }\n          }\n\n          // ensure ctx is an object\n          if(err) {\n            err = new JsonLdError(\n              'Dereferencing a URL did not result in a valid JSON-LD object. ' +\n              'Possible causes are an inaccessible URL perhaps due to ' +\n              'a same-origin policy (ensure the server uses CORS if you are ' +\n              'using client-side JavaScript), too many redirects, a ' +\n              'non-JSON response, or more than one HTTP Link Header was ' +\n              'provided for a remote context.',\n              'jsonld.InvalidUrl',\n              {code: 'loading remote context failed', url: url, cause: err});\n          } else if(!_isObject(ctx)) {\n            err = new JsonLdError(\n              'Dereferencing a URL did not result in a JSON object. The ' +\n              'response was valid JSON, but it was not a JSON object.',\n              'jsonld.InvalidUrl',\n              {code: 'invalid remote context', url: url, cause: err});\n          }\n          if(err) {\n            error = err;\n            return callback(error);\n          }\n\n          // use empty context if no @context key is present\n          if(!('@context' in ctx)) {\n            ctx = {'@context': {}};\n          } else {\n            ctx = {'@context': ctx['@context']};\n          }\n\n          // append context URL to context if given\n          if(remoteDoc.contextUrl) {\n            if(!_isArray(ctx['@context'])) {\n              ctx['@context'] = [ctx['@context']];\n            }\n            ctx['@context'].push(remoteDoc.contextUrl);\n          }\n\n          // recurse\n          retrieve(ctx, _cycles, documentLoader, url, function(err, ctx) {\n            if(err) {\n              return callback(err);\n            }\n            urls[url] = ctx['@context'];\n            count -= 1;\n            if(count === 0) {\n              finished();\n            }\n          });\n        };\n        var promise = documentLoader(url, done);\n        if(promise && 'then' in promise) {\n          promise.then(done.bind(null, null), done);\n        }\n      }(queue[i]));\n    }\n  };\n  retrieve(input, {}, documentLoader, options.base, callback);\n}\n\n// define js 1.8.5 Object.keys method if not present\nif(!Object.keys) {\n  Object.keys = function(o) {\n    if(o !== Object(o)) {\n      throw new TypeError('Object.keys called on non-object');\n    }\n    var rval = [];\n    for(var p in o) {\n      if(Object.prototype.hasOwnProperty.call(o, p)) {\n        rval.push(p);\n      }\n    }\n    return rval;\n  };\n}\n\n/**\n * Parses RDF in the form of N-Quads.\n *\n * @param input the N-Quads input to parse.\n *\n * @return an RDF dataset.\n */\nfunction _parseNQuads(input) {\n  // define partial regexes\n  var iri = '(?:<([^:]+:[^>]*)>)';\n  var bnode = '(_:(?:[A-Za-z0-9]+))';\n  var plain = '\"([^\"\\\\\\\\]*(?:\\\\\\\\.[^\"\\\\\\\\]*)*)\"';\n  var datatype = '(?:\\\\^\\\\^' + iri + ')';\n  var language = '(?:@([a-z]+(?:-[a-z0-9]+)*))';\n  var literal = '(?:' + plain + '(?:' + datatype + '|' + language + ')?)';\n  var comment = '(?:#.*)?';\n  var ws = '[ \\\\t]+';\n  var wso = '[ \\\\t]*';\n  var eoln = /(?:\\r\\n)|(?:\\n)|(?:\\r)/g;\n  var empty = new RegExp('^' + wso + comment + '$');\n\n  // define quad part regexes\n  var subject = '(?:' + iri + '|' + bnode + ')' + ws;\n  var property = iri + ws;\n  var object = '(?:' + iri + '|' + bnode + '|' + literal + ')' + wso;\n  var graphName = '(?:\\\\.|(?:(?:' + iri + '|' + bnode + ')' + wso + '\\\\.))';\n\n  // full quad regex\n  var quad = new RegExp(\n    '^' + wso + subject + property + object + graphName + wso + comment + '$');\n\n  // build RDF dataset\n  var dataset = {};\n\n  // split N-Quad input into lines\n  var lines = input.split(eoln);\n  var lineNumber = 0;\n  for(var li = 0; li < lines.length; ++li) {\n    var line = lines[li];\n    lineNumber++;\n\n    // skip empty lines\n    if(empty.test(line)) {\n      continue;\n    }\n\n    // parse quad\n    var match = line.match(quad);\n    if(match === null) {\n      throw new JsonLdError(\n        'Error while parsing N-Quads; invalid quad.',\n        'jsonld.ParseError', {line: lineNumber});\n    }\n\n    // create RDF triple\n    var triple = {};\n\n    // get subject\n    if(!_isUndefined(match[1])) {\n      triple.subject = {type: 'IRI', value: match[1]};\n    } else {\n      triple.subject = {type: 'blank node', value: match[2]};\n    }\n\n    // get predicate\n    triple.predicate = {type: 'IRI', value: match[3]};\n\n    // get object\n    if(!_isUndefined(match[4])) {\n      triple.object = {type: 'IRI', value: match[4]};\n    } else if(!_isUndefined(match[5])) {\n      triple.object = {type: 'blank node', value: match[5]};\n    } else {\n      triple.object = {type: 'literal'};\n      if(!_isUndefined(match[7])) {\n        triple.object.datatype = match[7];\n      } else if(!_isUndefined(match[8])) {\n        triple.object.datatype = RDF_LANGSTRING;\n        triple.object.language = match[8];\n      } else {\n        triple.object.datatype = XSD_STRING;\n      }\n      var unescaped = match[6]\n        .replace(/\\\\\"/g, '\"')\n        .replace(/\\\\t/g, '\\t')\n        .replace(/\\\\n/g, '\\n')\n        .replace(/\\\\r/g, '\\r')\n        .replace(/\\\\\\\\/g, '\\\\');\n      triple.object.value = unescaped;\n    }\n\n    // get graph name ('@default' is used for the default graph)\n    var name = '@default';\n    if(!_isUndefined(match[9])) {\n      name = match[9];\n    } else if(!_isUndefined(match[10])) {\n      name = match[10];\n    }\n\n    // initialize graph in dataset\n    if(!(name in dataset)) {\n      dataset[name] = [triple];\n    } else {\n      // add triple if unique to its graph\n      var unique = true;\n      var triples = dataset[name];\n      for(var ti = 0; unique && ti < triples.length; ++ti) {\n        if(_compareRDFTriples(triples[ti], triple)) {\n          unique = false;\n        }\n      }\n      if(unique) {\n        triples.push(triple);\n      }\n    }\n  }\n\n  return dataset;\n}\n\n// register the N-Quads RDF parser\njsonld.registerRDFParser('application/nquads', _parseNQuads);\n\n/**\n * Converts an RDF dataset to N-Quads.\n *\n * @param dataset the RDF dataset to convert.\n *\n * @return the N-Quads string.\n */\nfunction _toNQuads(dataset) {\n  var quads = [];\n  for(var graphName in dataset) {\n    var triples = dataset[graphName];\n    for(var ti = 0; ti < triples.length; ++ti) {\n      var triple = triples[ti];\n      if(graphName === '@default') {\n        graphName = null;\n      }\n      quads.push(_toNQuad(triple, graphName));\n    }\n  }\n  return quads.sort().join('');\n}\n\n/**\n * Converts an RDF triple and graph name to an N-Quad string (a single quad).\n *\n * @param triple the RDF triple or quad to convert (a triple or quad may be\n *          passed, if a triple is passed then `graphName` should be given\n *          to specify the name of the graph the triple is in, `null` for\n *          the default graph).\n * @param graphName the name of the graph containing the triple, null for\n *          the default graph.\n *\n * @return the N-Quad string.\n */\nfunction _toNQuad(triple, graphName) {\n  var s = triple.subject;\n  var p = triple.predicate;\n  var o = triple.object;\n  var g = graphName || null;\n  if('name' in triple && triple.name) {\n    g = triple.name.value;\n  }\n\n  var quad = '';\n\n  // subject is an IRI\n  if(s.type === 'IRI') {\n    quad += '<' + s.value + '>';\n  } else {\n    quad += s.value;\n  }\n  quad += ' ';\n\n  // predicate is an IRI\n  if(p.type === 'IRI') {\n    quad += '<' + p.value + '>';\n  } else {\n    quad += p.value;\n  }\n  quad += ' ';\n\n  // object is IRI, bnode, or literal\n  if(o.type === 'IRI') {\n    quad += '<' + o.value + '>';\n  } else if(o.type === 'blank node') {\n    quad += o.value;\n  } else {\n    var escaped = o.value\n      .replace(/\\\\/g, '\\\\\\\\')\n      .replace(/\\t/g, '\\\\t')\n      .replace(/\\n/g, '\\\\n')\n      .replace(/\\r/g, '\\\\r')\n      .replace(/\\\"/g, '\\\\\"');\n    quad += '\"' + escaped + '\"';\n    if(o.datatype === RDF_LANGSTRING) {\n      if(o.language) {\n        quad += '@' + o.language;\n      }\n    } else if(o.datatype !== XSD_STRING) {\n      quad += '^^<' + o.datatype + '>';\n    }\n  }\n\n  // graph\n  if(g !== null && g !== undefined) {\n    if(g.indexOf('_:') !== 0) {\n      quad += ' <' + g + '>';\n    } else {\n      quad += ' ' + g;\n    }\n  }\n\n  quad += ' .\\n';\n  return quad;\n}\n\n/**\n * Parses the RDF dataset found via the data object from the RDFa API.\n *\n * @param data the RDFa API data object.\n *\n * @return the RDF dataset.\n */\nfunction _parseRdfaApiData(data) {\n  var dataset = {};\n  dataset['@default'] = [];\n\n  var subjects = data.getSubjects();\n  for(var si = 0; si < subjects.length; ++si) {\n    var subject = subjects[si];\n    if(subject === null) {\n      continue;\n    }\n\n    // get all related triples\n    var triples = data.getSubjectTriples(subject);\n    if(triples === null) {\n      continue;\n    }\n    var predicates = triples.predicates;\n    for(var predicate in predicates) {\n      // iterate over objects\n      var objects = predicates[predicate].objects;\n      for(var oi = 0; oi < objects.length; ++oi) {\n        var object = objects[oi];\n\n        // create RDF triple\n        var triple = {};\n\n        // add subject\n        if(subject.indexOf('_:') === 0) {\n          triple.subject = {type: 'blank node', value: subject};\n        } else {\n          triple.subject = {type: 'IRI', value: subject};\n        }\n\n        // add predicate\n        if(predicate.indexOf('_:') === 0) {\n          triple.predicate = {type: 'blank node', value: predicate};\n        } else {\n          triple.predicate = {type: 'IRI', value: predicate};\n        }\n\n        // serialize XML literal\n        var value = object.value;\n        if(object.type === RDF_XML_LITERAL) {\n          // initialize XMLSerializer\n          if(!XMLSerializer) {\n            _defineXMLSerializer();\n          }\n          var serializer = new XMLSerializer();\n          value = '';\n          for(var x = 0; x < object.value.length; x++) {\n            if(object.value[x].nodeType === Node.ELEMENT_NODE) {\n              value += serializer.serializeToString(object.value[x]);\n            } else if(object.value[x].nodeType === Node.TEXT_NODE) {\n              value += object.value[x].nodeValue;\n            }\n          }\n        }\n\n        // add object\n        triple.object = {};\n\n        // object is an IRI\n        if(object.type === RDF_OBJECT) {\n          if(object.value.indexOf('_:') === 0) {\n            triple.object.type = 'blank node';\n          } else {\n            triple.object.type = 'IRI';\n          }\n        } else {\n          // object is a literal\n          triple.object.type = 'literal';\n          if(object.type === RDF_PLAIN_LITERAL) {\n            if(object.language) {\n              triple.object.datatype = RDF_LANGSTRING;\n              triple.object.language = object.language;\n            } else {\n              triple.object.datatype = XSD_STRING;\n            }\n          } else {\n            triple.object.datatype = object.type;\n          }\n        }\n        triple.object.value = value;\n\n        // add triple to dataset in default graph\n        dataset['@default'].push(triple);\n      }\n    }\n  }\n\n  return dataset;\n}\n\n// register the RDFa API RDF parser\njsonld.registerRDFParser('rdfa-api', _parseRdfaApiData);\n\n/**\n * Creates a new IdentifierIssuer. A IdentifierIssuer issues unique\n * identifiers, keeping track of any previously issued identifiers.\n *\n * @param prefix the prefix to use ('<prefix><counter>').\n */\nfunction IdentifierIssuer(prefix) {\n  this.prefix = prefix;\n  this.counter = 0;\n  this.existing = {};\n}\njsonld.IdentifierIssuer = IdentifierIssuer;\n// backwards-compability\njsonld.UniqueNamer = IdentifierIssuer;\n\n/**\n * Copies this IdentifierIssuer.\n *\n * @return a copy of this IdentifierIssuer.\n */\nIdentifierIssuer.prototype.clone = function() {\n  var copy = new IdentifierIssuer(this.prefix);\n  copy.counter = this.counter;\n  copy.existing = _clone(this.existing);\n  return copy;\n};\n\n/**\n * Gets the new identifier for the given old identifier, where if no old\n * identifier is given a new identifier will be generated.\n *\n * @param [old] the old identifier to get the new identifier for.\n *\n * @return the new identifier.\n */\nIdentifierIssuer.prototype.getId = function(old) {\n  // return existing old identifier\n  if(old && old in this.existing) {\n    return this.existing[old];\n  }\n\n  // get next identifier\n  var identifier = this.prefix + this.counter;\n  this.counter += 1;\n\n  // save mapping\n  if(old) {\n    this.existing[old] = identifier;\n  }\n\n  return identifier;\n};\n// alias\nIdentifierIssuer.prototype.getName = IdentifierIssuer.prototype.getName;\n\n/**\n * Returns true if the given old identifer has already been assigned a new\n * identifier.\n *\n * @param old the old identifier to check.\n *\n * @return true if the old identifier has been assigned a new identifier, false\n *   if not.\n */\nIdentifierIssuer.prototype.hasId = function(old) {\n  return (old in this.existing);\n};\n// alias\nIdentifierIssuer.prototype.isNamed = IdentifierIssuer.prototype.hasId;\n\n/**\n * A Permutator iterates over all possible permutations of the given array\n * of elements.\n *\n * @param list the array of elements to iterate over.\n */\nvar Permutator = function(list) {\n  // original array\n  this.list = list.sort();\n  // indicates whether there are more permutations\n  this.done = false;\n  // directional info for permutation algorithm\n  this.left = {};\n  for(var i = 0; i < list.length; ++i) {\n    this.left[list[i]] = true;\n  }\n};\n\n/**\n * Returns true if there is another permutation.\n *\n * @return true if there is another permutation, false if not.\n */\nPermutator.prototype.hasNext = function() {\n  return !this.done;\n};\n\n/**\n * Gets the next permutation. Call hasNext() to ensure there is another one\n * first.\n *\n * @return the next permutation.\n */\nPermutator.prototype.next = function() {\n  // copy current permutation\n  var rval = this.list.slice();\n\n  /* Calculate the next permutation using the Steinhaus-Johnson-Trotter\n   permutation algorithm. */\n\n  // get largest mobile element k\n  // (mobile: element is greater than the one it is looking at)\n  var k = null;\n  var pos = 0;\n  var length = this.list.length;\n  for(var i = 0; i < length; ++i) {\n    var element = this.list[i];\n    var left = this.left[element];\n    if((k === null || element > k) &&\n      ((left && i > 0 && element > this.list[i - 1]) ||\n      (!left && i < (length - 1) && element > this.list[i + 1]))) {\n      k = element;\n      pos = i;\n    }\n  }\n\n  // no more permutations\n  if(k === null) {\n    this.done = true;\n  } else {\n    // swap k and the element it is looking at\n    var swap = this.left[k] ? pos - 1 : pos + 1;\n    this.list[pos] = this.list[swap];\n    this.list[swap] = k;\n\n    // reverse the direction of all elements larger than k\n    for(var i = 0; i < length; ++i) {\n      if(this.list[i] > k) {\n        this.left[this.list[i]] = !this.left[this.list[i]];\n      }\n    }\n  }\n\n  return rval;\n};\n\n//////////////////////// DEFINE NORMALIZATION HASH API ////////////////////////\n\n/**\n * Creates a new NormalizeHash for use by the given normalization algorithm.\n *\n * @param algorithm the RDF Dataset Normalization algorithm to use:\n *          'URDNA2015' or 'URGNA2012'.\n */\nvar NormalizeHash = function(algorithm) {\n  if(!(this instanceof NormalizeHash)) {\n    return new NormalizeHash(algorithm);\n  }\n  if(['URDNA2015', 'URGNA2012'].indexOf(algorithm) === -1) {\n    throw new Error(\n      'Invalid RDF Dataset Normalization algorithm: ' + algorithm);\n  }\n  NormalizeHash._init.call(this, algorithm);\n};\nNormalizeHash.hashNQuads = function(algorithm, nquads) {\n  var md = new NormalizeHash(algorithm);\n  for(var i = 0; i < nquads.length; ++i) {\n    md.update(nquads[i]);\n  }\n  return md.digest();\n};\n\n// switch definition of NormalizeHash based on environment\n(function(_nodejs) {\n\nif(_nodejs) {\n  // define NormalizeHash using native crypto lib\n  var crypto = require('crypto');\n  NormalizeHash._init = function(algorithm) {\n    if(algorithm === 'URDNA2015') {\n      algorithm = 'sha256';\n    } else {\n      // assume URGNA2012\n      algorithm = 'sha1';\n    }\n    this.md = crypto.createHash(algorithm);\n  };\n  NormalizeHash.prototype.update = function(msg) {\n    return this.md.update(msg, 'utf8');\n  };\n  NormalizeHash.prototype.digest = function() {\n    return this.md.digest('hex');\n  };\n  return;\n}\n\n// define NormalizeHash using JavaScript\nNormalizeHash._init = function(algorithm) {\n  if(algorithm === 'URDNA2015') {\n    algorithm = new sha256.Algorithm();\n  } else {\n    // assume URGNA2012\n    algorithm = new sha1.Algorithm();\n  }\n  this.md = new MessageDigest(algorithm);\n};\nNormalizeHash.prototype.update = function(msg) {\n  return this.md.update(msg);\n};\nNormalizeHash.prototype.digest = function() {\n  return this.md.digest().toHex();\n};\n\n/////////////////////////// DEFINE MESSAGE DIGEST API /////////////////////////\n\n/**\n * Creates a new MessageDigest.\n *\n * @param algorithm the algorithm to use.\n */\nvar MessageDigest = function(algorithm) {\n  if(!(this instanceof MessageDigest)) {\n    return new MessageDigest(algorithm);\n  }\n\n  this._algorithm = algorithm;\n\n  // create shared padding as needed\n  if(!MessageDigest._padding ||\n    MessageDigest._padding.length < this._algorithm.blockSize) {\n    MessageDigest._padding = String.fromCharCode(128);\n    var c = String.fromCharCode(0x00);\n    var n = 64;\n    while(n > 0) {\n      if(n & 1) {\n        MessageDigest._padding += c;\n      }\n      n >>>= 1;\n      if(n > 0) {\n        c += c;\n      }\n    }\n  }\n\n  // start digest automatically for first time\n  this.start();\n};\n\n/**\n * Starts the digest.\n *\n * @return this digest object.\n */\nMessageDigest.prototype.start = function() {\n  // up to 56-bit message length for convenience\n  this.messageLength = 0;\n\n  // full message length\n  this.fullMessageLength = [];\n  var int32s = this._algorithm.messageLengthSize / 4;\n  for(var i = 0; i < int32s; ++i) {\n    this.fullMessageLength.push(0);\n  }\n\n  // input buffer\n  this._input = new MessageDigest.ByteBuffer();\n\n  // get starting state\n  this.state = this._algorithm.start();\n\n  return this;\n};\n\n/**\n * Updates the digest with the given message input. The input must be\n * a string of characters.\n *\n * @param msg the message input to update with (ByteBuffer or string).\n *\n * @return this digest object.\n */\nMessageDigest.prototype.update = function(msg) {\n  // encode message as a UTF-8 encoded binary string\n  msg = new MessageDigest.ByteBuffer(unescape(encodeURIComponent(msg)));\n\n  // update message length\n  this.messageLength += msg.length();\n  var len = msg.length();\n  len = [(len / 0x100000000) >>> 0, len >>> 0];\n  for(var i = this.fullMessageLength.length - 1; i >= 0; --i) {\n    this.fullMessageLength[i] += len[1];\n    len[1] = len[0] + ((this.fullMessageLength[i] / 0x100000000) >>> 0);\n    this.fullMessageLength[i] = this.fullMessageLength[i] >>> 0;\n    len[0] = ((len[1] / 0x100000000) >>> 0);\n  }\n\n  // add bytes to input buffer\n  this._input.putBytes(msg.bytes());\n\n  // digest blocks\n  while(this._input.length() >= this._algorithm.blockSize) {\n    this.state = this._algorithm.digest(this.state, this._input);\n  }\n\n  // compact input buffer every 2K or if empty\n  if(this._input.read > 2048 || this._input.length() === 0) {\n    this._input.compact();\n  }\n\n  return this;\n};\n\n/**\n * Produces the digest.\n *\n * @return a byte buffer containing the digest value.\n */\nMessageDigest.prototype.digest = function() {\n  /* Note: Here we copy the remaining bytes in the input buffer and add the\n  appropriate padding. Then we do the final update on a copy of the state so\n  that if the user wants to get intermediate digests they can do so. */\n\n  /* Determine the number of bytes that must be added to the message to\n  ensure its length is appropriately congruent. In other words, the data to\n  be digested must be a multiple of `blockSize`. This data includes the\n  message, some padding, and the length of the message. Since the length of\n  the message will be encoded as `messageLengthSize` bytes, that means that\n  the last segment of the data must have `blockSize` - `messageLengthSize`\n  bytes of message and padding. Therefore, the length of the message plus the\n  padding must be congruent to X mod `blockSize` because\n  `blockSize` - `messageLengthSize` = X.\n\n  For example, SHA-1 is congruent to 448 mod 512 and SHA-512 is congruent to\n  896 mod 1024. SHA-1 uses a `blockSize` of 64 bytes (512 bits) and a\n  `messageLengthSize` of 8 bytes (64 bits). SHA-512 uses a `blockSize` of\n  128 bytes (1024 bits) and a `messageLengthSize` of 16 bytes (128 bits).\n\n  In order to fill up the message length it must be filled with padding that\n  begins with 1 bit followed by all 0 bits. Padding must *always* be present,\n  so if the message length is already congruent, then `blockSize` padding bits\n  must be added. */\n\n  // create final block\n  var finalBlock = new MessageDigest.ByteBuffer();\n  finalBlock.putBytes(this._input.bytes());\n\n  // compute remaining size to be digested (include message length size)\n  var remaining = (\n    this.fullMessageLength[this.fullMessageLength.length - 1] +\n    this._algorithm.messageLengthSize);\n\n  // add padding for overflow blockSize - overflow\n  // _padding starts with 1 byte with first bit is set (byte value 128), then\n  // there may be up to (blockSize - 1) other pad bytes\n  var overflow = remaining & (this._algorithm.blockSize - 1);\n  finalBlock.putBytes(MessageDigest._padding.substr(\n    0, this._algorithm.blockSize - overflow));\n\n  // serialize message length in bits in big-endian order; since length\n  // is stored in bytes we multiply by 8 (left shift by 3 and merge in\n  // remainder from )\n  var messageLength = new MessageDigest.ByteBuffer();\n  for(var i = 0; i < this.fullMessageLength.length; ++i) {\n    messageLength.putInt32((this.fullMessageLength[i] << 3) |\n      (this.fullMessageLength[i + 1] >>> 28));\n  }\n\n  // write the length of the message (algorithm-specific)\n  this._algorithm.writeMessageLength(finalBlock, messageLength);\n\n  // digest final block\n  var state = this._algorithm.digest(this.state.copy(), finalBlock);\n\n  // write state to buffer\n  var rval = new MessageDigest.ByteBuffer();\n  state.write(rval);\n  return rval;\n};\n\n/**\n * Creates a simple byte buffer for message digest operations.\n *\n * @param data the data to put in the buffer.\n */\nMessageDigest.ByteBuffer = function(data) {\n  if(typeof data === 'string') {\n    this.data = data;\n  } else {\n    this.data = '';\n  }\n  this.read = 0;\n};\n\n/**\n * Puts a 32-bit integer into this buffer in big-endian order.\n *\n * @param i the 32-bit integer.\n */\nMessageDigest.ByteBuffer.prototype.putInt32 = function(i) {\n  this.data += (\n    String.fromCharCode(i >> 24 & 0xFF) +\n    String.fromCharCode(i >> 16 & 0xFF) +\n    String.fromCharCode(i >> 8 & 0xFF) +\n    String.fromCharCode(i & 0xFF));\n};\n\n/**\n * Gets a 32-bit integer from this buffer in big-endian order and\n * advances the read pointer by 4.\n *\n * @return the word.\n */\nMessageDigest.ByteBuffer.prototype.getInt32 = function() {\n  var rval = (\n    this.data.charCodeAt(this.read) << 24 ^\n    this.data.charCodeAt(this.read + 1) << 16 ^\n    this.data.charCodeAt(this.read + 2) << 8 ^\n    this.data.charCodeAt(this.read + 3));\n  this.read += 4;\n  return rval;\n};\n\n/**\n * Puts the given bytes into this buffer.\n *\n * @param bytes the bytes as a binary-encoded string.\n */\nMessageDigest.ByteBuffer.prototype.putBytes = function(bytes) {\n  this.data += bytes;\n};\n\n/**\n * Gets the bytes in this buffer.\n *\n * @return a string full of UTF-8 encoded characters.\n */\nMessageDigest.ByteBuffer.prototype.bytes = function() {\n  return this.data.slice(this.read);\n};\n\n/**\n * Gets the number of bytes in this buffer.\n *\n * @return the number of bytes in this buffer.\n */\nMessageDigest.ByteBuffer.prototype.length = function() {\n  return this.data.length - this.read;\n};\n\n/**\n * Compacts this buffer.\n */\nMessageDigest.ByteBuffer.prototype.compact = function() {\n  this.data = this.data.slice(this.read);\n  this.read = 0;\n};\n\n/**\n * Converts this buffer to a hexadecimal string.\n *\n * @return a hexadecimal string.\n */\nMessageDigest.ByteBuffer.prototype.toHex = function() {\n  var rval = '';\n  for(var i = this.read; i < this.data.length; ++i) {\n    var b = this.data.charCodeAt(i);\n    if(b < 16) {\n      rval += '0';\n    }\n    rval += b.toString(16);\n  }\n  return rval;\n};\n\n///////////////////////////// DEFINE SHA-1 ALGORITHM //////////////////////////\n\nvar sha1 = {\n  // used for word storage\n  _w: null\n};\n\nsha1.Algorithm = function() {\n  this.name = 'sha1',\n  this.blockSize = 64;\n  this.digestLength = 20;\n  this.messageLengthSize = 8;\n};\n\nsha1.Algorithm.prototype.start = function() {\n  if(!sha1._w) {\n    sha1._w = new Array(80);\n  }\n  return sha1._createState();\n};\n\nsha1.Algorithm.prototype.writeMessageLength = function(\n  finalBlock, messageLength) {\n  // message length is in bits and in big-endian order; simply append\n  finalBlock.putBytes(messageLength.bytes());\n};\n\nsha1.Algorithm.prototype.digest = function(s, input) {\n  // consume 512 bit (64 byte) chunks\n  var t, a, b, c, d, e, f, i;\n  var len = input.length();\n  var _w = sha1._w;\n  while(len >= 64) {\n    // initialize hash value for this chunk\n    a = s.h0;\n    b = s.h1;\n    c = s.h2;\n    d = s.h3;\n    e = s.h4;\n\n    // the _w array will be populated with sixteen 32-bit big-endian words\n    // and then extended into 80 32-bit words according to SHA-1 algorithm\n    // and for 32-79 using Max Locktyukhin's optimization\n\n    // round 1\n    for(i = 0; i < 16; ++i) {\n      t = input.getInt32();\n      _w[i] = t;\n      f = d ^ (b & (c ^ d));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    for(; i < 20; ++i) {\n      t = (_w[i - 3] ^ _w[i - 8] ^ _w[i - 14] ^ _w[i - 16]);\n      t = (t << 1) | (t >>> 31);\n      _w[i] = t;\n      f = d ^ (b & (c ^ d));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x5A827999 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    // round 2\n    for(; i < 32; ++i) {\n      t = (_w[i - 3] ^ _w[i - 8] ^ _w[i - 14] ^ _w[i - 16]);\n      t = (t << 1) | (t >>> 31);\n      _w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    for(; i < 40; ++i) {\n      t = (_w[i - 6] ^ _w[i - 16] ^ _w[i - 28] ^ _w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      _w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x6ED9EBA1 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    // round 3\n    for(; i < 60; ++i) {\n      t = (_w[i - 6] ^ _w[i - 16] ^ _w[i - 28] ^ _w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      _w[i] = t;\n      f = (b & c) | (d & (b ^ c));\n      t = ((a << 5) | (a >>> 27)) + f + e + 0x8F1BBCDC + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n    // round 4\n    for(; i < 80; ++i) {\n      t = (_w[i - 6] ^ _w[i - 16] ^ _w[i - 28] ^ _w[i - 32]);\n      t = (t << 2) | (t >>> 30);\n      _w[i] = t;\n      f = b ^ c ^ d;\n      t = ((a << 5) | (a >>> 27)) + f + e + 0xCA62C1D6 + t;\n      e = d;\n      d = c;\n      c = (b << 30) | (b >>> 2);\n      b = a;\n      a = t;\n    }\n\n    // update hash state\n    s.h0 = (s.h0 + a) | 0;\n    s.h1 = (s.h1 + b) | 0;\n    s.h2 = (s.h2 + c) | 0;\n    s.h3 = (s.h3 + d) | 0;\n    s.h4 = (s.h4 + e) | 0;\n\n    len -= 64;\n  }\n\n  return s;\n};\n\nsha1._createState = function() {\n  var state = {\n    h0: 0x67452301,\n    h1: 0xEFCDAB89,\n    h2: 0x98BADCFE,\n    h3: 0x10325476,\n    h4: 0xC3D2E1F0\n  };\n  state.copy = function() {\n    var rval = sha1._createState();\n    rval.h0 = state.h0;\n    rval.h1 = state.h1;\n    rval.h2 = state.h2;\n    rval.h3 = state.h3;\n    rval.h4 = state.h4;\n    return rval;\n  };\n  state.write = function(buffer) {\n    buffer.putInt32(state.h0);\n    buffer.putInt32(state.h1);\n    buffer.putInt32(state.h2);\n    buffer.putInt32(state.h3);\n    buffer.putInt32(state.h4);\n  };\n  return state;\n};\n\n//////////////////////////// DEFINE SHA-256 ALGORITHM /////////////////////////\n\nvar sha256 = {\n  // shared state\n  _k: null,\n  _w: null\n};\n\nsha256.Algorithm = function() {\n  this.name = 'sha256',\n  this.blockSize = 64;\n  this.digestLength = 32;\n  this.messageLengthSize = 8;\n};\n\nsha256.Algorithm.prototype.start = function() {\n  if(!sha256._k) {\n    sha256._init();\n  }\n  return sha256._createState();\n};\n\nsha256.Algorithm.prototype.writeMessageLength = function(\n  finalBlock, messageLength) {\n  // message length is in bits and in big-endian order; simply append\n  finalBlock.putBytes(messageLength.bytes());\n};\n\nsha256.Algorithm.prototype.digest = function(s, input) {\n  // consume 512 bit (64 byte) chunks\n  var t1, t2, s0, s1, ch, maj, i, a, b, c, d, e, f, g, h;\n  var len = input.length();\n  var _k = sha256._k;\n  var _w = sha256._w;\n  while(len >= 64) {\n    // the w array will be populated with sixteen 32-bit big-endian words\n    // and then extended into 64 32-bit words according to SHA-256\n    for(i = 0; i < 16; ++i) {\n      _w[i] = input.getInt32();\n    }\n    for(; i < 64; ++i) {\n      // XOR word 2 words ago rot right 17, rot right 19, shft right 10\n      t1 = _w[i - 2];\n      t1 =\n        ((t1 >>> 17) | (t1 << 15)) ^\n        ((t1 >>> 19) | (t1 << 13)) ^\n        (t1 >>> 10);\n      // XOR word 15 words ago rot right 7, rot right 18, shft right 3\n      t2 = _w[i - 15];\n      t2 =\n        ((t2 >>> 7) | (t2 << 25)) ^\n        ((t2 >>> 18) | (t2 << 14)) ^\n        (t2 >>> 3);\n      // sum(t1, word 7 ago, t2, word 16 ago) modulo 2^32\n      _w[i] = (t1 + _w[i - 7] + t2 + _w[i - 16]) | 0;\n    }\n\n    // initialize hash value for this chunk\n    a = s.h0;\n    b = s.h1;\n    c = s.h2;\n    d = s.h3;\n    e = s.h4;\n    f = s.h5;\n    g = s.h6;\n    h = s.h7;\n\n    // round function\n    for(i = 0; i < 64; ++i) {\n      // Sum1(e)\n      s1 =\n        ((e >>> 6) | (e << 26)) ^\n        ((e >>> 11) | (e << 21)) ^\n        ((e >>> 25) | (e << 7));\n      // Ch(e, f, g) (optimized the same way as SHA-1)\n      ch = g ^ (e & (f ^ g));\n      // Sum0(a)\n      s0 =\n        ((a >>> 2) | (a << 30)) ^\n        ((a >>> 13) | (a << 19)) ^\n        ((a >>> 22) | (a << 10));\n      // Maj(a, b, c) (optimized the same way as SHA-1)\n      maj = (a & b) | (c & (a ^ b));\n\n      // main algorithm\n      t1 = h + s1 + ch + _k[i] + _w[i];\n      t2 = s0 + maj;\n      h = g;\n      g = f;\n      f = e;\n      e = (d + t1) | 0;\n      d = c;\n      c = b;\n      b = a;\n      a = (t1 + t2) | 0;\n    }\n\n    // update hash state\n    s.h0 = (s.h0 + a) | 0;\n    s.h1 = (s.h1 + b) | 0;\n    s.h2 = (s.h2 + c) | 0;\n    s.h3 = (s.h3 + d) | 0;\n    s.h4 = (s.h4 + e) | 0;\n    s.h5 = (s.h5 + f) | 0;\n    s.h6 = (s.h6 + g) | 0;\n    s.h7 = (s.h7 + h) | 0;\n    len -= 64;\n  }\n\n  return s;\n};\n\nsha256._createState = function() {\n  var state = {\n    h0: 0x6A09E667,\n    h1: 0xBB67AE85,\n    h2: 0x3C6EF372,\n    h3: 0xA54FF53A,\n    h4: 0x510E527F,\n    h5: 0x9B05688C,\n    h6: 0x1F83D9AB,\n    h7: 0x5BE0CD19\n  };\n  state.copy = function() {\n    var rval = sha256._createState();\n    rval.h0 = state.h0;\n    rval.h1 = state.h1;\n    rval.h2 = state.h2;\n    rval.h3 = state.h3;\n    rval.h4 = state.h4;\n    rval.h5 = state.h5;\n    rval.h6 = state.h6;\n    rval.h7 = state.h7;\n    return rval;\n  };\n  state.write = function(buffer) {\n    buffer.putInt32(state.h0);\n    buffer.putInt32(state.h1);\n    buffer.putInt32(state.h2);\n    buffer.putInt32(state.h3);\n    buffer.putInt32(state.h4);\n    buffer.putInt32(state.h5);\n    buffer.putInt32(state.h6);\n    buffer.putInt32(state.h7);\n  };\n  return state;\n};\n\nsha256._init = function() {\n  // create K table for SHA-256\n  sha256._k = [\n    0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,\n    0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,\n    0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,\n    0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,\n    0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,\n    0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,\n    0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,\n    0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,\n    0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,\n    0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,\n    0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,\n    0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,\n    0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,\n    0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,\n    0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,\n    0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2];\n\n  // used for word storage\n  sha256._w = new Array(64);\n};\n\n})(_nodejs); // end definition of NormalizeHash\n\nif(!XMLSerializer) {\n\nvar _defineXMLSerializer = function() {\n  XMLSerializer = require('xmldom').XMLSerializer;\n};\n\n} // end _defineXMLSerializer\n\n// define URL parser\n// parseUri 1.2.2\n// (c) Steven Levithan <stevenlevithan.com>\n// MIT License\n// with local jsonld.js modifications\njsonld.url = {};\njsonld.url.parsers = {\n  simple: {\n    // RFC 3986 basic parts\n    keys: ['href','scheme','authority','path','query','fragment'],\n    regex: /^(?:([^:\\/?#]+):)?(?:\\/\\/([^\\/?#]*))?([^?#]*)(?:\\?([^#]*))?(?:#(.*))?/\n  },\n  full: {\n    keys: ['href','protocol','scheme','authority','auth','user','password','hostname','port','path','directory','file','query','fragment'],\n    regex: /^(([^:\\/?#]+):)?(?:\\/\\/((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\\/?#]*)(?::(\\d*))?))?(?:(((?:[^?#\\/]*\\/)*)([^?#]*))(?:\\?([^#]*))?(?:#(.*))?)/\n  }\n};\njsonld.url.parse = function(str, parser) {\n  var parsed = {};\n  var o = jsonld.url.parsers[parser || 'full'];\n  var m = o.regex.exec(str);\n  var i = o.keys.length;\n  while(i--) {\n    parsed[o.keys[i]] = (m[i] === undefined) ? null : m[i];\n  }\n  parsed.normalizedPath = _removeDotSegments(parsed.path, !!parsed.authority);\n  return parsed;\n};\n\n/**\n * Removes dot segments from a URL path.\n *\n * @param path the path to remove dot segments from.\n * @param hasAuthority true if the URL has an authority, false if not.\n */\nfunction _removeDotSegments(path, hasAuthority) {\n  var rval = '';\n\n  if(path.indexOf('/') === 0) {\n    rval = '/';\n  }\n\n  // RFC 3986 5.2.4 (reworked)\n  var input = path.split('/');\n  var output = [];\n  while(input.length > 0) {\n    if(input[0] === '.' || (input[0] === '' && input.length > 1)) {\n      input.shift();\n      continue;\n    }\n    if(input[0] === '..') {\n      input.shift();\n      if(hasAuthority ||\n        (output.length > 0 && output[output.length - 1] !== '..')) {\n        output.pop();\n      } else {\n        // leading relative URL '..'\n        output.push('..');\n      }\n      continue;\n    }\n    output.push(input.shift());\n  }\n\n  return rval + output.join('/');\n}\n\nif(_nodejs) {\n  // use node document loader by default\n  jsonld.useDocumentLoader('node');\n} else if(typeof XMLHttpRequest !== 'undefined') {\n  // use xhr document loader by default\n  jsonld.useDocumentLoader('xhr');\n}\n\nif(_nodejs) {\n  jsonld.use = function(extension) {\n    switch(extension) {\n      // TODO: Deprecated as of 0.4.0. Remove at some point.\n      case 'request':\n        // use node JSON-LD request extension\n        jsonld.request = require('jsonld-request');\n        break;\n      default:\n        throw new JsonLdError(\n          'Unknown extension.',\n          'jsonld.UnknownExtension', {extension: extension});\n    }\n  };\n\n  // expose version\n  var _module = {exports: {}, filename: __dirname};\n  require('pkginfo')(_module, 'version');\n  jsonld.version = _module.exports.version;\n}\n\n// end of jsonld API factory\nreturn jsonld;\n};\n\n// external APIs:\n\n// used to generate a new jsonld API instance\nvar factory = function() {\n  return wrapper(function() {\n    return factory();\n  });\n};\n\nif(!_nodejs && (typeof define === 'function' && define.amd)) {\n  // export AMD API\n  define([], function() {\n    // now that module is defined, wrap main jsonld API instance\n    wrapper(factory);\n    return factory;\n  });\n} else {\n  // wrap the main jsonld API instance\n  wrapper(factory);\n\n  if(typeof require === 'function' &&\n    typeof module !== 'undefined' && module.exports) {\n    // export CommonJS/nodejs API\n    module.exports = factory;\n  }\n\n  if(_browser) {\n    // export simple browser API\n    if(typeof jsonld === 'undefined') {\n      jsonld = jsonldjs = factory;\n    } else {\n      jsonldjs = factory;\n    }\n  }\n}\n\nreturn factory;\n\n})();\n","/**\n * A JavaScript implementation of the JSON-LD API.\n *\n * @author Dave Longley\n *\n * @license BSD 3-Clause License\n * Copyright (c) 2011-2017 Digital Bazaar, Inc.\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * Redistributions of source code must retain the above copyright notice,\n * this list of conditions and the following disclaimer.\n *\n * Redistributions in binary form must reproduce the above copyright\n * notice, this list of conditions and the following disclaimer in the\n * documentation and/or other materials provided with the distribution.\n *\n * Neither the name of the Digital Bazaar, Inc. nor the names of its\n * contributors may be used to endorse or promote products derived from\n * this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS\n * IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\n * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n(function() {\n\nconst canonize = require('rdf-canonize');\nconst util = require('./util');\nconst IdentifierIssuer = util.IdentifierIssuer;\nconst JsonLdError = require('./JsonLdError');\nconst NQuads = require('./NQuads');\nconst Rdfa = require('./Rdfa');\n\nconst {expand: _expand} = require('./expand');\nconst {flatten: _flatten} = require('./flatten');\nconst {fromRDF: _fromRDF} = require('./fromRdf');\nconst {toRDF: _toRDF} = require('./toRdf');\n\nconst {\n  frameMergedOrDefault: _frameMergedOrDefault\n} = require('./frame');\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString\n} = require('./types');\n\nconst {\n  isSubjectReference: _isSubjectReference,\n} = require('./graphTypes');\n\nconst {\n  getInitialContext: _getInitialContext,\n  process: _processContext,\n  getAllContexts: _getAllContexts,\n  expandIri: _expandIri\n} = require('./context');\n\nconst {\n  compact: _compact,\n  compactIri: _compactIri,\n  removePreserve: _removePreserve\n} = require('./compact');\n\nconst {\n  createNodeMap: _createNodeMap,\n  createMergedNodeMap: _createMergedNodeMap,\n  mergeNodeMaps: _mergeNodeMaps\n} = require('./nodeMap');\n\n// determine if in-browser or using node.js\nconst _nodejs = (\n  typeof process !== 'undefined' && process.versions && process.versions.node);\nconst _browser = !_nodejs &&\n  (typeof window !== 'undefined' || typeof self !== 'undefined');\n\n// attaches jsonld API to the given object\nconst wrapper = function(jsonld) {\n\n/* Core API */\n\n/**\n * Performs JSON-LD compaction.\n *\n * @param input the JSON-LD input to compact.\n * @param ctx the context to compact with.\n * @param [options] options to use:\n *          [base] the base IRI to use.\n *          [compactArrays] true to compact arrays to single values when\n *            appropriate, false not to (default: true).\n *          [compactToRelative] true to compact IRIs to be relative to document base,\n *            false to keep absolute (default: true)\n *          [graph] true to always output a top-level graph (default: false).\n *          [expandContext] a context to expand with.\n *          [skipExpansion] true to assume the input is expanded and skip\n *            expansion, false not to, defaults to false.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n *          [expansionMap(info)] a function that can be used to custom map\n *            unmappable values (or to throw an error when they are detected);\n *            if this function returns `undefined` then the default behavior\n *            will be used.\n *          [framing] true if compaction is occuring during a framing operation.\n *          [compactionMap(info)] a function that can be used to custom map\n *            unmappable values (or to throw an error when they are detected);\n *            if this function returns `undefined` then the default behavior\n *            will be used.\n * @param [callback(err, compacted)] called once the operation completes.\n *\n * @return a Promise that resolves to the compacted output.\n */\njsonld.compact = util.callbackify(async function(input, ctx, options) {\n  if(arguments.length < 2) {\n    throw new TypeError('Could not compact, too few arguments.');\n  }\n\n  if(ctx === null) {\n    throw new JsonLdError(\n      'The compaction context must not be null.',\n      'jsonld.CompactError', {code: 'invalid local context'});\n  }\n\n  // nothing to compact\n  if(input === null) {\n    return null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    compactArrays: true,\n    compactToRelative: true,\n    graph: false,\n    skipExpansion: false,\n    link: false,\n    issuer: new IdentifierIssuer('_:b')\n  });\n  if(options.link) {\n    // force skip expansion when linking, \"link\" is not part of the public\n    // API, it should only be called from framing\n    options.skipExpansion = true;\n  }\n  if(!options.compactToRelative) {\n    delete options.base;\n  }\n\n  // expand input\n  let expanded;\n  if(options.skipExpansion) {\n    expanded = input;\n  } else {\n    expanded = await jsonld.expand(input, options);\n  }\n\n  // process context\n  const activeCtx = await jsonld.processContext(\n    _getInitialContext(options), ctx, options);\n\n  // do compaction\n  let compacted = _compact({\n    activeCtx,\n    element: expanded,\n    options,\n    compactionMap: options.compactionMap\n  });\n\n  // perform clean up\n  if(options.compactArrays && !options.graph && _isArray(compacted)) {\n    if(compacted.length === 1) {\n      // simplify to a single item\n      compacted = compacted[0];\n    } else if(compacted.length === 0) {\n      // simplify to an empty object\n      compacted = {};\n    }\n  } else if(options.graph && _isObject(compacted)) {\n    // always use array if graph option is on\n    compacted = [compacted];\n  }\n\n  // follow @context key\n  if(_isObject(ctx) && '@context' in ctx) {\n    ctx = ctx['@context'];\n  }\n\n  // build output context\n  ctx = util.clone(ctx);\n  if(!_isArray(ctx)) {\n    ctx = [ctx];\n  }\n  // remove empty contexts\n  const tmp = ctx;\n  ctx = [];\n  for(let i = 0; i < tmp.length; ++i) {\n    if(!_isObject(tmp[i]) || Object.keys(tmp[i]).length > 0) {\n      ctx.push(tmp[i]);\n    }\n  }\n\n  // remove array if only one context\n  const hasContext = (ctx.length > 0);\n  if(ctx.length === 1) {\n    ctx = ctx[0];\n  }\n\n  // add context and/or @graph\n  if(_isArray(compacted)) {\n    // use '@graph' keyword\n    const graphAlias = _compactIri({activeCtx, iri: '@graph', relativeTo: {vocab: true}});\n    const graph = compacted;\n    compacted = {};\n    if(hasContext) {\n      compacted['@context'] = ctx;\n    }\n    compacted[graphAlias] = graph;\n  } else if(_isObject(compacted) && hasContext) {\n    // reorder keys so @context is first\n    const graph = compacted;\n    compacted = {'@context': ctx};\n    for(let key in graph) {\n      compacted[key] = graph[key];\n    }\n  }\n\n  if(options.framing) {\n    // get graph alias\n    const graph = _compactIri({activeCtx, iri: '@graph', relativeTo: {vocab: true}});\n    // remove @preserve from results\n    options.link = {};\n    compacted[graph] = _removePreserve(activeCtx, compacted[graph], options);\n  }\n\n  return compacted;\n});\n\n/**\n * Performs JSON-LD expansion.\n *\n * @param input the JSON-LD input to expand.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [keepFreeFloatingNodes] true to keep free-floating nodes,\n *            false not to, defaults to false.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n *          [expansionMap(info)] a function that can be used to custom map\n *            unmappable values (or to throw an error when they are detected);\n *            if this function returns `undefined` then the default behavior\n *            will be used.\n * @param [callback(err, expanded)] called once the operation completes.\n *\n * @return a Promise that resolves to the expanded output.\n */\njsonld.expand = util.callbackify(async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not expand, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    keepFreeFloatingNodes: false\n  });\n  if(options.expansionMap === false) {\n    options.expansionMap = undefined;\n  }\n\n  // build set of objects that may have @contexts to resolve\n  const toResolve = {};\n\n  // build set of contexts to process prior to expansion\n  const contextsToProcess = [];\n\n  // if an `expandContext` has been given ensure it gets resolved\n  if('expandContext' in options) {\n    const expandContext = util.clone(options.expandContext);\n    if(_isObject(expandContext) && '@context' in expandContext) {\n      toResolve.expandContext = expandContext;\n    } else {\n      toResolve.expandContext = {'@context': expandContext};\n    }\n    contextsToProcess.push(toResolve.expandContext);\n  }\n\n  // if input is a string, attempt to dereference remote document\n  let defaultBase;\n  if(!_isString(input)) {\n    // input is not a URL, do not need to retrieve it first\n    toResolve.input = util.clone(input);\n  } else {\n    // load remote doc\n    const remoteDoc = await jsonld.get(input, options);\n    defaultBase = remoteDoc.documentUrl;\n    toResolve.input = remoteDoc.document;\n    if(remoteDoc.contextUrl) {\n      // context included in HTTP link header and must be resolved\n      toResolve.remoteContext = {'@context': remoteDoc.contextUrl};\n      contextsToProcess.push(toResolve.remoteContext);\n    }\n  }\n\n  // set default base\n  if(!('base' in options)) {\n    options.base = defaultBase || '';\n  }\n\n  // get all contexts in `toResolve`\n  await _getAllContexts(toResolve, options);\n\n  // process any additional contexts\n  let activeCtx = _getInitialContext(options);\n  contextsToProcess.forEach(localCtx => {\n    activeCtx = _processContext({activeCtx, localCtx, options});\n  });\n\n  // expand resolved input\n  let expanded = _expand({\n    activeCtx,\n    element: toResolve.input,\n    options,\n    expansionMap: options.expansionMap\n  });\n\n  // optimize away @graph with no other properties\n  if(_isObject(expanded) && ('@graph' in expanded) &&\n    Object.keys(expanded).length === 1) {\n    expanded = expanded['@graph'];\n  } else if(expanded === null) {\n    expanded = [];\n  }\n\n  // normalize to an array\n  if(!_isArray(expanded)) {\n    expanded = [expanded];\n  }\n\n  return expanded;\n});\n\n/**\n * Performs JSON-LD flattening.\n *\n * @param input the JSON-LD to flatten.\n * @param ctx the context to use to compact the flattened output, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param [callback(err, flattened)] called once the operation completes.\n *\n * @return a Promise that resolves to the flattened output.\n */\njsonld.flatten = util.callbackify(async function(input, ctx, options) {\n  if(arguments.length < 1) {\n    return new TypeError('Could not flatten, too few arguments.');\n  }\n\n  if(typeof ctx === 'function') {\n    ctx = null;\n  } else {\n    ctx = ctx || null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : ''\n  });\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  // do flattening\n  const flattened = _flatten(expanded);\n\n  if(ctx === null) {\n    // no compaction required\n    return flattened;\n  }\n\n  // compact result (force @graph option to true, skip expansion)\n  options.graph = true;\n  options.skipExpansion = true;\n  const compacted = await jsonld.compact(flattened, ctx, options);\n\n  return compacted;\n});\n\n/**\n * Performs JSON-LD framing.\n *\n * @param input the JSON-LD input to frame.\n * @param frame the JSON-LD frame to use.\n * @param [options] the framing options.\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [embed] default @embed flag: '@last', '@always', '@never', '@link'\n *            (default: '@last').\n *          [explicit] default @explicit flag (default: false).\n *          [requireAll] default @requireAll flag (default: true).\n *          [omitDefault] default @omitDefault flag (default: false).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param [callback(err, framed)] called once the operation completes.\n *\n * @return a Promise that resolves to the framed output.\n */\njsonld.frame = util.callbackify(async function(input, frame, options) {\n  if(arguments.length < 2) {\n    throw new TypeError('Could not frame, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    embed: '@last',\n    explicit: false,\n    requireAll: true,\n    omitDefault: false,\n    pruneBlankNodeIdentifiers: true,\n    bnodesToClear: []\n  });\n\n  // if frame is a string, attempt to dereference remote document\n  if(_isString(frame)) {\n    // load remote doc\n    const remoteDoc = await jsonld.get(frame, options);\n    frame = remoteDoc.document;\n\n    if(remoteDoc.contextUrl) {\n      // inject link header @context into frame\n      let ctx = frame['@context'];\n      if(!ctx) {\n        ctx = remoteDoc.contextUrl;\n      } else if(_isArray(ctx)) {\n        ctx.push(remoteDoc.contextUrl);\n      } else {\n        ctx = [ctx, remoteDoc.contextUrl];\n      }\n      frame['@context'] = ctx;\n    }\n  }\n\n  let frameContext = frame ? frame['@context'] || {} : {};\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  // expand frame\n  const opts = util.clone(options);\n  opts.isFrame = true;\n  opts.keepFreeFloatingNodes = true;\n  const expandedFrame = await jsonld.expand(frame, opts);\n\n  // if the unexpanded frame includes a key expanding to @graph, frame the default graph, otherwise, the merged graph\n  let framed;\n  // FIXME should look for aliases of @graph\n  opts.merged = !('@graph' in frame);\n  // do framing\n  framed = _frameMergedOrDefault(expanded, expandedFrame, opts);\n\n  // compact result (force @graph option to true, skip expansion,\n  // check for linked embeds)\n  opts.graph = true;\n  opts.skipExpansion = true;\n  opts.link = {};\n  opts.framing = true;\n  const compacted = await jsonld.compact(framed, frameContext, opts);\n\n  return compacted;\n});\n\n/**\n * **Experimental**\n *\n * Links a JSON-LD document's nodes in memory.\n *\n * @param input the JSON-LD document to link.\n * @param [ctx] the JSON-LD context to apply.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param [callback(err, linked)] called once the operation completes.\n *\n * @return a Promise that resolves to the linked output.\n */\njsonld.link = util.callbackify(async function(input, ctx, options) {\n  // API matches running frame with a wildcard frame and embed: '@link'\n  // get arguments\n  const frame = {};\n  if(ctx) {\n    frame['@context'] = ctx;\n  }\n  frame['@embed'] = '@link';\n  return jsonld.frame(input, frame, options);\n});\n\n/**\n * Performs RDF dataset normalization on the given input. The input is JSON-LD\n * unless the 'inputFormat' option is used. The output is an RDF dataset\n * unless the 'format' option is used.\n *\n * @param input the input to normalize as JSON-LD or as a format specified by\n *          the 'inputFormat' option.\n * @param [options] the options to use:\n *          [algorithm] the normalization algorithm to use, `URDNA2015` or\n *            `URGNA2012` (default: `URGNA2012`).\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [inputFormat] the format if input is not JSON-LD:\n *            'application/n-quads' for N-Quads.\n *          [format] the format if output is a string:\n *            'application/n-quads' for N-Quads.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param [callback(err, normalized)] called once the operation completes.\n *\n * @return a Promise that resolves to the normalized output.\n */\njsonld.normalize = jsonld.canonize = util.callbackify(async function(\n  input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not canonize, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : '',\n    algorithm: 'URDNA2015'\n  });\n  if('inputFormat' in options) {\n    if(options.inputFormat !== 'application/n-quads' &&\n      options.inputFormat !== 'application/nquads') {\n      throw new JsonLdError(\n        'Unknown canonicalization input format.',\n        'jsonld.CanonizeError');\n    }\n    // TODO: `await` for async parsers\n    const parsedInput = NQuads.parse(input);\n\n    // do canonicalization\n    return canonize.canonize(parsedInput, options);\n  }\n\n  // convert to RDF dataset then do normalization\n  const opts = util.clone(options);\n  delete opts.format;\n  opts.produceGeneralizedRdf = false;\n  const dataset = await jsonld.toRDF(input, opts);\n\n  // do canonicalization\n  return canonize.canonize(dataset, options);\n});\n\n/**\n * Converts an RDF dataset to JSON-LD.\n *\n * @param dataset a serialized string of RDF in a format specified by the\n *          format option or an RDF dataset to convert.\n * @param [options] the options to use:\n *          [format] the format if dataset param must first be parsed:\n *            'application/n-quads' for N-Quads (default).\n *          [rdfParser] a custom RDF-parser to use to parse the dataset.\n *          [useRdfType] true to use rdf:type, false to use @type\n *            (default: false).\n *          [useNativeTypes] true to convert XSD types into native types\n *            (boolean, integer, double), false not to (default: false).\n * @param [callback(err, output)] called once the operation completes.\n *\n * @return a Promise that resolves to the JSON-LD document.\n */\njsonld.fromRDF = util.callbackify(async function(dataset, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not convert from RDF, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    format: _isString(dataset) ? 'application/n-quads' : undefined\n  });\n\n  let {format, rdfParser} = options;\n\n  // handle special format\n  if(format) {\n    // check supported formats\n    rdfParser = rdfParser || _rdfParsers[format];\n    if(!rdfParser) {\n      throw new JsonLdError(\n        'Unknown input format.',\n        'jsonld.UnknownFormat', {format});\n    }\n  } else {\n    // no-op parser, assume dataset already parsed\n    rdfParser = () => dataset;\n  }\n\n  // TODO: call `normalizeAsyncFn` on parser fn\n\n  // rdfParser can be callback, promise-based, or synchronous\n  let parsedDataset;\n  if(rdfParser.length > 1) {\n    // convert callback-based rdf parser to promise-based\n    parsedDataset = new Promise((resolve, reject) => {\n      rdfParser(dataset, (err, dataset) => {\n        if(err) {\n          reject(err);\n        } else {\n          resolve(dataset);\n        }\n      });\n    });\n  } else {\n    parsedDataset = Promise.resolve(rdfParser(dataset));\n  }\n\n  parsedDataset = await parsedDataset;\n\n  // back-compat with old parsers that produced legacy dataset format\n  if(!Array.isArray(parsedDataset)) {\n    parsedDataset = NQuads.legacyDatasetToQuads(parsedDataset);\n  }\n\n  return _fromRDF(parsedDataset, options);\n});\n\n/**\n * Outputs the RDF dataset found in the given JSON-LD object.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [format] the format to use to output a string:\n *            'application/n-quads' for N-Quads.\n *          [produceGeneralizedRdf] true to output generalized RDF, false\n *            to produce only standard RDF (default: false).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param [callback(err, dataset)] called once the operation completes.\n *\n * @return a Promise that resolves to the RDF dataset.\n */\njsonld.toRDF = util.callbackify(async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not convert to RDF, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : ''\n  });\n\n  // TODO: support toRDF custom map?\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  // output RDF dataset\n  const dataset = _toRDF(expanded, options);\n  if(options.format) {\n    if(options.format === 'application/n-quads' ||\n      options.format === 'application/nquads') {\n      return await NQuads.serialize(dataset);\n    }\n    throw new JsonLdError(\n      'Unknown output format.',\n      'jsonld.UnknownFormat', {format: options.format});\n  }\n\n  return dataset;\n});\n\n/**\n * **Experimental**\n *\n * Recursively flattens the nodes in the given JSON-LD input into a merged\n * map of node ID => node. All graphs will be merged into the default graph.\n *\n * @param input the JSON-LD input.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param [callback(err, nodeMap)] called once the operation completes.\n *\n * @return a Promise that resolves to the merged node map.\n */\njsonld.createNodeMap = util.callbackify(async function(input, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not create node map, too few arguments.');\n  }\n\n  // set default options\n  options = _setDefaults(options, {\n    base: _isString(input) ? input : ''\n  });\n\n  // expand input\n  const expanded = await jsonld.expand(input, options);\n\n  return _createMergedNodeMap(expanded, options);\n});\n\n/**\n * **Experimental**\n *\n * Merges two or more JSON-LD documents into a single flattened document.\n *\n * @param docs the JSON-LD documents to merge together.\n * @param ctx the context to use to compact the merged result, or null.\n * @param [options] the options to use:\n *          [base] the base IRI to use.\n *          [expandContext] a context to expand with.\n *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.\n *          [mergeNodes] true to merge properties for nodes with the same ID,\n *            false to ignore new properties for nodes with the same ID once\n *            the ID has been defined; note that this may not prevent merging\n *            new properties where a node is in the `object` position\n *            (default: true).\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param [callback(err, merged)] called once the operation completes.\n *\n * @return a Promise that resolves to the merged output.\n */\njsonld.merge = util.callbackify(async function(docs, ctx, options) {\n  if(arguments.length < 1) {\n    throw new TypeError('Could not merge, too few arguments.');\n  }\n  if(!_isArray(docs)) {\n    throw new TypeError('Could not merge, \"docs\" must be an array.');\n  }\n\n  if(typeof ctx === 'function') {\n    ctx = null;\n  } else {\n    ctx = ctx || null;\n  }\n\n  // set default options\n  options = _setDefaults(options, {});\n\n  // expand all documents\n  const expanded = await Promise.all(docs.map(doc => {\n    const opts = Object.assign({}, options);\n    return jsonld.expand(doc, opts);\n  }));\n\n  let mergeNodes = true;\n  if('mergeNodes' in options) {\n    mergeNodes = options.mergeNodes;\n  }\n\n  const issuer = options.issuer || new IdentifierIssuer('_:b');\n  const graphs = {'@default': {}};\n\n  for(let i = 0; i < expanded.length; ++i) {\n    // uniquely relabel blank nodes\n    const doc = util.relabelBlankNodes(expanded[i], {\n      issuer: new IdentifierIssuer('_:b' + i + '-')\n    });\n\n    // add nodes to the shared node map graphs if merging nodes, to a\n    // separate graph set if not\n    const _graphs = (mergeNodes || i === 0) ? graphs : {'@default': {}};\n    _createNodeMap(doc, _graphs, '@default', issuer);\n\n    if(_graphs !== graphs) {\n      // merge document graphs but don't merge existing nodes\n      for(let graphName in _graphs) {\n        const _nodeMap = _graphs[graphName];\n        if(!(graphName in graphs)) {\n          graphs[graphName] = _nodeMap;\n          continue;\n        }\n        const nodeMap = graphs[graphName];\n        for(let key in _nodeMap) {\n          if(!(key in nodeMap)) {\n            nodeMap[key] = _nodeMap[key];\n          }\n        }\n      }\n    }\n  }\n\n  // add all non-default graphs to default graph\n  const defaultGraph = _mergeNodeMaps(graphs);\n\n  // produce flattened output\n  const flattened = [];\n  const keys = Object.keys(defaultGraph).sort();\n  for(let ki = 0; ki < keys.length; ++ki) {\n    const node = defaultGraph[keys[ki]];\n    // only add full subjects to top-level\n    if(!_isSubjectReference(node)) {\n      flattened.push(node);\n    }\n  }\n\n  if(ctx === null) {\n    return flattened;\n  }\n\n  // compact result (force @graph option to true, skip expansion)\n  options.graph = true;\n  options.skipExpansion = true;\n  const compacted = await jsonld.compact(flattened, ctx, options);\n\n  return compacted;\n});\n\n/**\n * The default document loader for external documents. If the environment\n * is node.js, a callback-continuation-style document loader is used; otherwise,\n * a promises-style document loader is used.\n *\n * @param url the URL to load.\n * @param callback(err, remoteDoc) called once the operation completes,\n *          if using a non-promises API.\n *\n * @return a promise, if using a promises API.\n */\nObject.defineProperty(jsonld, 'documentLoader', {\n  get: () => jsonld._documentLoader,\n  set: v => jsonld._documentLoader = util.normalizeDocumentLoader(v)\n});\n// default document loader not implemented\njsonld.documentLoader = async url => {\n  throw new JsonLdError(\n    'Could not retrieve a JSON-LD document from the URL. URL ' +\n    'dereferencing not implemented.', 'jsonld.LoadDocumentError',\n    {code: 'loading document failed', url: url});\n};\n\n/**\n * Deprecated default document loader. Do not use or override.\n */\njsonld.loadDocument = util.callbackify(async function() {\n  return jsonld.documentLoader.apply(null, arguments);\n});\n\n/**\n * Gets a remote JSON-LD document using the default document loader or\n * one given in the passed options.\n *\n * @param url the URL to fetch.\n * @param [options] the options to use:\n *          [documentLoader] the document loader to use.\n * @param [callback(err, remoteDoc)] called once the operation completes.\n *\n * @return a Promise that resolves to the retrieved remote document.\n */\njsonld.get = util.callbackify(async function(url, options) {\n  let load;\n  if(typeof options.documentLoader === 'function') {\n    load = util.normalizeDocumentLoader(options.documentLoader);\n  } else {\n    load = jsonld.documentLoader;\n  }\n\n  const remoteDoc = await load(url);\n\n  // TODO: can this be moved into `normalizeDocumentLoader`?\n  try {\n    if(!remoteDoc.document) {\n      throw new JsonLdError(\n        'No remote document found at the given URL.',\n        'jsonld.NullRemoteDocument');\n    }\n    if(_isString(remoteDoc.document)) {\n      remoteDoc.document = JSON.parse(remoteDoc.document);\n    }\n  } catch(e) {\n    throw new JsonLdError(\n      'Could not retrieve a JSON-LD document from the URL.',\n      'jsonld.LoadDocumentError', {\n        code: 'loading document failed',\n        cause: e,\n        remoteDoc: remoteDoc\n      });\n  }\n\n  return remoteDoc;\n});\n\n/**\n * Processes a local context, resolving any URLs as necessary, and returns a\n * new active context in its callback.\n *\n * @param activeCtx the current active context.\n * @param localCtx the local context to process.\n * @param [options] the options to use:\n *          [documentLoader(url, callback(err, remoteDoc))] the document loader.\n * @param [callback(err, activeCtx)] called once the operation completes.\n *\n * @return a Promise that resolves to the new active context.\n */\njsonld.processContext = util.callbackify(async function(\n  activeCtx, localCtx, options) {\n  // set default options\n  options = _setDefaults(options, {\n    base: ''\n  });\n\n  // return initial context early for null context\n  if(localCtx === null) {\n    return _getInitialContext(options);\n  }\n\n  // get URLs in localCtx\n  localCtx = util.clone(localCtx);\n  if(!(_isObject(localCtx) && '@context' in localCtx)) {\n    localCtx = {'@context': localCtx};\n  }\n  let ctx = await _getAllContexts(localCtx, options);\n\n  return _processContext({activeCtx, localCtx: ctx, options});\n});\n\n// backwards compatibility\njsonld.getContextValue = require('./context').getContextValue;\n\n/**\n * Document loaders.\n */\njsonld.documentLoaders = {};\njsonld.documentLoaders.node = require('./documentLoaders/node');\njsonld.documentLoaders.xhr = require('./documentLoaders/xhr');\n\n/**\n * Assigns the default document loader for external document URLs to a built-in\n * default. Supported types currently include: 'xhr' and 'node'.\n *\n * @param type the type to set.\n * @param [params] the parameters required to use the document loader.\n */\njsonld.useDocumentLoader = function(type) {\n  if(!(type in jsonld.documentLoaders)) {\n    throw new JsonLdError(\n      'Unknown document loader type: \"' + type + '\"',\n      'jsonld.UnknownDocumentLoader',\n      {type: type});\n  }\n\n  // set document loader\n  jsonld.documentLoader = jsonld.documentLoaders[type].apply(\n    jsonld, Array.prototype.slice.call(arguments, 1));\n};\n\n/** Registered RDF dataset parsers hashed by content-type. */\nconst _rdfParsers = {};\n\n/**\n * Registers an RDF dataset parser by content-type, for use with\n * jsonld.fromRDF. An RDF dataset parser will always be given two parameters,\n * a string of input and a callback. An RDF dataset parser can be synchronous\n * or asynchronous.\n *\n * If the parser function returns undefined or null then it will be assumed to\n * be asynchronous w/a continuation-passing style and the callback parameter\n * given to the parser MUST be invoked.\n *\n * If it returns a Promise, then it will be assumed to be asynchronous, but the\n * callback parameter MUST NOT be invoked. It should instead be ignored.\n *\n * If it returns an RDF dataset, it will be assumed to be synchronous and the\n * callback parameter MUST NOT be invoked. It should instead be ignored.\n *\n * @param contentType the content-type for the parser.\n * @param parser(input, callback(err, dataset)) the parser function (takes a\n *          string as a parameter and either returns null/undefined and uses\n *          the given callback, returns a Promise, or returns an RDF dataset).\n */\njsonld.registerRDFParser = function(contentType, parser) {\n  _rdfParsers[contentType] = parser;\n};\n\n/**\n * Unregisters an RDF dataset parser by content-type.\n *\n * @param contentType the content-type for the parser.\n */\njsonld.unregisterRDFParser = function(contentType) {\n  delete _rdfParsers[contentType];\n};\n\n// register the N-Quads RDF parser\njsonld.registerRDFParser('application/n-quads', NQuads.parse);\njsonld.registerRDFParser('application/nquads', NQuads.parse);\n\n// register the RDFa API RDF parser\njsonld.registerRDFParser('rdfa-api', Rdfa.parse);\n\n/* URL API */\njsonld.url = require('./url');\n\n/* Utility API */\njsonld.util = util;\n// backwards compatibility\nObject.assign(jsonld, util);\n\n// reexpose API as jsonld.promises for backwards compatability\njsonld.promises = jsonld;\n\n// backwards compatibility\njsonld.RequestQueue = require('./RequestQueue');\n\n/* WebIDL API */\njsonld.JsonLdProcessor = require('./JsonLdProcessor')(jsonld);\n\n// setup browser global JsonLdProcessor\nif(_browser && typeof global.JsonLdProcessor === 'undefined') {\n  Object.defineProperty(global, 'JsonLdProcessor', {\n    writable: true,\n    enumerable: false,\n    configurable: true,\n    value: jsonld.JsonLdProcessor\n  });\n}\n\n// set platform-specific defaults/APIs\nif(_nodejs) {\n  // use node document loader by default\n  jsonld.useDocumentLoader('node');\n} else if(typeof XMLHttpRequest !== 'undefined') {\n  // use xhr document loader by default\n  jsonld.useDocumentLoader('xhr');\n}\n\nfunction _setDefaults(options, {\n  documentLoader = jsonld.documentLoader,\n  ...defaults\n}) {\n  if(typeof options === 'function') {\n    options = {};\n  }\n  options = options || {};\n  return Object.assign({}, {documentLoader}, defaults, options);\n}\n\n// end of jsonld API `wrapper` factory\nreturn jsonld;\n};\n\n// external APIs:\n\n// used to generate a new jsonld API instance\nconst factory = function() {\n  return wrapper(function() {\n    return factory();\n  });\n};\n\nif(!_nodejs && (typeof define === 'function' && define.amd)) {\n  // export AMD API\n  define([], function() {\n    // now that module is defined, wrap main jsonld API instance\n    wrapper(factory);\n    return factory;\n  });\n} else {\n  // wrap the main jsonld API instance\n  wrapper(factory);\n\n  if(typeof require === 'function' &&\n    typeof module !== 'undefined' && module.exports) {\n    // export CommonJS/nodejs API\n    module.exports = factory;\n  }\n\n  if(_browser) {\n    // export simple browser API\n    if(typeof jsonld === 'undefined') {\n      jsonld = jsonldjs = factory;\n    } else {\n      jsonldjs = factory;\n    }\n  }\n}\n\nreturn factory;\n\n})();\n","/*\n * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.\n */\n'use strict';\n\nconst JsonLdError = require('./JsonLdError');\n\nconst {\n  isArray: _isArray,\n  isObject: _isObject,\n  isString: _isString\n} = require('./types');\n\nconst {\n  isList: _isList,\n  isValue: _isValue,\n  isGraph: _isGraph,\n  isSimpleGraph: _isSimpleGraph,\n  isSubjectReference: _isSubjectReference\n} = require('./graphTypes');\n\nconst {\n  expandIri: _expandIri,\n  getContextValue: _getContextValue,\n  isKeyword: _isKeyword,\n  process: _processContext\n} = require('./context');\n\nconst {\n  removeBase: _removeBase\n} = require('./url');\n\nconst {\n  addValue: _addValue,\n  compareShortestLeast: _compareShortestLeast\n} = require('./util');\n\nconst api = {};\nmodule.exports = api;\n\n/**\n * Recursively compacts an element using the given active context. All values\n * must be in expanded form before this method is called.\n *\n * @param activeCtx the active context to use.\n * @param activeProperty the compacted property associated with the element\n *          to compact, null for none.\n * @param element the element to compact.\n * @param options the compaction options.\n * @param compactionMap the compaction map to use.\n *\n * @return the compacted value.\n */\napi.compact = ({\n  activeCtx,\n  activeProperty = null,\n  element,\n  options = {},\n  compactionMap = () => undefined\n}) => {\n  // recursively compact array\n  if(_isArray(element)) {\n    let rval = [];\n    for(let i = 0; i < element.length; ++i) {\n      // compact, dropping any null values unless custom mapped\n      let compacted = api.compact({\n        activeCtx,\n        activeProperty,\n        element: element[i],\n        options,\n        compactionMap\n      });\n      if(compacted === null) {\n        // TODO: use `await` to support async\n        compacted = compactionMap({\n          unmappedValue: element[i],\n          activeCtx,\n          activeProperty,\n          parent: element,\n          index: i,\n          options\n        });\n        if(compacted === undefined) {\n          continue;\n        }\n      }\n      rval.push(compacted);\n    }\n    if(options.compactArrays && rval.length === 1) {\n      // use single element if no container is specified\n      const container = _getContextValue(\n        activeCtx, activeProperty, '@container') || [];\n      if(container.length === 0) {\n        rval = rval[0];\n      }\n    }\n    return rval;\n  }\n\n  // use any scoped context on activeProperty\n  const ctx = _getContextValue(activeCtx, activeProperty, '@context');\n  if(ctx) {\n    activeCtx = _processContext({activeCtx, localCtx: ctx, options});\n  }\n\n  // recursively compact object\n  if(_isObject(element)) {\n    if(options.link && '@id' in element && element['@id'] in options.link) {\n      // check for a linked element to reuse\n      const linked = options.link[element['@id']];\n      for(let i = 0; i < linked.length; ++i) {\n        if(linked[i].expanded === element) {\n          return linked[i].compacted;\n        }\n      }\n    }\n\n    // do value compaction on @values and subject references\n    if(_isValue(element) || _isSubjectReference(element)) {\n      const rval =\n        api.compactValue({activeCtx, activeProperty, value: element});\n      if(options.link && _isSubjectReference(element)) {\n        // store linked element\n        if(!(element['@id'] in options.link)) {\n          options.link[element['@id']] = [];\n        }\n        options.link[element['@id']].push({expanded: element, compacted: rval});\n      }\n      return rval;\n    }\n\n    // FIXME: avoid misuse of active property as an expanded property?\n    const insideReverse = (activeProperty === '@reverse');\n\n    const rval = {};\n\n    if(options.link && '@id' in element) {\n      // store linked element\n      if(!(element['@id'] in options.link)) {\n        options.link[element['@id']] = [];\n      }\n      options.link[element['@id']].push({expanded: element, compacted: rval});\n    }\n\n    // apply any context defined on an alias of @type\n    // if key is @type and any compacted value is a term having a local\n    // context, overlay that context\n    const types = element['@type'] || [];\n    for(const type of types) {\n      const compactedType = api.compactIri(\n        {activeCtx, iri: type, relativeTo: {vocab: true}});\n\n      // Use any scoped context defined on this value\n      const ctx = _getContextValue(activeCtx, compactedType, '@context');\n      if(ctx) {\n        activeCtx = _processContext({activeCtx, localCtx: ctx, options});\n      }\n    }\n\n    // process element keys in order\n    const keys = Object.keys(element).sort();\n    for(const expandedProperty of keys) {\n      const expandedValue = element[expandedProperty];\n\n      // compact @id and @type(s)\n      if(expandedProperty === '@id' || expandedProperty === '@type') {\n        let compactedValue = [].concat(expandedValue).map(\n          expandedIri => api.compactIri({\n            activeCtx,\n            iri: expandedIri,\n            relativeTo: {\n              vocab: expandedProperty === '@type'\n            }\n          }));\n        if(compactedValue.length === 1) {\n          compactedValue = compactedValue[0];\n        }\n\n        // use keyword alias and add value\n        const alias = api.compactIri(\n          {activeCtx, iri: expandedProperty, relativeTo: {vocab: true}});\n        const isArray = _isArray(compactedValue) && expandedValue.length === 0;\n        _addValue(rval, alias, compactedValue, {propertyIsArray: isArray});\n        continue;\n      }\n\n      // handle @reverse\n      if(expandedProperty === '@reverse') {\n        // recursively compact expanded value\n        const compactedValue = api.compact({\n          activeCtx,\n          activeProperty: '@reverse',\n          element: expandedValue,\n          options,\n          compactionMap\n        });\n\n        // handle double-reversed properties\n        for(const compactedProperty in compactedValue) {\n          if(activeCtx.mappings[compactedProperty] &&\n            activeCtx.mappings[compactedProperty].reverse) {\n            const value = compactedValue[compactedProperty];\n            const container = _getContextValue(\n              activeCtx, compactedProperty, '@container') || [];\n            const useArray = (\n              container.includes('@set') || !options.compactArrays);\n            _addValue(\n              rval, compactedProperty, value, {propertyIsArray: useArray});\n            delete compactedValue[compactedProperty];\n          }\n        }\n\n        if(Object.keys(compactedValue).length > 0) {\n          // use keyword alias and add value\n          const alias = api.compactIri({\n            activeCtx,\n            iri: expandedProperty,\n            relativeTo: {vocab: true}\n          });\n          _addValue(rval, alias, compactedValue);\n        }\n\n        continue;\n      }\n\n      if(expandedProperty === '@preserve') {\n        // compact using activeProperty\n        const compactedValue = api.compact({\n          activeCtx,\n          activeProperty,\n          element: expandedValue,\n          options,\n          compactionMap});\n\n        if(!(_isArray(compactedValue) && compactedValue.length === 0)) {\n          _addValue(rval, expandedProperty, compactedValue);\n        }\n        continue;\n      }\n\n      // handle @index property\n      if(expandedProperty === '@index') {\n        // drop @index if inside an @index container\n        const container = _getContextValue(\n          activeCtx, activeProperty, '@container') || [];\n        if(container.includes('@index')) {\n          continue;\n        }\n\n        // use keyword alias and add value\n        const alias = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          relativeTo: {vocab: true}\n        });\n        _addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // skip array processing for keywords that aren't @graph or @list\n      if(expandedProperty !== '@graph' && expandedProperty !== '@list' &&\n        _isKeyword(expandedProperty)) {\n        // use keyword alias and add value as is\n        const alias = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          relativeTo: {vocab: true}\n        });\n        _addValue(rval, alias, expandedValue);\n        continue;\n      }\n\n      // Note: expanded value must be an array due to expansion algorithm.\n      if(!_isArray(expandedValue)) {\n        throw new JsonLdError(\n          'JSON-LD expansion error; expanded value must be an array.',\n          'jsonld.SyntaxError');\n      }\n\n      // preserve empty arrays\n      if(expandedValue.length === 0) {\n        const itemActiveProperty = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          value: expandedValue,\n          relativeTo: {vocab: true},\n          reverse: insideReverse\n        });\n        const nestProperty = (itemActiveProperty in activeCtx.mappings) ?\n          activeCtx.mappings[itemActiveProperty]['@nest'] : null;\n        let nestResult = rval;\n        if(nestProperty) {\n          _checkNestProperty(activeCtx, nestProperty);\n          if(!_isObject(rval[nestProperty])) {\n            rval[nestProperty] = {};\n          }\n          nestResult = rval[nestProperty];\n        }\n        _addValue(\n          nestResult, itemActiveProperty, expandedValue, {\n            propertyIsArray: true\n          });\n      }\n\n      // recusively process array values\n      for(const expandedItem of expandedValue) {\n        // compact property and get container type\n        const itemActiveProperty = api.compactIri({\n          activeCtx,\n          iri: expandedProperty,\n          value: expandedItem,\n          relativeTo: {vocab: true},\n          reverse: insideReverse\n        });\n\n        // if itemActiveProperty is a @nest property, add values to nestResult,\n        // otherwise rval\n        const nestProperty = (itemActiveProperty in activeCtx.mappings) ?\n          activeCtx.mappings[itemActiveProperty]['@nest'] : null;\n        let nestResult = rval;\n        if(nestProperty) {\n          _checkNestProperty(activeCtx, nestProperty);\n          if(!_isObject(rval[nestProperty])) {\n            rval[nestProperty] = {};\n          }\n          nestResult = rval[nestProperty];\n        }\n\n        const container = _getContextValue(\n          activeCtx, itemActiveProperty, '@container') || [];\n\n        // get simple @graph or @list value if appropriate\n        const isGraph = _isGraph(expandedItem);\n        const isList = _isList(expandedItem);\n        let inner;\n        if(isList) {\n          inner = expandedItem['@list'];\n        } else if(isGraph) {\n          inner = expandedItem['@graph'];\n        }\n\n        // recursively compact expanded item\n        let compactedItem = api.compact({\n          activeCtx,\n          activeProperty: itemActiveProperty,\n          element: (isList || isGraph) ? inner : expandedItem,\n          options,\n          compactionMap\n        });\n\n        // handle @list\n        if(isList) {\n          // ensure @list value is an array\n          if(!_isArray(compactedItem)) {\n            compactedItem = [compactedItem];\n          }\n\n          if(!container.includes('@list')) {\n            // wrap using @list alias\n            compactedItem = {\n              [api.compactIri({\n                activeCtx,\n                iri: '@list',\n                relativeTo: {vocab: true}\n              })]: compactedItem\n            };\n\n            // include @index from expanded @list, if any\n            if('@index' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@index',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@index'];\n            }\n          } else if(itemActiveProperty in nestResult) {\n            // can't use @list container for more than 1 list\n            throw new JsonLdError(\n              'JSON-LD compact error; property has a \"@list\" @container ' +\n              'rule but there is more than a single @list that matches ' +\n              'the compacted term in the document. Compaction might mix ' +\n              'unwanted items into the list.',\n              'jsonld.SyntaxError', {code: 'compaction to list of lists'});\n          }\n        }\n\n        // Graph object compaction cases\n        if(isGraph) {\n          if(container.includes('@graph') && (container.includes('@id') ||\n            container.includes('@index') && _isSimpleGraph(expandedItem))) {\n            // get or create the map object\n            let mapObject;\n            if(itemActiveProperty in nestResult) {\n              mapObject = nestResult[itemActiveProperty];\n            } else {\n              nestResult[itemActiveProperty] = mapObject = {};\n            }\n\n            // index on @id or @index or alias of @none\n            const key = (container.includes('@id') ?\n              expandedItem['@id'] : expandedItem['@index']) ||\n              api.compactIri({activeCtx, iri: '@none', vocab: true});\n            // add compactedItem to map, using value of `@id` or a new blank\n            // node identifier\n\n            _addValue(\n              mapObject, key, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          } else if(container.includes('@graph') &&\n            _isSimpleGraph(expandedItem)) {\n            // container includes @graph but not @id or @index and value is a\n            // simple graph object add compact value\n            _addValue(\n              nestResult, itemActiveProperty, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          } else {\n            // wrap using @graph alias, remove array if only one item and\n            // compactArrays not set\n            if(_isArray(compactedItem) && compactedItem.length === 1 &&\n              options.compactArrays) {\n              compactedItem = compactedItem[0];\n            }\n            compactedItem = {\n              [api.compactIri({\n                activeCtx,\n                iri: '@graph',\n                relativeTo: {vocab: true}\n              })]: compactedItem\n            };\n\n            // include @id from expanded graph, if any\n            if('@id' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@id',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@id'];\n            }\n\n            // include @index from expanded graph, if any\n            if('@index' in expandedItem) {\n              compactedItem[api.compactIri({\n                activeCtx,\n                iri: '@index',\n                relativeTo: {vocab: true}\n              })] = expandedItem['@index'];\n            }\n            _addValue(\n              nestResult, itemActiveProperty, compactedItem, {\n                propertyIsArray:\n                  (!options.compactArrays || container.includes('@set'))\n              });\n          }\n        } else if(container.includes('@language') ||\n          container.includes('@index') || container.includes('@id') ||\n          container.includes('@type')) {\n          // handle language and index maps\n          // get or create the map object\n          let mapObject;\n          if(itemActiveProperty in nestResult) {\n            mapObject = nestResult[itemActiveProperty];\n          } else {\n            nestResult[itemActiveProperty] = mapObject = {};\n          }\n\n          let key;\n          if(container.includes('@language')) {\n          // if container is a language map, simplify compacted value to\n          // a simple string\n            if(_isValue(compactedItem)) {\n              compactedItem = compactedItem['@value'];\n            }\n            key = expandedItem['@language'];\n          } else if(container.includes('@index')) {\n            key = expandedItem['@index'];\n          } else if(container.includes('@id')) {\n            const idKey = api.compactIri({activeCtx, iri: '@id', vocab: true});\n            key = compactedItem[idKey];\n            delete compactedItem[idKey];\n          } else if(container.includes('@type')) {\n            const typeKey = api.compactIri({\n              activeCtx,\n              iri: '@type',\n              vocab: true\n            });\n            let types;\n            [key, ...types] = [].concat(compactedItem[typeKey] || []);\n            switch(types.length) {\n            case 0:\n              delete compactedItem[typeKey];\n              break;\n            case 1:\n              compactedItem[typeKey] = types[0];\n              break;\n            default:\n              compactedItem[typeKey] = types;\n              break;\n            }\n          }\n\n          // if compacting this value which has no key, index on @none\n          if(!key) {\n            key = api.compactIri({activeCtx, iri: '@none', vocab: true});\n          }\n          // add compact value to map object using key from expanded value\n          // based on the container type\n          _addValue(\n            mapObject, key, compactedItem, {\n              propertyIsArray: container.includes('@set')\n            });\n        } else {\n          // use an array if: compactArrays flag is false,\n          // @container is @set or @list , value is an empty\n          // array, or key is @graph\n          const isArray = (!options.compactArrays ||\n            container.includes('@set') || container.includes('@list') ||\n            (_isArray(compactedItem) && compactedItem.length === 0) ||\n            expandedProperty === '@list' || expandedProperty === '@graph');\n\n          // add compact value\n          _addValue(\n            nestResult, itemActiveProperty, compactedItem,\n            {propertyIsArray: isArray});\n        }\n      }\n    }\n\n    return rval;\n  }\n\n  // only primitives remain which are already compact\n  return element;\n};\n\n/**\n * Compacts an IRI or keyword into a term or prefix if it can be. If the\n * IRI has an associated value it may be passed.\n *\n * @param activeCtx the active context to use.\n * @param iri the IRI to compact.\n * @param value the value to check or null.\n * @param relativeTo options for how to compact IRIs:\n *          vocab: true to split after @vocab, false not to.\n * @param reverse true if a reverse property is being compacted, false if not.\n *\n * @return the compacted term, prefix, keyword alias, or the original IRI.\n */\napi.compactIri = ({\n  activeCtx,\n  iri,\n  value = null,\n  relativeTo = {vocab: false},\n  reverse = false\n}) => {\n  // can't compact null\n  if(iri === null) {\n    return iri;\n  }\n\n  const inverseCtx = activeCtx.getInverse();\n\n  // if term is a keyword, it may be compacted to a simple alias\n  if(_isKeyword(iri) &&\n    iri in inverseCtx &&\n    '@none' in inverseCtx[iri] &&\n    '@type' in inverseCtx[iri]['@none'] &&\n    '@none' in inverseCtx[iri]['@none']['@type']) {\n    return inverseCtx[iri]['@none']['@type']['@none'];\n  }\n\n  // use inverse context to pick a term if iri is relative to vocab\n  if(relativeTo.vocab && iri in inverseCtx) {\n    const defaultLanguage = activeCtx['@language'] || '@none';\n\n    // prefer @index if available in value\n    const containers = [];\n    if(_isObject(value) && '@index' in value && !('@graph' in value)) {\n      containers.push('@index', '@index@set');\n    }\n\n    // if value is a preserve object, use its value\n    if(_isObject(value) && '@preserve' in value) {\n      value = value['@preserve'][0];\n    }\n\n    // prefer most specific container including @graph, prefering @set\n    // variations\n    if(_isGraph(value)) {\n      // favor indexmap if the graph is indexed\n      if('@index' in value) {\n        containers.push(\n          '@graph@index', '@graph@index@set', '@index', '@index@set');\n      }\n      // favor idmap if the graph is has an @id\n      if('@id' in value) {\n        containers.push(\n          '@graph@id', '@graph@id@set');\n      }\n      containers.push('@graph', '@graph@set', '@set');\n      // allow indexmap if the graph is not indexed\n      if(!('@index' in value)) {\n        containers.push(\n          '@graph@index', '@graph@index@set', '@index', '@index@set');\n      }\n      // allow idmap if the graph does not have an @id\n      if(!('@id' in value)) {\n        containers.push('@graph@id', '@graph@id@set');\n      }\n    } else if(_isObject(value) && !_isValue(value)) {\n      containers.push('@id', '@id@set', '@type', '@set@type');\n    }\n\n    // defaults for term selection based on type/language\n    let typeOrLanguage = '@language';\n    let typeOrLanguageValue = '@null';\n\n    if(reverse) {\n      typeOrLanguage = '@type';\n      typeOrLanguageValue = '@reverse';\n      containers.push('@set');\n    } else if(_isList(value)) {\n      // choose the most specific term that works for all elements in @list\n      // only select @list containers if @index is NOT in value\n      if(!('@index' in value)) {\n        containers.push('@list');\n      }\n      const list = value['@list'];\n      if(list.length === 0) {\n        // any empty list can be matched against any term that uses the\n        // @list container regardless of @type or @language\n        typeOrLanguage = '@any';\n        typeOrLanguageValue = '@none';\n      } else {\n        let commonLanguage = (list.length === 0) ? defaultLanguage : null;\n        let commonType = null;\n        for(let i = 0; i < list.length; ++i) {\n          const item = list[i];\n          let itemLanguage = '@none';\n          let itemType = '@none';\n          if(_isValue(item)) {\n            if('@language' in item) {\n              itemLanguage = item['@language'];\n            } else if('@type' in item) {\n              itemType = item['@type'];\n            } else {\n              // plain literal\n              itemLanguage = '@null';\n            }\n          } else {\n            itemType = '@id';\n          }\n          if(commonLanguage === null) {\n            commonLanguage = itemLanguage;\n          } else if(itemLanguage !== commonLanguage && _isValue(item)) {\n            commonLanguage = '@none';\n          }\n          if(commonType === null) {\n            commonType = itemType;\n          } else if(itemType !== commonType) {\n            commonType = '@none';\n          }\n          // there are different languages and types in the list, so choose\n          // the most generic term, no need to keep iterating the list\n          if(commonLanguage === '@none' && commonType === '@none') {\n            break;\n          }\n        }\n        commonLanguage = commonLanguage || '@none';\n        commonType = commonType || '@none';\n        if(commonType !== '@none') {\n          typeOrLanguage = '@type';\n          typeOrLanguageValue = commonType;\n        } else {\n          typeOrLanguageValue = commonLanguage;\n        }\n      }\n    } else {\n      if(_isValue(value)) {\n        if('@language' in value && !('@index' in value)) {\n          containers.push('@language', '@language@set');\n          typeOrLanguageValue = value['@language'];\n        } else if('@type' in value) {\n          typeOrLanguage = '@type';\n          typeOrLanguageValue = value['@type'];\n        }\n      } else {\n        typeOrLanguage = '@type';\n        typeOrLanguageValue = '@id';\n      }\n      containers.push('@set');\n    }\n\n    // do term selection\n    containers.push('@none');\n\n    // an index map can be used to index values using @none, so add as a low\n    // priority\n    if(_isObject(value) && !('@index' in value)) {\n      // allow indexing even if no @index present\n      containers.push('@index', '@index@set');\n    }\n\n    // values without type or language can use @language map\n    if(_isValue(value) && Object.keys(value).length === 1) {\n      // allow indexing even if no @index present\n      containers.push('@language', '@language@set');\n    }\n\n    const term = _selectTerm(\n      activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue);\n    if(term !== null) {\n      return term;\n    }\n  }\n\n  // no term match, use @vocab if available\n  if(relativeTo.vocab) {\n    if('@vocab' in activeCtx) {\n      // determine if vocab is a prefix of the iri\n      const vocab = activeCtx['@vocab'];\n      if(iri.indexOf(vocab) === 0 && iri !== vocab) {\n        // use suffix as relative iri if it is not a term in the active context\n        const suffix = iri.substr(vocab.length);\n        if(!(suffix in activeCtx.mappings)) {\n          return suffix;\n        }\n      }\n    }\n  }\n\n  // no term or @vocab match, check for possible CURIEs\n  let choice = null;\n  // TODO: make FastCurieMap a class with a method to do this lookup\n  const partialMatches = [];\n  let iriMap = activeCtx.fastCurieMap;\n  // check for partial matches of against `iri`, which means look until\n  // iri.length - 1, not full length\n  const maxPartialLength = iri.length - 1;\n  for(let i = 0; i < maxPartialLength && iri[i] in iriMap; ++i) {\n    iriMap = iriMap[iri[i]];\n    if('' in iriMap) {\n      partialMatches.push(iriMap[''][0]);\n    }\n  }\n  // check partial matches in reverse order to prefer longest ones first\n  for(let i = partialMatches.length - 1; i >= 0; --i) {\n    const entry = partialMatches[i];\n    const terms = entry.terms;\n    for(const term of terms) {\n      // a CURIE is usable if:\n      // 1. it has no mapping, OR\n      // 2. value is null, which means we're not compacting an @value, AND\n      //   the mapping matches the IRI\n      const curie = term + ':' + iri.substr(entry.iri.length);\n      const isUsableCurie = (activeCtx.mappings[term]._prefix &&\n        (!(curie in activeCtx.mappings) ||\n        (value === null && activeCtx.mappings[curie]['@id'] === iri)));\n\n      // select curie if it is shorter or the same length but lexicographically\n      // less than the current choice\n      if(isUsableCurie && (choice === null ||\n        _compareShortestLeast(curie, choice) < 0)) {\n        choice = curie;\n      }\n    }\n  }\n\n  // return chosen curie\n  if(choice !== null) {\n    return choice;\n  }\n\n  // compact IRI relative to base\n  if(!relativeTo.vocab) {\n    return _removeBase(activeCtx['@base'], iri);\n  }\n\n  // return IRI as is\n  return iri;\n};\n\n/**\n * Performs value compaction on an object with '@value' or '@id' as the only\n * property.\n *\n * @param activeCtx the active context.\n * @param activeProperty the active property that points to the value.\n * @param value the value to compact.\n *\n * @return the compaction result.\n */\napi.compactValue = ({activeCtx, activeProperty, value}) => {\n  // value is a @value\n  if(_isValue(value)) {\n    // get context rules\n    const type = _getContextValue(activeCtx, activeProperty, '@type');\n    const language = _getContextValue(activeCtx, activeProperty, '@language');\n    const container =\n      _getContextValue(activeCtx, activeProperty, '@container') || [];\n\n    // whether or not the value has an @index that must be preserved\n    const preserveIndex = '@index' in value && !container.includes('@index');\n\n    // if there's no @index to preserve ...\n    if(!preserveIndex) {\n      // matching @type or @language specified in context, compact value\n      if(value['@type'] === type || value['@language'] === language) {\n        return value['@value'];\n      }\n    }\n\n    // return just the value of @value if all are true:\n    // 1. @value is the only key or @index isn't being preserved\n    // 2. there is no default language or @value is not a string or\n    //   the key has a mapping with a null @language\n    const keyCount = Object.keys(value).length;\n    const isValueOnlyKey = (keyCount === 1 ||\n      (keyCount === 2 && '@index' in value && !preserveIndex));\n    const hasDefaultLanguage = ('@language' in activeCtx);\n    const isValueString = _isString(value['@value']);\n    const hasNullMapping = (activeCtx.mappings[activeProperty] &&\n      activeCtx.mappings[activeProperty]['@language'] === null);\n    if(isValueOnlyKey &&\n      (!hasDefaultLanguage || !isValueString || hasNullMapping)) {\n      return value['@value'];\n    }\n\n    const rval = {};\n\n    // preserve @index\n    if(preserveIndex) {\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@index',\n        relativeTo: {vocab: true}\n      })] = value['@index'];\n    }\n\n    if('@type' in value) {\n      // compact @type IRI\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@type',\n        relativeTo: {vocab: true}\n      })] = api.compactIri(\n        {activeCtx, iri: value['@type'], relativeTo: {vocab: true}});\n    } else if('@language' in value) {\n      // alias @language\n      rval[api.compactIri({\n        activeCtx,\n        iri: '@language',\n        relativeTo: {vocab: true}\n      })] = value['@language'];\n    }\n\n    // alias @value\n    rval[api.compactIri({\n      activeCtx,\n      iri: '@value',\n      relativeTo: {vocab: true}\n    })] = value['@value'];\n\n    return rval;\n  }\n\n  // value is a subject reference\n  const expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true});\n  const type = _getContextValue(activeCtx, activeProperty, '@type');\n  const compacted = api.compactIri(\n    {activeCtx, iri: value['@id'], relativeTo: {vocab: type === '@vocab'}});\n\n  // compact to scalar\n  if(type === '@id' || type === '@vocab' || expandedProperty === '@graph') {\n    return compacted;\n  }\n\n  return {\n    [api.compactIri({\n      activeCtx,\n      iri: '@id',\n      relativeTo: {vocab: true}\n    })]: compacted\n  };\n};\n\n/**\n * Removes the @preserve keywords as the last step of the compaction\n * algorithm when it is running on framed output.\n *\n * @param ctx the active context used to compact the input.\n * @param input the framed, compacted output.\n * @param options the compaction options used.\n *\n * @return the resulting output.\n */\napi.removePreserve = (ctx, input, options) => {\n  // recurse through arrays\n  if(_isArray(input)) {\n    const output = [];\n    for(let i = 0; i < input.length; ++i) {\n      const result = api.removePreserve(ctx, input[i], options);\n      // drop nulls from arrays\n      if(result !== null) {\n        output.push(result);\n      }\n    }\n    input = output;\n  } else if(_isObject(input)) {\n    // remove @preserve\n    if('@preserve' in input) {\n      if(input['@preserve'] === '@null') {\n        return null;\n      }\n      return input['@preserve'];\n    }\n\n    // skip @values\n    if(_isValue(input)) {\n      return input;\n    }\n\n    // recurse through @lists\n    if(_isList(input)) {\n      input['@list'] = api.removePreserve(ctx, input['@list'], options);\n      return input;\n    }\n\n    // handle in-memory linked nodes\n    const idAlias = api.compactIri({\n      activeCtx: ctx,\n      iri: '@id',\n      relativeTo: {vocab: true}\n    });\n    if(idAlias in input) {\n      const id = input[idAlias];\n      if(id in options.link) {\n        const idx = options.link[id].indexOf(input);\n        if(idx !== -1) {\n          // already visited\n          return options.link[id][idx];\n        }\n        // prevent circular visitation\n        options.link[id].push(input);\n      } else {\n        // prevent circular visitation\n        options.link[id] = [input];\n      }\n    }\n\n    // recurse through properties\n    const graphAlias = api.compactIri({\n      activeCtx: ctx,\n      iri: '@graph',\n      relativeTo: {vocab: true}\n    });\n    for(const prop in input) {\n      // potentially remove the id, if it is an unreference bnode\n      if(prop === idAlias && options.bnodesToClear.includes(input[prop])) {\n        delete input[idAlias];\n        continue;\n      }\n\n      let result = api.removePreserve(ctx, input[prop], options);\n      const container = _getContextValue(ctx, prop, '@container') || [];\n      if(options.compactArrays && _isArray(result) && result.length === 1 &&\n        container.length === 0 && prop !== graphAlias) {\n        result = result[0];\n      }\n      input[prop] = result;\n    }\n  }\n  return input;\n};\n\n/**\n * Picks the preferred compaction term from the given inverse context entry.\n *\n * @param activeCtx the active context.\n * @param iri the IRI to pick the term for.\n * @param value the value to pick the term for.\n * @param containers the preferred containers.\n * @param typeOrLanguage either '@type' or '@language'.\n * @param typeOrLanguageValue the preferred value for '@type' or '@language'.\n *\n * @return the preferred term.\n */\nfunction _selectTerm(\n  activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue) {\n  if(typeOrLanguageValue === null) {\n    typeOrLanguageValue = '@null';\n  }\n\n  // preferences for the value of @type or @language\n  const prefs = [];\n\n  // determine prefs for @id based on whether or not value compacts to a term\n  if((typeOrLanguageValue === '@id' || typeOrLanguageValue === '@reverse') &&\n    _isSubjectReference(value)) {\n    // prefer @reverse first\n    if(typeOrLanguageValue === '@reverse') {\n      prefs.push('@reverse');\n    }\n    // try to compact value to a term\n    const term = api.compactIri(\n      {activeCtx, iri: value['@id'], relativeTo: {vocab: true}});\n    if(term in activeCtx.mappings &&\n      activeCtx.mappings[term] &&\n      activeCtx.mappings[term]['@id'] === value['@id']) {\n      // prefer @vocab\n      prefs.push.apply(prefs, ['@vocab', '@id']);\n    } else {\n      // prefer @id\n      prefs.push.apply(prefs, ['@id', '@vocab']);\n    }\n  } else {\n    prefs.push(typeOrLanguageValue);\n  }\n  prefs.push('@none');\n\n  const containerMap = activeCtx.inverse[iri];\n  for(let ci = 0; ci < containers.length; ++ci) {\n    // if container not available in the map, continue\n    const container = containers[ci];\n    if(!(container in containerMap)) {\n      continue;\n    }\n\n    const typeOrLanguageValueMap = containerMap[container][typeOrLanguage];\n    for(let pi = 0; pi < prefs.length; ++pi) {\n      // if type/language option not available in the map, continue\n      const pref = prefs[pi];\n      if(!(pref in typeOrLanguageValueMap)) {\n        continue;\n      }\n\n      // select term\n      return typeOrLanguageValueMap[pref];\n    }\n  }\n\n  return null;\n}\n\n/**\n * The value of `@nest` in the term definition must either be `@nest`, or a term\n * which resolves to `@nest`.\n *\n * @param activeCtx the active context.\n * @param nestProperty a term in the active context or `@nest`.\n */\nfunction _checkNestProperty(activeCtx, nestProperty) {\n  if(_expandIri(activeCtx, nestProperty, {vocab: true}) !== '@nest') {\n    throw new JsonLdError(\n      'JSON-LD compact error; nested property must have an @nest value ' +\n      'resolving to @nest.',\n      'jsonld.SyntaxError', {code: 'invalid @nest value'});\n  }\n}\n"],"mappings":"AACA;;;;;;;ACSA;ACygBA;AAAA;;;;;;;;;;;;;;ACngBA;;;;;;;;;;;;;;;ACRA;ACJA;ACHA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ACkCA;AAyiBA;AAAA;;;;;;;;;AAglJA;;AAcA;AA2oBA;AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AClxLA;AA4MA;AAAA;;;;;;;;;;ACopBA;;AAcA","sourceRoot":""}